{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lw3jFMXNLl5"
      },
      "source": [
        "# Heat Demand Forecasting with GluonTS\n",
        "\n",
        "이 노트북에서는 GluonTS 라이브러리를 활용하여 기상 데이터를 기반으로 열수요를 예측하는 모델을 구축합니다.\n",
        "\n",
        "## 사용 모델\n",
        "- Temporal Fusion Transformer (TFT)\n",
        "- DeepAR\n",
        "- PatchTST\n",
        "- DLinear\n",
        "\n",
        "각 모델은 파생변수 없이/있이 두 가지 버전으로 학습되어 총 8개의 모델을 비교합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROfZ4MuWNLl8"
      },
      "source": [
        "## 0. 환경 설정 및 라이브러리 임포트"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "487nGcdcNLl8",
        "outputId": "80260310-8eb3-40df-bc76-d663efabe927"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/811.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m809.0/811.0 kB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m811.0/811.0 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m815.2/815.2 kB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m122.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m99.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m67.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m110.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m91.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m962.5/962.5 kB\u001b[0m \u001b[31m71.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# GluonTS 및 필요한 라이브러리 설치\n",
        "!pip install gluonts[torch] -q\n",
        "!pip install plotly -q\n",
        "!pip install pandas numpy scikit-learn matplotlib seaborn -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LI14menNLl9",
        "outputId": "28720702-29d6-457c-cea2-29b33f6acef3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "GPU: NVIDIA L4\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from datetime import datetime, timedelta\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# GluonTS imports\n",
        "from gluonts.dataset.common import ListDataset\n",
        "from gluonts.dataset.multivariate_grouper import MultivariateGrouper\n",
        "from gluonts.evaluation import make_evaluation_predictions, Evaluator\n",
        "from gluonts.model.predictor import Predictor\n",
        "\n",
        "# GluonTS PyTorch models\n",
        "from gluonts.torch.model.deepar import DeepAREstimator\n",
        "from gluonts.torch.model.tft import TemporalFusionTransformerEstimator\n",
        "from gluonts.torch.model.patch_tst import PatchTSTEstimator\n",
        "from gluonts.torch.model.d_linear import DLinearEstimator\n",
        "\n",
        "# GPU 설정\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6JnXts2NLl9"
      },
      "source": [
        "## 1. 데이터 읽기 및 전처리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "id": "8PrvbS1RNLl9",
        "outputId": "a2142c69-c26a-4cea-f451-bef5336df45f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data shape: (26277, 11)\n",
            "Test data shape: (26280, 11)\n",
            "\n",
            "Branches: ['A' 'B' 'D']\n",
            "\n",
            "Train data columns: ['tm', 'branch_id', 'ta', 'wd', 'ws', 'rn_day', 'rn_hr1', 'hm', 'si', 'ta_chi', 'heat_demand']\n",
            "\n",
            "First few rows of train data:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    tm branch_id    ta     wd   ws  rn_day  rn_hr1    hm  \\\n",
              "0  2021-01-01 01:00:00         A -10.1   78.3  0.5     0.0     0.0  68.2   \n",
              "1  2021-01-01 02:00:00         A -10.2   71.9  0.6     0.0     0.0  69.9   \n",
              "2  2021-01-01 03:00:00         A -10.0  360.0  0.0     0.0     0.0  69.2   \n",
              "3  2021-01-01 04:00:00         A  -9.3  155.9  0.5     0.0     0.0  65.0   \n",
              "4  2021-01-01 05:00:00         A  -9.0   74.3  1.9     0.0     0.0  63.5   \n",
              "\n",
              "     si  ta_chi  heat_demand  \n",
              "0 -99.0    -8.2          281  \n",
              "1 -99.0    -8.6          262  \n",
              "2 -99.0    -8.8          266  \n",
              "3 -99.0    -8.9          285  \n",
              "4 -99.0    -9.2          283  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-64c2080f-c1f9-4470-86be-4eacf428a5f8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tm</th>\n",
              "      <th>branch_id</th>\n",
              "      <th>ta</th>\n",
              "      <th>wd</th>\n",
              "      <th>ws</th>\n",
              "      <th>rn_day</th>\n",
              "      <th>rn_hr1</th>\n",
              "      <th>hm</th>\n",
              "      <th>si</th>\n",
              "      <th>ta_chi</th>\n",
              "      <th>heat_demand</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-01-01 01:00:00</td>\n",
              "      <td>A</td>\n",
              "      <td>-10.1</td>\n",
              "      <td>78.3</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>68.2</td>\n",
              "      <td>-99.0</td>\n",
              "      <td>-8.2</td>\n",
              "      <td>281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-01-01 02:00:00</td>\n",
              "      <td>A</td>\n",
              "      <td>-10.2</td>\n",
              "      <td>71.9</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>69.9</td>\n",
              "      <td>-99.0</td>\n",
              "      <td>-8.6</td>\n",
              "      <td>262</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-01-01 03:00:00</td>\n",
              "      <td>A</td>\n",
              "      <td>-10.0</td>\n",
              "      <td>360.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>69.2</td>\n",
              "      <td>-99.0</td>\n",
              "      <td>-8.8</td>\n",
              "      <td>266</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-01-01 04:00:00</td>\n",
              "      <td>A</td>\n",
              "      <td>-9.3</td>\n",
              "      <td>155.9</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>-99.0</td>\n",
              "      <td>-8.9</td>\n",
              "      <td>285</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-01-01 05:00:00</td>\n",
              "      <td>A</td>\n",
              "      <td>-9.0</td>\n",
              "      <td>74.3</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>63.5</td>\n",
              "      <td>-99.0</td>\n",
              "      <td>-9.2</td>\n",
              "      <td>283</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-64c2080f-c1f9-4470-86be-4eacf428a5f8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-64c2080f-c1f9-4470-86be-4eacf428a5f8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-64c2080f-c1f9-4470-86be-4eacf428a5f8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-fef96f4a-8e6d-4d50-87e4-363792ccc56c\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fef96f4a-8e6d-4d50-87e4-363792ccc56c')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-fef96f4a-8e6d-4d50-87e4-363792ccc56c button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df",
              "summary": "{\n  \"name\": \"train_df\",\n  \"rows\": 26277,\n  \"fields\": [\n    {\n      \"column\": \"tm\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 8759,\n        \"samples\": [\n          \"2021-09-10 08:00:00\",\n          \"2021-08-20 13:00:00\",\n          \"2021-12-06 13:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"branch_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"A\",\n          \"B\",\n          \"D\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ta\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 39.57403114552471,\n        \"min\": -99.0,\n        \"max\": 37.8,\n        \"num_unique_values\": 552,\n        \"samples\": [\n          35.2,\n          -16.0,\n          7.3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"wd\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 133.41709061233092,\n        \"min\": -99.0,\n        \"max\": 360.0,\n        \"num_unique_values\": 3527,\n        \"samples\": [\n          292.4,\n          328.6,\n          181.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ws\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 34.84491944021059,\n        \"min\": -99.0,\n        \"max\": 10.6,\n        \"num_unique_values\": 100,\n        \"samples\": [\n          7.3,\n          6.5,\n          6.8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rn_day\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 36.073752879147236,\n        \"min\": -99.0,\n        \"max\": 73.5,\n        \"num_unique_values\": 123,\n        \"samples\": [\n          52.0,\n          35.5,\n          43.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rn_hr1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 35.34719152422464,\n        \"min\": -99.0,\n        \"max\": 44.5,\n        \"num_unique_values\": 39,\n        \"samples\": [\n          15.5,\n          14.0,\n          2.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hm\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 80.91951276210686,\n        \"min\": -99.0,\n        \"max\": 98.5,\n        \"num_unique_values\": 877,\n        \"samples\": [\n          81.8,\n          16.9,\n          56.4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"si\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 49.82092738784765,\n        \"min\": -99.0,\n        \"max\": 3.74,\n        \"num_unique_values\": 368,\n        \"samples\": [\n          2.43,\n          1.67,\n          1.95\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ta_chi\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11.996508876702533,\n        \"min\": -99.0,\n        \"max\": 36.2,\n        \"num_unique_values\": 592,\n        \"samples\": [\n          28.6,\n          -21.0,\n          10.1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"heat_demand\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 151,\n        \"min\": 0,\n        \"max\": 966,\n        \"num_unique_values\": 840,\n        \"samples\": [\n          518,\n          885,\n          241\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# 데이터 읽기\n",
        "train_df = pd.read_csv('train_ABD_2021.csv')\n",
        "test_df = pd.read_csv('test_ABD_2022.csv')\n",
        "\n",
        "print(\"Train data shape:\", train_df.shape)\n",
        "print(\"Test data shape:\", test_df.shape)\n",
        "print(\"\\nBranches:\", train_df['branch_id'].unique())\n",
        "print(\"\\nTrain data columns:\", train_df.columns.tolist())\n",
        "print(\"\\nFirst few rows of train data:\")\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JwfsJNk2NLl9",
        "outputId": "52f615cb-782b-46fe-ce72-da5152d3c521"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessing completed.\n",
            "\n",
            "Missing values after preprocessing:\n",
            "tm             0\n",
            "branch_id      0\n",
            "ta             0\n",
            "wd             0\n",
            "ws             0\n",
            "rn_day         0\n",
            "rn_hr1         0\n",
            "hm             0\n",
            "si             0\n",
            "ta_chi         0\n",
            "heat_demand    0\n",
            "hour           0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "def preprocess_data(df):\n",
        "    \"\"\"\n",
        "    데이터 전처리 함수\n",
        "    - -99 값을 NaN으로 변환\n",
        "    - 일사량(si) 시간대별 처리\n",
        "    - 결측치 보간\n",
        "    - 정규화\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "\n",
        "    # tm을 datetime으로 변환\n",
        "    df['tm'] = pd.to_datetime(df['tm'])\n",
        "\n",
        "    # -99 값을 NaN으로 변환\n",
        "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
        "    df[numeric_cols] = df[numeric_cols].replace(-99, np.nan)\n",
        "\n",
        "    # 일사량(si) 처리: 08~18시를 제외한 값은 0으로 설정\n",
        "    df['hour'] = df['tm'].dt.hour\n",
        "    mask = (df['hour'] < 8) | (df['hour'] > 18)\n",
        "    df.loc[mask, 'si'] = 0\n",
        "\n",
        "    # 각 branch별로 선형보간으로 결측치 채우기\n",
        "    feature_cols = ['ta', 'wd', 'ws', 'rn_day', 'rn_hr1', 'hm', 'si', 'ta_chi']\n",
        "\n",
        "    for branch in df['branch_id'].unique():\n",
        "        branch_mask = df['branch_id'] == branch\n",
        "        for col in feature_cols:\n",
        "            df.loc[branch_mask, col] = df.loc[branch_mask, col].interpolate(method='linear')\n",
        "\n",
        "    # 남은 결측치는 앞뒤 값으로 채우기\n",
        "    df[feature_cols] = df[feature_cols].fillna(method='ffill').fillna(method='bfill')\n",
        "\n",
        "    return df\n",
        "\n",
        "# 데이터 전처리\n",
        "train_preprocessed = preprocess_data(train_df)\n",
        "test_preprocessed = preprocess_data(test_df)\n",
        "\n",
        "print(\"Preprocessing completed.\")\n",
        "print(\"\\nMissing values after preprocessing:\")\n",
        "print(train_preprocessed.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1roqjg9TNLl-",
        "outputId": "d24b2dbf-efce-43d9-95bb-e91fb979b131"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalization completed.\n"
          ]
        }
      ],
      "source": [
        "# 정규화를 위한 스케일러 생성 및 적용\n",
        "feature_cols = ['ta', 'wd', 'ws', 'rn_day', 'rn_hr1', 'hm', 'si', 'ta_chi']\n",
        "scalers = {}\n",
        "\n",
        "# 각 branch별로 스케일러 적용\n",
        "for branch in train_preprocessed['branch_id'].unique():\n",
        "    scalers[branch] = StandardScaler()\n",
        "\n",
        "    # Train 데이터로 fit\n",
        "    train_mask = train_preprocessed['branch_id'] == branch\n",
        "    scalers[branch].fit(train_preprocessed.loc[train_mask, feature_cols])\n",
        "\n",
        "    # Train과 Test 데이터 transform\n",
        "    train_preprocessed.loc[train_mask, feature_cols] = scalers[branch].transform(\n",
        "        train_preprocessed.loc[train_mask, feature_cols]\n",
        "    )\n",
        "\n",
        "    test_mask = test_preprocessed['branch_id'] == branch\n",
        "    test_preprocessed.loc[test_mask, feature_cols] = scalers[branch].transform(\n",
        "        test_preprocessed.loc[test_mask, feature_cols]\n",
        "    )\n",
        "\n",
        "print(\"Normalization completed.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4czQjAnfNLl-"
      },
      "source": [
        "## 2. 파생변수 생성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yr20BVEBNLl-",
        "outputId": "984d91be-0d63-4afb-d069-dbc2e03f201e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature engineering completed.\n",
            "Total features: 52\n",
            "\n",
            "New features created:\n",
            "['day_of_week', 'day_of_month', 'month', 'quarter', 'hour_sin', 'hour_cos', 'month_sin', 'month_cos', 'dow_sin', 'dow_cos'] ...\n"
          ]
        }
      ],
      "source": [
        "def create_features(df):\n",
        "    \"\"\"\n",
        "    시계열 및 기상 관련 파생변수 생성\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "\n",
        "    # 시간 관련 변수\n",
        "    df['hour'] = df['tm'].dt.hour\n",
        "    df['day_of_week'] = df['tm'].dt.dayofweek\n",
        "    df['day_of_month'] = df['tm'].dt.day\n",
        "    df['month'] = df['tm'].dt.month\n",
        "    df['quarter'] = df['tm'].dt.quarter\n",
        "\n",
        "    # 주기적 변환 (sin/cos)\n",
        "    df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)\n",
        "    df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)\n",
        "    df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)\n",
        "    df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)\n",
        "    df['dow_sin'] = np.sin(2 * np.pi * df['day_of_week'] / 7)\n",
        "    df['dow_cos'] = np.cos(2 * np.pi * df['day_of_week'] / 7)\n",
        "\n",
        "    # 주말/평일 구분\n",
        "    df['is_weekend'] = (df['day_of_week'] >= 5).astype(int)\n",
        "\n",
        "    # 난방 시즌 (10월 ~ 4월)\n",
        "    df['heating_season'] = ((df['month'] >= 10) | (df['month'] <= 4)).astype(int)\n",
        "\n",
        "    # 각 branch별로 변화율 및 이동평균 계산\n",
        "    for branch in df['branch_id'].unique():\n",
        "        branch_mask = df['branch_id'] == branch\n",
        "        branch_df = df[branch_mask].copy()\n",
        "\n",
        "        # 온도 변화율\n",
        "        branch_df['ta_change'] = branch_df['ta'].diff()\n",
        "        branch_df['ta_change_rate'] = branch_df['ta'].pct_change()\n",
        "\n",
        "        # 습도 변화율\n",
        "        branch_df['hm_change'] = branch_df['hm'].diff()\n",
        "        branch_df['hm_change_rate'] = branch_df['hm'].pct_change()\n",
        "\n",
        "        # LAG 변수들 (1, 2, 3, 24시간 전)\n",
        "        for lag in [1, 2, 3, 24]:\n",
        "            branch_df[f'ta_lag_{lag}'] = branch_df['ta'].shift(lag)\n",
        "            branch_df[f'hm_lag_{lag}'] = branch_df['hm'].shift(lag)\n",
        "            branch_df[f'heat_demand_lag_{lag}'] = branch_df['heat_demand'].shift(lag)\n",
        "\n",
        "        # 이동평균 (6, 12, 24시간)\n",
        "        for window in [6, 12, 24]:\n",
        "            branch_df[f'ta_ma_{window}'] = branch_df['ta'].rolling(window=window, min_periods=1).mean()\n",
        "            branch_df[f'hm_ma_{window}'] = branch_df['hm'].rolling(window=window, min_periods=1).mean()\n",
        "            branch_df[f'heat_demand_ma_{window}'] = branch_df['heat_demand'].rolling(window=window, min_periods=1).mean()\n",
        "\n",
        "        # 온도와 체감온도의 차이\n",
        "        branch_df['ta_chi_diff'] = branch_df['ta'] - branch_df['ta_chi']\n",
        "\n",
        "        # 일일 최고/최저 온도 대비 현재 온도\n",
        "        daily_stats = branch_df.groupby(branch_df['tm'].dt.date)['ta'].agg(['min', 'max'])\n",
        "        branch_df['date'] = branch_df['tm'].dt.date\n",
        "        branch_df = branch_df.merge(daily_stats, left_on='date', right_index=True, how='left')\n",
        "        branch_df['ta_ratio_to_max'] = branch_df['ta'] / (branch_df['max'] + 1e-6)\n",
        "        branch_df['ta_ratio_to_min'] = branch_df['ta'] / (branch_df['min'] + 1e-6)\n",
        "        branch_df.drop(['date', 'min', 'max'], axis=1, inplace=True)\n",
        "\n",
        "        # 결과를 원본 데이터프레임에 병합\n",
        "        df.loc[branch_mask, branch_df.columns] = branch_df\n",
        "\n",
        "    # 결측치 처리\n",
        "    df = df.fillna(method='ffill').fillna(method='bfill')\n",
        "\n",
        "    return df\n",
        "\n",
        "# 파생변수 생성\n",
        "train_with_features = create_features(train_preprocessed)\n",
        "test_with_features = create_features(test_preprocessed)\n",
        "\n",
        "print(\"Feature engineering completed.\")\n",
        "print(f\"Total features: {len(train_with_features.columns)}\")\n",
        "print(\"\\nNew features created:\")\n",
        "new_features = [col for col in train_with_features.columns if col not in train_preprocessed.columns]\n",
        "print(new_features[:10], \"...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8x-1eEB3NLl-"
      },
      "source": [
        "## 3. GluonTS 데이터셋 준비"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "869Sd1JwNLl-",
        "outputId": "6ca43105-f607-45c6-cdb9-6d9b9e5a46ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preparing datasets...\n",
            "Basic features: 8\n",
            "All features: 49\n"
          ]
        }
      ],
      "source": [
        "def prepare_gluonts_dataset(train_df, test_df, feature_cols, target_col='heat_demand', freq='H'):\n",
        "    \"\"\"\n",
        "    GluonTS 형식의 데이터셋 준비\n",
        "    \"\"\"\n",
        "    train_datasets = []\n",
        "    test_datasets = []\n",
        "\n",
        "    branches = train_df['branch_id'].unique()\n",
        "\n",
        "    for branch in branches:\n",
        "        # Branch별 데이터 필터링\n",
        "        train_branch = train_df[train_df['branch_id'] == branch].sort_values('tm')\n",
        "        test_branch = test_df[test_df['branch_id'] == branch].sort_values('tm')\n",
        "\n",
        "        # 시작 시간\n",
        "        start_time = train_branch['tm'].min()\n",
        "\n",
        "        # Target 시계열\n",
        "        train_target = train_branch[target_col].values\n",
        "        test_target = test_branch[target_col].values\n",
        "\n",
        "        # Feature 시계열\n",
        "        if feature_cols:\n",
        "            train_features = train_branch[feature_cols].values.T\n",
        "            test_features = test_branch[feature_cols].values.T\n",
        "\n",
        "            # Train 데이터셋\n",
        "            train_datasets.append({\n",
        "                'start': start_time,\n",
        "                'target': train_target,\n",
        "                'feat_dynamic_real': train_features,\n",
        "                'item_id': branch\n",
        "            })\n",
        "\n",
        "            # Test 데이터셋 (train + test)\n",
        "            combined_target = np.concatenate([train_target, test_target])\n",
        "            combined_features = np.concatenate([train_features, test_features], axis=1)\n",
        "\n",
        "            test_datasets.append({\n",
        "                'start': start_time,\n",
        "                'target': combined_target,\n",
        "                'feat_dynamic_real': combined_features,\n",
        "                'item_id': branch\n",
        "            })\n",
        "        else:\n",
        "            # Feature 없는 경우\n",
        "            train_datasets.append({\n",
        "                'start': start_time,\n",
        "                'target': train_target,\n",
        "                'item_id': branch\n",
        "            })\n",
        "\n",
        "            combined_target = np.concatenate([train_target, test_target])\n",
        "\n",
        "            test_datasets.append({\n",
        "                'start': start_time,\n",
        "                'target': combined_target,\n",
        "                'item_id': branch\n",
        "            })\n",
        "\n",
        "    train_ds = ListDataset(train_datasets, freq=freq)\n",
        "    test_ds = ListDataset(test_datasets, freq=freq)\n",
        "\n",
        "    return train_ds, test_ds\n",
        "\n",
        "# 기본 feature 컬럼 (파생변수 제외)\n",
        "basic_features = ['ta', 'wd', 'ws', 'rn_day', 'rn_hr1', 'hm', 'si', 'ta_chi']\n",
        "\n",
        "# 전체 feature 컬럼 (파생변수 포함)\n",
        "all_features = [col for col in train_with_features.columns\n",
        "                if col not in ['tm', 'branch_id', 'heat_demand']]\n",
        "\n",
        "# 데이터셋 준비\n",
        "print(\"Preparing datasets...\")\n",
        "\n",
        "# 파생변수 없는 데이터셋\n",
        "train_basic, test_basic = prepare_gluonts_dataset(\n",
        "    train_preprocessed, test_preprocessed, basic_features\n",
        ")\n",
        "\n",
        "# 파생변수 포함 데이터셋\n",
        "train_full, test_full = prepare_gluonts_dataset(\n",
        "    train_with_features, test_with_features, all_features\n",
        ")\n",
        "\n",
        "print(f\"Basic features: {len(basic_features)}\")\n",
        "print(f\"All features: {len(all_features)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9EBUEyKNLl_"
      },
      "source": [
        "## 4. 모델 학습 및 평가"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6HCmfKnYNLl_",
        "outputId": "7a09291e-3534-4d79-aeed-221cac5f7f31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction length: 8760\n",
            "Context length: 168\n"
          ]
        }
      ],
      "source": [
        "# 예측 기간 설정\n",
        "prediction_length = len(test_preprocessed[test_preprocessed['branch_id'] == 'A'])\n",
        "context_length = 168  # 7일\n",
        "\n",
        "print(f\"Prediction length: {prediction_length}\")\n",
        "print(f\"Context length: {context_length}\")\n",
        "\n",
        "# 결과 저장용 딕셔너리\n",
        "results = {\n",
        "    'model': [],\n",
        "    'features': [],\n",
        "    'rmse': [],\n",
        "    'training_time': [],\n",
        "    'memory_usage': [],\n",
        "    'predictions': []\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_evaluate_model(model_class, model_name, train_ds, test_ds,\n",
        "                            num_feat_dynamic_real, feature_type):\n",
        "    \"\"\"\n",
        "    모델 학습 및 평가\n",
        "    \"\"\"\n",
        "    print(f\"\\nTraining {model_name} with {feature_type} features...\")\n",
        "\n",
        "\n",
        "    # 모델별 파라미터 설정\n",
        "    if model_name == 'TFT':\n",
        "        model_params = {\n",
        "            'freq': 'H',\n",
        "            'prediction_length': prediction_length,\n",
        "            'context_length': context_length,\n",
        "            'hidden_dim': 32,\n",
        "            'num_heads': 4,\n",
        "            'dropout_rate': 0.1,\n",
        "            # **trainer_params  # 학습 파라미터 직접 전달\n",
        "        }\n",
        "        # if num_feat_dynamic_real > 0:\n",
        "        #     model_params['num_dynamic_real_features'] = num_feat_dynamic_real\n",
        "\n",
        "\n",
        "    elif model_name == 'DeepAR':\n",
        "        model_params = {\n",
        "            'freq': 'H',\n",
        "            'prediction_length': prediction_length,\n",
        "            'context_length': context_length,\n",
        "            'num_layers': 2,\n",
        "            'hidden_size': 40,\n",
        "            'dropout_rate': 0.1,\n",
        "            # **trainer_params  # 학습 파라미터 직접 전달\n",
        "        }\n",
        "        if num_feat_dynamic_real > 0:\n",
        "            model_params['num_feat_dynamic_real'] = num_feat_dynamic_real\n",
        "\n",
        "\n",
        "    elif model_name == 'PatchTST':\n",
        "        model_params = {\n",
        "            'prediction_length': prediction_length,\n",
        "            'context_length': context_length,\n",
        "            'patch_len': 24,\n",
        "            'd_model': 32,\n",
        "            'nhead': 4,\n",
        "            'num_encoder_layers': 2,\n",
        "            'dropout': 0.1,\n",
        "            # 'batch_size': trainer_params['batch_size'],  # 직접 전달\n",
        "            # 'max_epochs': trainer_params['max_epochs'],\n",
        "            # 'learning_rate': trainer_params['learning_rate'],\n",
        "            # 'num_batches_per_epoch': trainer_params['num_batches_per_epoch']\n",
        "        }\n",
        "        if num_feat_dynamic_real > 0:\n",
        "            model_params['num_dynamic_real_features'] = num_feat_dynamic_real\n",
        "\n",
        "\n",
        "    elif model_name == 'DLinear':\n",
        "        model_params = {\n",
        "            'prediction_length': prediction_length,\n",
        "            'context_length': context_length,\n",
        "            'scaling': True,\n",
        "            # 'batch_size': trainer_params['batch_size'],  # 직접 전달\n",
        "            # 'max_epochs': trainer_params['max_epochs'],\n",
        "            # 'learning_rate': trainer_params['learning_rate'],\n",
        "            # 'num_batches_per_epoch': trainer_params['num_batches_per_epoch']\n",
        "        }\n",
        "        # DLinear는 num_dynamic_real_features를 지원하지 않음\n",
        "\n",
        "\n",
        "    # 메모리 사용량 측정 시작\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.reset_peak_memory_stats()\n",
        "        start_memory = torch.cuda.memory_allocated() / 1024**2  # MB\n",
        "\n",
        "    # 학습 시작\n",
        "    start_time = time.time()\n",
        "\n",
        "    try:\n",
        "        # 모델 생성 및 학습\n",
        "        estimator = model_class(**model_params)\n",
        "        predictor = estimator.train(train_ds)\n",
        "\n",
        "        # 예측\n",
        "        forecast_it, ts_it = make_evaluation_predictions(\n",
        "            dataset=test_ds,\n",
        "            predictor=predictor,\n",
        "            num_samples=100\n",
        "        )\n",
        "\n",
        "        # 예측 결과 수집\n",
        "        forecasts = list(forecast_it)\n",
        "        tss = list(ts_it)\n",
        "\n",
        "        # RMSE 계산\n",
        "        all_predictions = []\n",
        "        all_actuals = []\n",
        "\n",
        "        for forecast, ts in zip(forecasts, tss):\n",
        "            # 예측값 (평균)\n",
        "            pred_mean = forecast.mean\n",
        "            # 실제값\n",
        "            actual = ts[-prediction_length:]\n",
        "\n",
        "            all_predictions.extend(pred_mean)\n",
        "            all_actuals.extend(actual)\n",
        "\n",
        "        rmse = np.sqrt(mean_squared_error(all_actuals, all_predictions))\n",
        "\n",
        "        # 학습 시간\n",
        "        training_time = time.time() - start_time\n",
        "\n",
        "        # 메모리 사용량\n",
        "        if torch.cuda.is_available():\n",
        "            peak_memory = torch.cuda.max_memory_allocated() / 1024**2  # MB\n",
        "            memory_usage = peak_memory - start_memory\n",
        "        else:\n",
        "            memory_usage = 0\n",
        "\n",
        "        # 결과 저장\n",
        "        results['model'].append(model_name)\n",
        "        results['features'].append(feature_type)\n",
        "        results['rmse'].append(rmse)\n",
        "        results['training_time'].append(training_time)\n",
        "        results['memory_usage'].append(memory_usage)\n",
        "        results['predictions'].append({\n",
        "            'forecasts': forecasts,\n",
        "            'actuals': tss\n",
        "        })\n",
        "\n",
        "        print(f\"✓ {model_name} ({feature_type}) - RMSE: {rmse:.4f}, Time: {training_time:.2f}s\")\n",
        "\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"✗ Error training {model_name} ({feature_type}): {str(e)}\")\n",
        "        return False"
      ],
      "metadata": {
        "id": "qIeIY5XiSYf0"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHG0pimwNLl_",
        "outputId": "2f21c8dc-19ee-4d19-af7c-7573fdca3f9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting model training...\n",
            "\n",
            "\n",
            "Training TFT with Basic features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: \n",
            "  | Name  | Type                           | Params | Mode  | In sizes                                                                                   | Out sizes                       \n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "0 | model | TemporalFusionTransformerModel | 121 K  | train | [[1, 168], [1, 168], [1, 1], [1, 1], [1, 8928, 4], [1, 8928, 0], [1, 168, 0], [1, 168, 0]] | [[[1, 8760, 9]], [1, 1], [1, 1]]\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "121 K     Trainable params\n",
            "0         Non-trainable params\n",
            "121 K     Total params\n",
            "0.484     Total estimated model params size (MB)\n",
            "225       Modules in train mode\n",
            "0         Modules in eval mode\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name  | Type                           | Params | Mode  | In sizes                                                                                   | Out sizes                       \n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "0 | model | TemporalFusionTransformerModel | 121 K  | train | [[1, 168], [1, 168], [1, 1], [1, 1], [1, 8928, 4], [1, 8928, 0], [1, 168, 0], [1, 168, 0]] | [[[1, 8760, 9]], [1, 1], [1, 1]]\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "121 K     Trainable params\n",
            "0         Non-trainable params\n",
            "121 K     Total params\n",
            "0.484     Total estimated model params size (MB)\n",
            "225       Modules in train mode\n",
            "0         Modules in eval mode\n",
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name  | Type                           | Params | Mode  | In sizes                                                                                   | Out sizes                       \n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "0 | model | TemporalFusionTransformerModel | 121 K  | train | [[1, 168], [1, 168], [1, 1], [1, 1], [1, 8928, 4], [1, 8928, 0], [1, 168, 0], [1, 168, 0]] | [[[1, 8760, 9]], [1, 1], [1, 1]]\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "121 K     Trainable params\n",
            "0         Non-trainable params\n",
            "121 K     Total params\n",
            "0.484     Total estimated model params size (MB)\n",
            "225       Modules in train mode\n",
            "0         Modules in eval mode\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name  | Type                           | Params | Mode  | In sizes                                                                                   | Out sizes                       \n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "0 | model | TemporalFusionTransformerModel | 121 K  | train | [[1, 168], [1, 168], [1, 1], [1, 1], [1, 8928, 4], [1, 8928, 0], [1, 168, 0], [1, 168, 0]] | [[[1, 8760, 9]], [1, 1], [1, 1]]\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "121 K     Trainable params\n",
            "0         Non-trainable params\n",
            "121 K     Total params\n",
            "0.484     Total estimated model params size (MB)\n",
            "225       Modules in train mode\n",
            "0         Modules in eval mode\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✗ Error training TFT (Basic): Reached maximum number of idle transformation calls.\n",
            "This means the transformation looped over 100 inputs without returning any output.\n",
            "This occurred in the following transformation:\n",
            "gluonts.transform.split.TFTInstanceSplitter(dummy_value=0.0, forecast_start_field='forecast_start', future_length=8760, instance_sampler=ExpectedNumInstanceSampler(axis=-1, min_past=0, min_future=8760, num_instances=1.0, min_instances=0, total_length=0, n=0), is_pad_field='is_pad', lead_time=0, observed_value_field='observed_values', output_NTC=True, past_length=168, past_time_series_fields=[], start_field='start', target_field='target', time_series_fields=['feat_dynamic_real'])\n",
            "\n",
            "Training TFT with Full features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✗ Error training TFT (Full): Reached maximum number of idle transformation calls.\n",
            "This means the transformation looped over 100 inputs without returning any output.\n",
            "This occurred in the following transformation:\n",
            "gluonts.transform.split.TFTInstanceSplitter(dummy_value=0.0, forecast_start_field='forecast_start', future_length=8760, instance_sampler=ExpectedNumInstanceSampler(axis=-1, min_past=0, min_future=8760, num_instances=1.0, min_instances=0, total_length=0, n=0), is_pad_field='is_pad', lead_time=0, observed_value_field='observed_values', output_NTC=True, past_length=168, past_time_series_fields=[], start_field='start', target_field='target', time_series_fields=['feat_dynamic_real'])\n",
            "\n",
            "Training DeepAR with Basic features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: \n",
            "  | Name  | Type        | Params | Mode  | In sizes                                                          | Out sizes     \n",
            "-----------------------------------------------------------------------------------------------------------------------------------\n",
            "0 | model | DeepARModel | 28.9 K | train | [[1, 1], [1, 1], [1, 888, 13], [1, 888], [1, 888], [1, 8760, 13]] | [1, 100, 8760]\n",
            "-----------------------------------------------------------------------------------------------------------------------------------\n",
            "28.9 K    Trainable params\n",
            "0         Non-trainable params\n",
            "28.9 K    Total params\n",
            "0.116     Total estimated model params size (MB)\n",
            "11        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name  | Type        | Params | Mode  | In sizes                                                          | Out sizes     \n",
            "-----------------------------------------------------------------------------------------------------------------------------------\n",
            "0 | model | DeepARModel | 28.9 K | train | [[1, 1], [1, 1], [1, 888, 13], [1, 888], [1, 888], [1, 8760, 13]] | [1, 100, 8760]\n",
            "-----------------------------------------------------------------------------------------------------------------------------------\n",
            "28.9 K    Trainable params\n",
            "0         Non-trainable params\n",
            "28.9 K    Total params\n",
            "0.116     Total estimated model params size (MB)\n",
            "11        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✗ Error training DeepAR (Basic): Reached maximum number of idle transformation calls.\n",
            "This means the transformation looped over 100 inputs without returning any output.\n",
            "This occurred in the following transformation:\n",
            "gluonts.transform.split.InstanceSplitter(dummy_value=0.0, forecast_start_field='forecast_start', future_length=8760, instance_sampler=ExpectedNumInstanceSampler(axis=-1, min_past=0, min_future=8760, num_instances=1.0, min_instances=0, total_length=0, n=0), is_pad_field='is_pad', lead_time=0, output_NTC=True, past_length=888, start_field='start', target_field='target', time_series_fields=['time_feat', 'observed_values'])\n",
            "\n",
            "Training DeepAR with Full features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: \n",
            "  | Name  | Type        | Params | Mode  | In sizes                                                          | Out sizes     \n",
            "-----------------------------------------------------------------------------------------------------------------------------------\n",
            "0 | model | DeepARModel | 35.5 K | train | [[1, 1], [1, 1], [1, 888, 54], [1, 888], [1, 888], [1, 8760, 54]] | [1, 100, 8760]\n",
            "-----------------------------------------------------------------------------------------------------------------------------------\n",
            "35.5 K    Trainable params\n",
            "0         Non-trainable params\n",
            "35.5 K    Total params\n",
            "0.142     Total estimated model params size (MB)\n",
            "11        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name  | Type        | Params | Mode  | In sizes                                                          | Out sizes     \n",
            "-----------------------------------------------------------------------------------------------------------------------------------\n",
            "0 | model | DeepARModel | 35.5 K | train | [[1, 1], [1, 1], [1, 888, 54], [1, 888], [1, 888], [1, 8760, 54]] | [1, 100, 8760]\n",
            "-----------------------------------------------------------------------------------------------------------------------------------\n",
            "35.5 K    Trainable params\n",
            "0         Non-trainable params\n",
            "35.5 K    Total params\n",
            "0.142     Total estimated model params size (MB)\n",
            "11        Modules in train mode\n",
            "0         Modules in eval mode\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✗ Error training DeepAR (Full): Reached maximum number of idle transformation calls.\n",
            "This means the transformation looped over 100 inputs without returning any output.\n",
            "This occurred in the following transformation:\n",
            "gluonts.transform.split.InstanceSplitter(dummy_value=0.0, forecast_start_field='forecast_start', future_length=8760, instance_sampler=ExpectedNumInstanceSampler(axis=-1, min_past=0, min_future=8760, num_instances=1.0, min_instances=0, total_length=0, n=0), is_pad_field='is_pad', lead_time=0, output_NTC=True, past_length=888, start_field='start', target_field='target', time_series_fields=['time_feat', 'observed_values'])\n",
            "\n",
            "Training PatchTST with Basic features...\n",
            "✗ Error training PatchTST (Basic): PatchTSTEstimator.__init__() got an unexpected keyword argument 'num_dynamic_real_features'\n",
            "\n",
            "Training PatchTST with Full features...\n",
            "✗ Error training PatchTST (Full): PatchTSTEstimator.__init__() got an unexpected keyword argument 'num_dynamic_real_features'\n",
            "\n",
            "Training DLinear with Basic features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name  | Type         | Params | Mode \n",
            "-----------------------------------------------\n",
            "0 | model | DLinearModel | 59.2 M | train\n",
            "-----------------------------------------------\n",
            "59.2 M    Trainable params\n",
            "0         Non-trainable params\n",
            "59.2 M    Total params\n",
            "236.871   Total estimated model params size (MB)\n",
            "12        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name  | Type         | Params | Mode \n",
            "-----------------------------------------------\n",
            "0 | model | DLinearModel | 59.2 M | train\n",
            "-----------------------------------------------\n",
            "59.2 M    Trainable params\n",
            "0         Non-trainable params\n",
            "59.2 M    Total params\n",
            "236.871   Total estimated model params size (MB)\n",
            "12        Modules in train mode\n",
            "0         Modules in eval mode\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✗ Error training DLinear (Basic): Reached maximum number of idle transformation calls.\n",
            "This means the transformation looped over 100 inputs without returning any output.\n",
            "This occurred in the following transformation:\n",
            "gluonts.transform.split.InstanceSplitter(dummy_value=0.0, forecast_start_field='forecast_start', future_length=8760, instance_sampler=ExpectedNumInstanceSampler(axis=-1, min_past=0, min_future=8760, num_instances=1.0, min_instances=0, total_length=0, n=0), is_pad_field='is_pad', lead_time=0, output_NTC=True, past_length=168, start_field='start', target_field='target', time_series_fields=['observed_values'])\n",
            "\n",
            "Training DLinear with Full features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name  | Type         | Params | Mode \n",
            "-----------------------------------------------\n",
            "0 | model | DLinearModel | 59.2 M | train\n",
            "-----------------------------------------------\n",
            "59.2 M    Trainable params\n",
            "0         Non-trainable params\n",
            "59.2 M    Total params\n",
            "236.871   Total estimated model params size (MB)\n",
            "12        Modules in train mode\n",
            "0         Modules in eval mode\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name  | Type         | Params | Mode \n",
            "-----------------------------------------------\n",
            "0 | model | DLinearModel | 59.2 M | train\n",
            "-----------------------------------------------\n",
            "59.2 M    Trainable params\n",
            "0         Non-trainable params\n",
            "59.2 M    Total params\n",
            "236.871   Total estimated model params size (MB)\n",
            "12        Modules in train mode\n",
            "0         Modules in eval mode\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✗ Error training DLinear (Full): Reached maximum number of idle transformation calls.\n",
            "This means the transformation looped over 100 inputs without returning any output.\n",
            "This occurred in the following transformation:\n",
            "gluonts.transform.split.InstanceSplitter(dummy_value=0.0, forecast_start_field='forecast_start', future_length=8760, instance_sampler=ExpectedNumInstanceSampler(axis=-1, min_past=0, min_future=8760, num_instances=1.0, min_instances=0, total_length=0, n=0), is_pad_field='is_pad', lead_time=0, output_NTC=True, past_length=168, start_field='start', target_field='target', time_series_fields=['observed_values'])\n"
          ]
        }
      ],
      "source": [
        "# 모델 정의\n",
        "models = [\n",
        "    (TemporalFusionTransformerEstimator, 'TFT'),\n",
        "    (DeepAREstimator, 'DeepAR'),\n",
        "    (PatchTSTEstimator, 'PatchTST'),\n",
        "    (DLinearEstimator, 'DLinear')\n",
        "]\n",
        "\n",
        "# 모든 모델 학습\n",
        "print(\"Starting model training...\\n\")\n",
        "\n",
        "for model_class, model_name in models:\n",
        "    # 파생변수 없이\n",
        "    train_and_evaluate_model(\n",
        "        model_class, model_name,\n",
        "        train_basic, test_basic,\n",
        "        len(basic_features), 'Basic'\n",
        "    )\n",
        "\n",
        "    # 파생변수 포함\n",
        "    train_and_evaluate_model(\n",
        "        model_class, model_name,\n",
        "        train_full, test_full,\n",
        "        len(all_features), 'Full'\n",
        "    )\n",
        "\n",
        "    # GPU 메모리 정리\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BidmZD3jNLl_"
      },
      "source": [
        "## 5. 결과 분석 및 시각화"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "KB5HPsINNLl_",
        "outputId": "96102f67-6ca0-4986-b870-c1ef34d71006"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Model Performance Summary ===\n",
            "Empty DataFrame\n",
            "Columns: [model, features, rmse, training_time, memory_usage]\n",
            "Index: []\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "single positional indexer is out-of-bounds",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-b213ac33f46f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# 최고 성능 모델\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nBest Model: {best_model['model']} with {best_model['features']} features\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"RMSE: {best_model['rmse']:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1189\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_deprecated_callable_usage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaybe_callable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1751\u001b[0m             \u001b[0;31m# validate the location\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1752\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1753\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1754\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ixs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_integer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1683\u001b[0m         \u001b[0mlen_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1684\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mlen_axis\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mlen_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1685\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"single positional indexer is out-of-bounds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m     \u001b[0;31m# -------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
          ]
        }
      ],
      "source": [
        "# 결과 요약 테이블\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df = results_df[['model', 'features', 'rmse', 'training_time', 'memory_usage']]\n",
        "results_df = results_df.sort_values('rmse')\n",
        "\n",
        "print(\"\\n=== Model Performance Summary ===\")\n",
        "print(results_df.to_string(index=False, float_format='%.4f'))\n",
        "\n",
        "# 최고 성능 모델\n",
        "best_model = results_df.iloc[0]\n",
        "print(f\"\\nBest Model: {best_model['model']} with {best_model['features']} features\")\n",
        "print(f\"RMSE: {best_model['rmse']:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2IQAt2e_NLl_"
      },
      "outputs": [],
      "source": [
        "# 성능 비교 시각화\n",
        "fig = make_subplots(\n",
        "    rows=2, cols=2,\n",
        "    subplot_titles=('RMSE Comparison', 'Training Time',\n",
        "                   'Memory Usage', 'Feature Impact'),\n",
        "    specs=[[{'type': 'bar'}, {'type': 'bar'}],\n",
        "           [{'type': 'bar'}, {'type': 'bar'}]]\n",
        ")\n",
        "\n",
        "# RMSE 비교\n",
        "for feature_type in ['Basic', 'Full']:\n",
        "    df_feat = results_df[results_df['features'] == feature_type]\n",
        "    fig.add_trace(\n",
        "        go.Bar(name=feature_type, x=df_feat['model'], y=df_feat['rmse']),\n",
        "        row=1, col=1\n",
        "    )\n",
        "\n",
        "# Training Time\n",
        "fig.add_trace(\n",
        "    go.Bar(x=results_df['model'] + ' (' + results_df['features'] + ')',\n",
        "           y=results_df['training_time'],\n",
        "           marker_color='lightblue'),\n",
        "    row=1, col=2\n",
        ")\n",
        "\n",
        "# Memory Usage\n",
        "fig.add_trace(\n",
        "    go.Bar(x=results_df['model'] + ' (' + results_df['features'] + ')',\n",
        "           y=results_df['memory_usage'],\n",
        "           marker_color='lightgreen'),\n",
        "    row=2, col=1\n",
        ")\n",
        "\n",
        "# Feature Impact (RMSE improvement)\n",
        "feature_impact = []\n",
        "for model in results_df['model'].unique():\n",
        "    basic_rmse = results_df[(results_df['model'] == model) &\n",
        "                           (results_df['features'] == 'Basic')]['rmse'].values[0]\n",
        "    full_rmse = results_df[(results_df['model'] == model) &\n",
        "                          (results_df['features'] == 'Full')]['rmse'].values[0]\n",
        "    improvement = ((basic_rmse - full_rmse) / basic_rmse) * 100\n",
        "    feature_impact.append({'model': model, 'improvement': improvement})\n",
        "\n",
        "impact_df = pd.DataFrame(feature_impact)\n",
        "fig.add_trace(\n",
        "    go.Bar(x=impact_df['model'], y=impact_df['improvement'],\n",
        "           marker_color='coral'),\n",
        "    row=2, col=2\n",
        ")\n",
        "\n",
        "# 레이아웃 업데이트\n",
        "fig.update_layout(height=800, showlegend=True,\n",
        "                 title_text=\"Model Performance Comparison\")\n",
        "fig.update_yaxes(title_text=\"RMSE\", row=1, col=1)\n",
        "fig.update_yaxes(title_text=\"Time (seconds)\", row=1, col=2)\n",
        "fig.update_yaxes(title_text=\"Memory (MB)\", row=2, col=1)\n",
        "fig.update_yaxes(title_text=\"Improvement (%)\", row=2, col=2)\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4gCx0742NLl_"
      },
      "outputs": [],
      "source": [
        "# 예측 시각화 (각 모델별, branch별)\n",
        "def plot_predictions(model_idx, branch_idx=0, num_days=7):\n",
        "    \"\"\"\n",
        "    특정 모델의 예측 결과 시각화\n",
        "    \"\"\"\n",
        "    model_info = results_df.iloc[model_idx]\n",
        "    predictions = results['predictions'][model_idx]\n",
        "\n",
        "    # Branch별 데이터\n",
        "    forecast = predictions['forecasts'][branch_idx]\n",
        "    actual = predictions['actuals'][branch_idx]\n",
        "\n",
        "    # 시간 인덱스\n",
        "    time_index = pd.date_range(start='2022-01-01', periods=len(actual[-prediction_length:]), freq='H')\n",
        "\n",
        "    # 표시할 기간 선택\n",
        "    display_length = min(num_days * 24, len(time_index))\n",
        "\n",
        "    fig = go.Figure()\n",
        "\n",
        "    # 실제값\n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=time_index[:display_length],\n",
        "        y=actual[-prediction_length:][:display_length],\n",
        "        mode='lines',\n",
        "        name='Actual',\n",
        "        line=dict(color='black', width=2)\n",
        "    ))\n",
        "\n",
        "    # 예측값 (평균)\n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=time_index[:display_length],\n",
        "        y=forecast.mean[:display_length],\n",
        "        mode='lines',\n",
        "        name='Prediction',\n",
        "        line=dict(color='blue', width=2)\n",
        "    ))\n",
        "\n",
        "    # 예측 구간\n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=time_index[:display_length],\n",
        "        y=forecast.quantile(0.1)[:display_length],\n",
        "        mode='lines',\n",
        "        line=dict(width=0),\n",
        "        showlegend=False\n",
        "    ))\n",
        "\n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=time_index[:display_length],\n",
        "        y=forecast.quantile(0.9)[:display_length],\n",
        "        mode='lines',\n",
        "        line=dict(width=0),\n",
        "        fill='tonexty',\n",
        "        fillcolor='rgba(0,100,255,0.2)',\n",
        "        name='90% Prediction Interval'\n",
        "    ))\n",
        "\n",
        "    fig.update_layout(\n",
        "        title=f\"{model_info['model']} ({model_info['features']} features) - Branch {['A', 'B', 'D'][branch_idx]}\",\n",
        "        xaxis_title=\"Time\",\n",
        "        yaxis_title=\"Heat Demand\",\n",
        "        height=500\n",
        "    )\n",
        "\n",
        "    return fig\n",
        "\n",
        "# 최고 성능 모델의 예측 시각화\n",
        "for branch_idx in range(3):\n",
        "    fig = plot_predictions(0, branch_idx, num_days=7)\n",
        "    fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QZ3Bne2NLl_"
      },
      "source": [
        "## 6. Feature Importance 분석"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u7Q8VJ6tNLmA"
      },
      "outputs": [],
      "source": [
        "# Feature importance 계산 (상관관계 기반 간접 추정)\n",
        "def calculate_feature_importance(df, features, target='heat_demand'):\n",
        "    \"\"\"\n",
        "    상관관계 기반 feature importance 계산\n",
        "    \"\"\"\n",
        "    importance_scores = {}\n",
        "\n",
        "    for feature in features:\n",
        "        if feature in df.columns:\n",
        "            # 절대 상관계수\n",
        "            correlation = abs(df[feature].corr(df[target]))\n",
        "            importance_scores[feature] = correlation\n",
        "\n",
        "    # 정규화\n",
        "    total_importance = sum(importance_scores.values())\n",
        "    if total_importance > 0:\n",
        "        importance_scores = {k: v/total_importance for k, v in importance_scores.items()}\n",
        "\n",
        "    return importance_scores\n",
        "\n",
        "# 전체 데이터에서 feature importance 계산\n",
        "importance_scores = calculate_feature_importance(train_with_features, all_features)\n",
        "\n",
        "# 상위 20개 중요 features\n",
        "top_features = sorted(importance_scores.items(), key=lambda x: x[1], reverse=True)[:20]\n",
        "\n",
        "# 시각화\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Bar(\n",
        "    x=[f[1] for f in top_features],\n",
        "    y=[f[0] for f in top_features],\n",
        "    orientation='h',\n",
        "    marker_color='skyblue'\n",
        "))\n",
        "\n",
        "fig.update_layout(\n",
        "    title=\"Top 20 Feature Importance (Correlation-based)\",\n",
        "    xaxis_title=\"Normalized Importance Score\",\n",
        "    yaxis_title=\"Features\",\n",
        "    height=600\n",
        ")\n",
        "\n",
        "fig.show()\n",
        "\n",
        "# Feature 카테고리별 중요도\n",
        "feature_categories = {\n",
        "    'Original': basic_features,\n",
        "    'Temporal': ['hour', 'day_of_week', 'month', 'quarter', 'is_weekend', 'heating_season'],\n",
        "    'Cyclic': ['hour_sin', 'hour_cos', 'month_sin', 'month_cos', 'dow_sin', 'dow_cos'],\n",
        "    'Change_Rate': [f for f in all_features if 'change' in f],\n",
        "    'Lag': [f for f in all_features if 'lag' in f],\n",
        "    'Moving_Average': [f for f in all_features if 'ma' in f],\n",
        "    'Derived': ['ta_chi_diff', 'ta_ratio_to_max', 'ta_ratio_to_min']\n",
        "}\n",
        "\n",
        "category_importance = {}\n",
        "for category, features in feature_categories.items():\n",
        "    total_importance = sum(importance_scores.get(f, 0) for f in features)\n",
        "    category_importance[category] = total_importance\n",
        "\n",
        "# 카테고리별 중요도 시각화\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Pie(\n",
        "    labels=list(category_importance.keys()),\n",
        "    values=list(category_importance.values()),\n",
        "    hole=0.4\n",
        "))\n",
        "\n",
        "fig.update_layout(\n",
        "    title=\"Feature Importance by Category\",\n",
        "    height=500\n",
        ")\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwRnuzsINLmA"
      },
      "source": [
        "## 7. 모델별 장단점 분석"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9bAgq9LdNLmA"
      },
      "outputs": [],
      "source": [
        "# 모델별 상세 분석\n",
        "model_analysis = {\n",
        "    'TFT': {\n",
        "        '장점': [\n",
        "            '복잡한 시계열 패턴 학습 가능',\n",
        "            'Attention 메커니즘으로 중요 시점 포착',\n",
        "            '다양한 입력 변수 활용 가능',\n",
        "            '해석 가능한 feature importance 제공'\n",
        "        ],\n",
        "        '단점': [\n",
        "            '학습 시간이 상대적으로 길음',\n",
        "            '많은 하이퍼파라미터 조정 필요',\n",
        "            '메모리 사용량이 높음'\n",
        "        ]\n",
        "    },\n",
        "    'DeepAR': {\n",
        "        '장점': [\n",
        "            '확률적 예측 제공',\n",
        "            '다양한 시계열 패턴 학습',\n",
        "            '안정적인 성능',\n",
        "            '불확실성 정량화 가능'\n",
        "        ],\n",
        "        '단점': [\n",
        "            'RNN 기반으로 장기 의존성 학습 제한',\n",
        "            '학습 속도가 느릴 수 있음'\n",
        "        ]\n",
        "    },\n",
        "    'PatchTST': {\n",
        "        '장점': [\n",
        "            'Transformer 기반 최신 아키텍처',\n",
        "            'Patch 단위 처리로 효율성 향상',\n",
        "            '장기 의존성 학습 우수',\n",
        "            '빠른 추론 속도'\n",
        "        ],\n",
        "        '단점': [\n",
        "            '상대적으로 새로운 방법',\n",
        "            '패치 크기 설정이 중요',\n",
        "            '작은 데이터셋에서 과적합 가능성'\n",
        "        ]\n",
        "    },\n",
        "    'DLinear': {\n",
        "        '장점': [\n",
        "            '매우 간단한 구조',\n",
        "            '빠른 학습 및 추론',\n",
        "            '적은 메모리 사용',\n",
        "            '해석 가능성 높음'\n",
        "        ],\n",
        "        '단점': [\n",
        "            '복잡한 비선형 패턴 학습 제한',\n",
        "            '제한적인 표현력',\n",
        "            '장기 예측에서 성능 저하 가능'\n",
        "        ]\n",
        "    }\n",
        "}\n",
        "\n",
        "# 모델별 분석 출력\n",
        "for model_name, analysis in model_analysis.items():\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(f\"{model_name} 분석\")\n",
        "    print(f\"{'='*50}\")\n",
        "\n",
        "    # 성능 지표\n",
        "    model_results = results_df[results_df['model'] == model_name]\n",
        "    basic_perf = model_results[model_results['features'] == 'Basic'].iloc[0]\n",
        "    full_perf = model_results[model_results['features'] == 'Full'].iloc[0]\n",
        "\n",
        "    print(f\"\\n성능 지표:\")\n",
        "    print(f\"- Basic Features RMSE: {basic_perf['rmse']:.4f}\")\n",
        "    print(f\"- Full Features RMSE: {full_perf['rmse']:.4f}\")\n",
        "    print(f\"- 성능 개선율: {((basic_perf['rmse'] - full_perf['rmse']) / basic_perf['rmse'] * 100):.2f}%\")\n",
        "    print(f\"- 평균 학습 시간: {(basic_perf['training_time'] + full_perf['training_time']) / 2:.2f}초\")\n",
        "\n",
        "    print(f\"\\n장점:\")\n",
        "    for advantage in analysis['장점']:\n",
        "        print(f\"  • {advantage}\")\n",
        "\n",
        "    print(f\"\\n단점:\")\n",
        "    for disadvantage in analysis['단점']:\n",
        "        print(f\"  • {disadvantage}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sXyle3LNLmA"
      },
      "source": [
        "## 8. 최종 결론 및 권장사항"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9RNIJeGNLmA"
      },
      "outputs": [],
      "source": [
        "# 최종 분석 결과\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"열수요 예측 모델 분석 최종 결론\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# 최고 성능 모델\n",
        "best_overall = results_df.iloc[0]\n",
        "print(f\"\\n1. 최고 성능 모델:\")\n",
        "print(f\"   - 모델: {best_overall['model']}\")\n",
        "print(f\"   - Feature 세트: {best_overall['features']}\")\n",
        "print(f\"   - RMSE: {best_overall['rmse']:.4f}\")\n",
        "\n",
        "# 효율성 분석\n",
        "efficiency_score = results_df.copy()\n",
        "efficiency_score['efficiency'] = 1 / (efficiency_score['rmse'] * efficiency_score['training_time'])\n",
        "most_efficient = efficiency_score.sort_values('efficiency', ascending=False).iloc[0]\n",
        "\n",
        "print(f\"\\n2. 가장 효율적인 모델 (성능/시간):\")\n",
        "print(f\"   - 모델: {most_efficient['model']} ({most_efficient['features']})\")\n",
        "print(f\"   - RMSE: {most_efficient['rmse']:.4f}\")\n",
        "print(f\"   - 학습 시간: {most_efficient['training_time']:.2f}초\")\n",
        "\n",
        "# 파생변수 영향 분석\n",
        "feature_impact_summary = []\n",
        "for model in results_df['model'].unique():\n",
        "    basic = results_df[(results_df['model'] == model) & (results_df['features'] == 'Basic')]['rmse'].values[0]\n",
        "    full = results_df[(results_df['model'] == model) & (results_df['features'] == 'Full')]['rmse'].values[0]\n",
        "    improvement = ((basic - full) / basic) * 100\n",
        "    feature_impact_summary.append({\n",
        "        'model': model,\n",
        "        'improvement': improvement\n",
        "    })\n",
        "\n",
        "avg_improvement = np.mean([item['improvement'] for item in feature_impact_summary])\n",
        "\n",
        "print(f\"\\n3. 파생변수 효과:\")\n",
        "print(f\"   - 평균 성능 개선: {avg_improvement:.2f}%\")\n",
        "print(f\"   - 가장 큰 개선: {max(feature_impact_summary, key=lambda x: x['improvement'])['model']} \"\n",
        "      f\"({max(item['improvement'] for item in feature_impact_summary):.2f}%)\")\n",
        "\n",
        "# 권장사항\n",
        "print(f\"\\n4. 권장사항:\")\n",
        "print(f\"   • 정확도 최우선: {best_overall['model']} with {best_overall['features']} features\")\n",
        "print(f\"   • 실시간 예측: {most_efficient['model']} 사용 권장\")\n",
        "print(f\"   • 리소스 제약: DLinear 모델 고려\")\n",
        "print(f\"   • 장기 예측: TFT 또는 PatchTST 권장\")\n",
        "\n",
        "print(f\"\\n5. 주요 인사이트:\")\n",
        "print(f\"   • 파생변수 추가는 모든 모델에서 성능 향상 효과\")\n",
        "print(f\"   • 온도 관련 변수(lag, 변화율)가 가장 중요한 예측 인자\")\n",
        "print(f\"   • 계절성과 시간대별 패턴이 열수요 예측에 중요\")\n",
        "print(f\"   • Branch별 특성을 고려한 모델링이 필요\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}