{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🔥 지역난방 열수요 예측을 위한 시계열 데이터 전처리\n",
    "\n",
    "## 📋 프로젝트 개요\n",
    "- **목표**: 기상변수를 활용한 지역난방 열수요 예측 모델 개발\n",
    "- **데이터**: 2021-2022년 1시간 단위 기상 + 열수요 데이터\n",
    "- **전처리**: 결측치 처리, 파생변수 생성, 스케일링, 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📚 라이브러리 로드 완료!\n"
     ]
    }
   ],
   "source": [
    "# 필요한 라이브러리 import\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 시각화 설정\n",
    "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"📚 라이브러리 로드 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1️⃣ 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 데이터 로드 중...\n",
      "✅ 훈련 데이터 로드 완료: (52557, 11)\n",
      "   컬럼: ['tm', 'branch_id', 'ta', 'wd', 'ws', 'rn_day', 'rn_hr1', 'hm', 'si', 'ta_chi', 'heat_demand']\n",
      "✅ 테스트 데이터 로드 완료: (26280, 11)\n"
     ]
    }
   ],
   "source": [
    "def load_data(train_path, test_path=None):\n",
    "    \"\"\"\n",
    "    훈련 데이터와 테스트 데이터를 로드합니다.\n",
    "    \n",
    "    Parameters:\n",
    "    train_path (str): 훈련 데이터 파일 경로\n",
    "    test_path (str): 테스트 데이터 파일 경로 (선택사항)\n",
    "    \n",
    "    Returns:\n",
    "    tuple: (train_df, test_df) 또는 train_df만\n",
    "    \"\"\"\n",
    "    print(\"📊 데이터 로드 중...\")\n",
    "    \n",
    "    # 훈련 데이터 로드\n",
    "    train_df = pd.read_csv(train_path)\n",
    "    print(f\"✅ 훈련 데이터 로드 완료: {train_df.shape}\")\n",
    "    print(f\"   컬럼: {list(train_df.columns)}\")\n",
    "    \n",
    "    # Unnamed 컬럼 제거\n",
    "    if 'Unnamed: 0' in train_df.columns:\n",
    "        train_df = train_df.drop(columns=['Unnamed: 0'])\n",
    "        print(\"   Unnamed: 0 컬럼 제거\")\n",
    "    \n",
    "    # 테스트 데이터 로드 (있는 경우)\n",
    "    if test_path:\n",
    "        test_df = pd.read_csv(test_path)\n",
    "        print(f\"✅ 테스트 데이터 로드 완료: {test_df.shape}\")\n",
    "        \n",
    "        if 'Unnamed: 0' in test_df.columns:\n",
    "            test_df = test_df.drop(columns=['Unnamed: 0'])\n",
    "            print(\"   Unnamed: 0 컬럼 제거\")\n",
    "        \n",
    "        return train_df, test_df\n",
    "    else:\n",
    "        return train_df\n",
    "\n",
    "# 데이터 로드 (파일 경로를 실제 경로로 변경하세요)\n",
    "# train_df = load_data('train_heat.csv')\n",
    "# test_df가 별도로 있다면: train_df, test_df = load_data('train_heat.csv', 'test_heat.csv')\n",
    "\n",
    "\n",
    "train_df, test_df = load_data('train_heat_ABD.csv', 'test_heat_ABD.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📈 데이터 기본 정보:\n",
      "   데이터 형태: (52557, 11)\n",
      "   지사별 데이터 수:\n",
      "branch_id\n",
      "A    17519\n",
      "B    17519\n",
      "D    17519\n",
      "Name: count, dtype: int64\n",
      "\n",
      "📊 결측치 현황:\n",
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# 데이터 기본 정보 확인\n",
    "print(f\"\\n📈 데이터 기본 정보:\")\n",
    "print(f\"   데이터 형태: {train_df.shape}\")\n",
    "print(f\"   지사별 데이터 수:\")\n",
    "if 'train_heat.branch_id' in train_df.columns:\n",
    "    print(train_df['train_heat.branch_id'].value_counts().head())\n",
    "elif 'branch_id' in train_df.columns:\n",
    "    print(train_df['branch_id'].value_counts().head())\n",
    "\n",
    "# 결측치 현황 확인\n",
    "print(f\"\\n📊 결측치 현황:\")\n",
    "missing_info = train_df.isnull().sum()\n",
    "print(missing_info[missing_info > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 컬럼명에서 'train_heat.' 접두사 제거\n",
    "# print(\"🔧 컬럼명 정리 중...\")\n",
    "# print(f\"   기존 컬럼명: {list(train_df.columns)}\")\n",
    "\n",
    "# # 'train_heat.' 접두사 제거\n",
    "# train_df.columns = train_df.columns.str.replace('train_heat.', '', regex=False)\n",
    "\n",
    "# print(f\"   변경된 컬럼명: {list(train_df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2️⃣ 결측치 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 결측치 처리 시작...\n",
      "   컬럼명 정리 완료: ['tm', 'branch_id', 'ta', 'wd', 'ws', 'rn_day', 'rn_hr1', 'hm', 'si', 'ta_chi', 'heat_demand']\n",
      "   🔄 -99 값을 NaN으로 변환 중...\n",
      "   ✅ 총 54449개의 -99 값을 NaN으로 변환\n",
      "   ☀️ 일사량(si) 특별 처리 중...\n",
      "   ✅ 야간시간대 일사량 23796개를 0으로 처리\n",
      "   📈 지사별 선형보간 처리 중...\n",
      "   ✅ 선형보간 완료\n",
      "   🎉 모든 결측치 처리 완료!\n"
     ]
    }
   ],
   "source": [
    "def handle_missing_values(df):\n",
    "    \"\"\"\n",
    "    결측치를 처리합니다.\n",
    "    1. -99 값을 NaN으로 변환\n",
    "    2. 일사량(si) 특별 처리 (야간시간 0 처리)\n",
    "    3. 지사별 선형보간\n",
    "    \"\"\"\n",
    "    print(\"🔧 결측치 처리 시작...\")\n",
    "    df = df.copy()\n",
    "    \n",
    "    # 컬럼명 정리 (train_heat. 접두사 제거)\n",
    "    df.columns = [col.replace('train_heat.', '') for col in df.columns]\n",
    "    print(f\"   컬럼명 정리 완료: {list(df.columns)}\")\n",
    "    \n",
    "    # 2-1. -99 값을 NaN으로 변환\n",
    "    print(\"   🔄 -99 값을 NaN으로 변환 중...\")\n",
    "    missing_cols = ['ta', 'wd', 'ws', 'rn_day', 'rn_hr1', 'hm', 'si', 'ta_chi', 'heat_demand']\n",
    "    before_count = 0\n",
    "    for col in missing_cols:\n",
    "        if col in df.columns:\n",
    "            count = (df[col] == -99).sum()\n",
    "            before_count += count\n",
    "            df[col] = df[col].replace(-99, np.nan)\n",
    "    \n",
    "    print(f\"   ✅ 총 {before_count}개의 -99 값을 NaN으로 변환\")\n",
    "    \n",
    "    # 2-2. 일사량(si) 특별 처리\n",
    "    if 'si' in df.columns and 'tm' in df.columns:\n",
    "        print(\"   ☀️ 일사량(si) 특별 처리 중...\")\n",
    "        \n",
    "        # tm을 datetime으로 변환\n",
    "        df['datetime'] = pd.to_datetime(df['tm'], format='%Y%m%d%H')\n",
    "        df['hour'] = df['datetime'].dt.hour\n",
    "        \n",
    "        # 야간시간대 (18시-08시) NaN을 0으로 처리\n",
    "        night_mask = (df['hour'] < 8) | (df['hour'] > 18)\n",
    "        night_nan_count = df.loc[night_mask, 'si'].isna().sum()\n",
    "        df.loc[night_mask & df['si'].isna(), 'si'] = 0\n",
    "        \n",
    "        print(f\"   ✅ 야간시간대 일사량 {night_nan_count}개를 0으로 처리\")\n",
    "    \n",
    "    # 2-3. 지사별 선형보간\n",
    "    print(\"   📈 지사별 선형보간 처리 중...\")\n",
    "    \n",
    "    if 'branch_id' in df.columns:\n",
    "        # datetime 기준으로 정렬\n",
    "        df = df.sort_values(['branch_id', 'datetime'])\n",
    "        \n",
    "        # 지사별로 그룹화하여 선형보간\n",
    "        for branch in df['branch_id'].unique():\n",
    "            branch_mask = df['branch_id'] == branch\n",
    "            branch_data = df[branch_mask].copy()\n",
    "            \n",
    "            # 각 수치형 컬럼에 대해 선형보간\n",
    "            numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "            for col in numeric_cols:\n",
    "                if col in branch_data.columns:\n",
    "                    # 시간 순서로 선형보간\n",
    "                    branch_data[col] = branch_data[col].interpolate(method='linear')\n",
    "                    # 앞뒤 결측치는 forward/backward fill\n",
    "                    branch_data[col] = branch_data[col].fillna(method='ffill').fillna(method='bfill')\n",
    "            \n",
    "            # 원본 데이터에 반영\n",
    "            df.loc[branch_mask, numeric_cols] = branch_data[numeric_cols]\n",
    "    \n",
    "    # 결측치 처리 결과 확인\n",
    "    missing_after = df.isnull().sum()\n",
    "    missing_cols_after = missing_after[missing_after > 0]\n",
    "    \n",
    "    print(f\"   ✅ 선형보간 완료\")\n",
    "    if len(missing_cols_after) > 0:\n",
    "        print(f\"   ⚠️ 남은 결측치: {missing_cols_after.to_dict()}\")\n",
    "    else:\n",
    "        print(f\"   🎉 모든 결측치 처리 완료!\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# 결측치 처리 실행\n",
    "train_df = handle_missing_values(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3️⃣ 기상 시계열 파생변수 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🌡️ 기상 시계열 파생변수 생성 중...\n",
      "   📅 시간 기본 변수 생성...\n",
      "   🔄 계절성 순환 변수 생성...\n",
      "✅ 시간 기본 변수 및 순환 변수 생성 완료\n"
     ]
    }
   ],
   "source": [
    "def create_weather_time_features(df):\n",
    "    \"\"\"\n",
    "    기상 데이터를 기반으로 시계열 파생변수를 생성합니다.\n",
    "    \"\"\"\n",
    "    print(\"🌡️ 기상 시계열 파생변수 생성 중...\")\n",
    "    df = df.copy()\n",
    "    \n",
    "    # 3-1. 시간 기본 변수 생성\n",
    "    print(\"   📅 시간 기본 변수 생성...\")\n",
    "    if 'datetime' not in df.columns and 'tm' in df.columns:\n",
    "        df['datetime'] = pd.to_datetime(df['tm'], format='%Y%m%d%H')\n",
    "    \n",
    "    df['year'] = df['datetime'].dt.year\n",
    "    df['month'] = df['datetime'].dt.month\n",
    "    df['day'] = df['datetime'].dt.day\n",
    "    df['hour'] = df['datetime'].dt.hour\n",
    "    df['dayofweek'] = df['datetime'].dt.dayofweek  # 0:월요일, 6:일요일\n",
    "    df['dayofyear'] = df['datetime'].dt.dayofyear\n",
    "    df['week'] = df['datetime'].dt.isocalendar().week\n",
    "    \n",
    "    # 3-2. 계절성 반영 변수 (순환형 인코딩)\n",
    "    print(\"   🔄 계절성 순환 변수 생성...\")\n",
    "    \n",
    "    # 시간의 순환성을 sin/cos로 표현\n",
    "    df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)\n",
    "    df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)\n",
    "    df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)\n",
    "    df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)\n",
    "    df['dayofweek_sin'] = np.sin(2 * np.pi * df['dayofweek'] / 7)\n",
    "    df['dayofweek_cos'] = np.cos(2 * np.pi * df['dayofweek'] / 7)\n",
    "    df['dayofyear_sin'] = np.sin(2 * np.pi * df['dayofyear'] / 365)\n",
    "    df['dayofyear_cos'] = np.cos(2 * np.pi * df['dayofyear'] / 365)\n",
    "    \n",
    "    # 계절 구분\n",
    "    df['season'] = df['month'].map({12: 0, 1: 0, 2: 0,  # 겨울\n",
    "                                   3: 1, 4: 1, 5: 1,    # 봄\n",
    "                                   6: 2, 7: 2, 8: 2,    # 여름\n",
    "                                   9: 3, 10: 3, 11: 3}) # 가을\n",
    "    \n",
    "    return df\n",
    "\n",
    "# 기상 시계열 파생변수 생성 실행\n",
    "train_df = create_weather_time_features(train_df)\n",
    "print(\"✅ 시간 기본 변수 및 순환 변수 생성 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔥 난방 관련 시간 변수 생성...\n",
      "   ✅ 난방 관련 시간 변수 생성 완료\n"
     ]
    }
   ],
   "source": [
    "def create_heating_related_features(df):\n",
    "    \"\"\"\n",
    "    난방 관련 시간 변수를 생성합니다.\n",
    "    \"\"\"\n",
    "    print(\"🔥 난방 관련 시간 변수 생성...\")\n",
    "    df = df.copy()\n",
    "    \n",
    "    # 난방시즌 (10월-4월)\n",
    "    df['heating_season'] = df['month'].isin([10, 11, 12, 1, 2, 3, 4]).astype(int)\n",
    "    # 피크 난방시즌 (12월-2월)\n",
    "    df['peak_heating'] = df['month'].isin([12, 1, 2]).astype(int)\n",
    "    # 중간계절 (3-4월, 10-11월)\n",
    "    df['shoulder_season'] = df['month'].isin([3, 4, 10, 11]).astype(int)\n",
    "    \n",
    "    # 시간대별 구분\n",
    "    df['is_weekend'] = (df['dayofweek'] >= 5).astype(int)\n",
    "    df['is_work_hour'] = ((df['hour'] >= 9) & (df['hour'] <= 18)).astype(int)\n",
    "    df['is_peak_morning'] = ((df['hour'] >= 7) & (df['hour'] <= 9)).astype(int)\n",
    "    df['is_peak_evening'] = ((df['hour'] >= 18) & (df['hour'] <= 22)).astype(int)\n",
    "    df['is_night'] = ((df['hour'] >= 23) | (df['hour'] <= 6)).astype(int)\n",
    "    \n",
    "    print(\"   ✅ 난방 관련 시간 변수 생성 완료\")\n",
    "    return df\n",
    "\n",
    "train_df = create_heating_related_features(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🌤️ 기상 파생변수 생성...\n",
      "   ✅ 기상 파생변수 생성 완료\n"
     ]
    }
   ],
   "source": [
    "def create_weather_derived_features(df):\n",
    "    \"\"\"\n",
    "    기상 파생변수를 생성합니다.\n",
    "    \"\"\"\n",
    "    print(\"🌤️ 기상 파생변수 생성...\")\n",
    "    df = df.copy()\n",
    "    \n",
    "    # 난방도일 (HDD) & 냉방도일 (CDD)\n",
    "    base_temp_heating = 18.0  # 난방 기준온도\n",
    "    base_temp_cooling = 26.0  # 냉방 기준온도\n",
    "    \n",
    "    if 'ta' in df.columns:\n",
    "        df['HDD_18'] = np.maximum(base_temp_heating - df['ta'], 0)\n",
    "        # df['HDD_20'] = np.maximum(20 - df['ta'], 0)  # 추가 기준온도\n",
    "        # df['CDD_26'] = np.maximum(df['ta'] - base_temp_cooling, 0)\n",
    "    \n",
    "    # # 체감온도 계산 (풍속 고려)\n",
    "    # if 'ta' in df.columns and 'ws' in df.columns:\n",
    "    #     df['wind_chill'] = 13.12 + 0.6215 * df['ta'] - 11.37 * (df['ws'] ** 0.16) + 0.3965 * df['ta'] * (df['ws'] ** 0.16)\n",
    "    \n",
    "    # 불쾌지수 (온도 + 습도)\n",
    "    if 'ta' in df.columns and 'hm' in df.columns:\n",
    "        df['discomfort_index'] = 0.81 * df['ta'] + 0.01 * df['hm'] * (0.99 * df['ta'] - 14.3) + 46.3\n",
    "    \n",
    "    # 기온 범주화\n",
    "    if 'ta' in df.columns:\n",
    "        df['temp_category'] = pd.cut(df['ta'], \n",
    "                                   bins=[-np.inf, 0, 10, 20, 30, np.inf], \n",
    "                                   labels=[0, 1, 2, 3, 4])  # 매우추움~더움\n",
    "        df['temp_category'] = df['temp_category'].astype(int)\n",
    "    \n",
    "    # 강수 관련\n",
    "    if 'rn_day' in df.columns:\n",
    "        df['is_rainy'] = (df['rn_day'] > 0).astype(int)\n",
    "        df['is_heavy_rain'] = (df['rn_day'] > 10).astype(int)\n",
    "        df['rain_intensity'] = pd.cut(df['rn_day'], \n",
    "                                    bins=[-1, 0, 1, 5, 10, np.inf], \n",
    "                                    labels=[0, 1, 2, 3, 4])\n",
    "        df['rain_intensity'] = df['rain_intensity'].astype(int)\n",
    "    \n",
    "    print(\"   ✅ 기상 파생변수 생성 완료\")\n",
    "    return df\n",
    "\n",
    "train_df = create_weather_derived_features(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Rolling 통계 및 지연 변수 생성...\n",
      "   ✅ Rolling 통계 및 지연 변수 생성 완료! (총 32개)\n"
     ]
    }
   ],
   "source": [
    "def create_rolling_and_lag_features(df):\n",
    "    \"\"\"\n",
    "    Rolling 통계 및 지연 변수를 생성합니다.\n",
    "    \"\"\"\n",
    "    print(\"📊 Rolling 통계 및 지연 변수 생성...\")\n",
    "    df = df.copy()\n",
    "    \n",
    "    # 지사별로 그룹화하여 처리\n",
    "    if 'branch_id' in df.columns:\n",
    "        df = df.sort_values(['branch_id', 'datetime'])\n",
    "        \n",
    "        for branch in df['branch_id'].unique():\n",
    "            branch_mask = df['branch_id'] == branch\n",
    "            branch_data = df[branch_mask].copy()\n",
    "            \n",
    "            # 기온 관련 rolling 통계\n",
    "            if 'ta' in branch_data.columns:\n",
    "                for window in [6, 12, 24, 48]:\n",
    "                    rolling_ta = branch_data['ta'].rolling(window=window, min_periods=1)\n",
    "                    branch_data[f'ta_mean_{window}h'] = rolling_ta.mean()\n",
    "                    branch_data[f'ta_std_{window}h'] = rolling_ta.std().fillna(0)  # std가 NaN일 수 있음\n",
    "                    branch_data[f'ta_max_{window}h'] = rolling_ta.max()\n",
    "                    branch_data[f'ta_min_{window}h'] = rolling_ta.min()\n",
    "                \n",
    "                # 기온 차분 및 변화율\n",
    "                branch_data['ta_diff_1h'] = branch_data['ta'].diff()\n",
    "                branch_data['ta_diff_24h'] = branch_data['ta'].diff(periods=24)\n",
    "                \n",
    "                # Lag 변수\n",
    "                for lag in [1, 2, 3, 6, 12, 24]:\n",
    "                    branch_data[f'ta_lag_{lag}'] = branch_data['ta'].shift(lag)\n",
    "            \n",
    "            # HDD rolling 합계\n",
    "            if 'HDD_18' in branch_data.columns:\n",
    "                for window in [6, 12, 24, 48]:\n",
    "                    branch_data[f'HDD_sum_{window}h'] = branch_data['HDD_18'].rolling(window=window, min_periods=1).sum()\n",
    "            \n",
    "            # 강수량 누적\n",
    "            if 'rn_hr1' in branch_data.columns:\n",
    "                for window in [3, 6, 12, 24]:\n",
    "                    branch_data[f'rain_sum_{window}h'] = branch_data['rn_hr1'].rolling(window=window, min_periods=1).sum()\n",
    "            \n",
    "            # 무한값 및 NaN 체크 및 처리\n",
    "            for col in branch_data.columns:\n",
    "                if branch_data[col].dtype in ['float64', 'float32']:\n",
    "                    # 무한값을 NaN으로 변환\n",
    "                    branch_data[col] = branch_data[col].replace([np.inf, -np.inf], np.nan)\n",
    "                    # NaN을 적절한 값으로 변환 (rolling 통계는 0, lag는 forward fill)\n",
    "                    if any(keyword in col for keyword in ['_mean_', '_std_', '_max_', '_min_', '_sum_', '_diff_']):\n",
    "                        branch_data[col] = branch_data[col].fillna(0)\n",
    "                    elif '_lag_' in col:\n",
    "                        branch_data[col] = branch_data[col].fillna(method='ffill').fillna(0)\n",
    "            \n",
    "            # 원본 데이터에 반영\n",
    "            new_cols = [col for col in branch_data.columns if col not in df.columns]\n",
    "            if new_cols:\n",
    "                df.loc[branch_mask, new_cols] = branch_data[new_cols]\n",
    "    \n",
    "    rolling_cols = len([col for col in df.columns if any(keyword in col for keyword in ['_mean_', '_std_', '_max_', '_min_', '_sum_', '_lag_', '_diff_'])])\n",
    "    print(f\"   ✅ Rolling 통계 및 지연 변수 생성 완료! (총 {rolling_cols}개)\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "train_df = create_rolling_and_lag_features(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4️⃣ 열수요 관련 파생변수 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔥 열수요 관련 파생변수 생성 중...\n",
      "   ✅ 열수요 관련 파생변수 생성 완료! (총 29개)\n"
     ]
    }
   ],
   "source": [
    "def create_heat_demand_features(df):\n",
    "    \"\"\"\n",
    "    열수요 관련 파생변수를 생성합니다.\n",
    "    \"\"\"\n",
    "    print(\"🔥 열수요 관련 파생변수 생성 중...\")\n",
    "    df = df.copy()\n",
    "    \n",
    "    if 'heat_demand' not in df.columns:\n",
    "        print(\"   ⚠️ heat_demand 컬럼이 없어서 건너뜁니다.\")\n",
    "        return df\n",
    "    \n",
    "    # 지사별로 그룹화하여 처리\n",
    "    if 'branch_id' in df.columns:\n",
    "        df = df.sort_values(['branch_id', 'datetime'])\n",
    "        \n",
    "        for branch in df['branch_id'].unique():\n",
    "            branch_mask = df['branch_id'] == branch\n",
    "            branch_data = df[branch_mask].copy()\n",
    "            \n",
    "            # 4-1. 열수요 Lag 변수\n",
    "            for lag in [1, 2, 3, 6, 12, 24, 48]:\n",
    "                branch_data[f'demand_lag_{lag}'] = branch_data['heat_demand'].shift(lag)\n",
    "            \n",
    "            # 4-2. 열수요 Rolling 통계\n",
    "            for window in [6, 12, 24, 48]:\n",
    "                rolling_demand = branch_data['heat_demand'].rolling(window=window, min_periods=1)\n",
    "                branch_data[f'demand_mean_{window}h'] = rolling_demand.mean()\n",
    "                branch_data[f'demand_std_{window}h'] = rolling_demand.std()\n",
    "                branch_data[f'demand_max_{window}h'] = rolling_demand.max()\n",
    "                branch_data[f'demand_min_{window}h'] = rolling_demand.min()\n",
    "            \n",
    "            # 4-3. 열수요 변화율 및 차분\n",
    "            branch_data['demand_diff_1h'] = branch_data['heat_demand'].diff()\n",
    "            branch_data['demand_diff_24h'] = branch_data['heat_demand'].diff(periods=24)\n",
    "            branch_data['demand_pct_change_1h'] = branch_data['heat_demand'].pct_change()\n",
    "            \n",
    "            # 4-4. 계절성 및 주기성 특성\n",
    "            # 같은 시간대 평균 대비 비율\n",
    "            hourly_avg = branch_data.groupby('hour')['heat_demand'].transform('mean')\n",
    "            branch_data['demand_vs_hourly_avg'] = branch_data['heat_demand'] / (hourly_avg + 1e-8)\n",
    "            \n",
    "            # 4-5. 효율성 지표\n",
    "            if 'HDD_18' in branch_data.columns:\n",
    "                branch_data['heating_efficiency'] = branch_data['heat_demand'] / (branch_data['HDD_18'] + 1e-8)\n",
    "            \n",
    "            if 'ta' in branch_data.columns:\n",
    "                branch_data['temp_sensitivity'] = branch_data['demand_diff_1h'] / (branch_data['ta_diff_1h'] + 1e-8)\n",
    "            \n",
    "            # 원본 데이터에 반영\n",
    "            new_cols = [col for col in branch_data.columns if col.startswith('demand_') or col in ['heating_efficiency', 'temp_sensitivity']]\n",
    "            df.loc[branch_mask, new_cols] = branch_data[new_cols]\n",
    "    \n",
    "    demand_cols = len([col for col in df.columns if col.startswith('demand_') or col in ['heating_efficiency', 'temp_sensitivity']])\n",
    "    print(f\"   ✅ 열수요 관련 파생변수 생성 완료! (총 {demand_cols}개)\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# 열수요 관련 파생변수 생성 실행\n",
    "train_df = create_heat_demand_features(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5️⃣ 상호작용 특성 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔗 상호작용 특성 생성 중...\n",
      "   ✅ 상호작용 특성 생성 완료! (총 16개)\n"
     ]
    }
   ],
   "source": [
    "def create_interaction_features(df):\n",
    "    \"\"\"\n",
    "    상호작용 특성을 생성합니다.\n",
    "    \"\"\"\n",
    "    print(\"🔗 상호작용 특성 생성 중...\")\n",
    "    df = df.copy()\n",
    "    \n",
    "    # 기온과 시간의 상호작용\n",
    "    if 'ta' in df.columns:\n",
    "        df['ta_hour_interaction'] = df['ta'] * df['hour']\n",
    "        df['ta_month_interaction'] = df['ta'] * df['month']\n",
    "        df['ta_weekend_interaction'] = df['ta'] * df['is_weekend']\n",
    "    \n",
    "    # HDD와 시간의 상호작용\n",
    "    if 'HDD_18' in df.columns:\n",
    "        df['hdd_hour_interaction'] = df['HDD_18'] * df['hour']\n",
    "        df['hdd_weekend_interaction'] = df['HDD_18'] * df['is_weekend']\n",
    "    \n",
    "    # 기온과 습도의 상호작용\n",
    "    if 'ta' in df.columns and 'hm' in df.columns:\n",
    "        df['ta_humidity_interaction'] = df['ta'] * df['hm']\n",
    "    \n",
    "    # 풍속과 기온의 상호작용\n",
    "    if 'ws' in df.columns and 'ta' in df.columns:\n",
    "        df['wind_temp_interaction'] = df['ws'] * df['ta']\n",
    "    \n",
    "    # 강수와 계절의 상호작용\n",
    "    if 'rn_day' in df.columns:\n",
    "        df['rain_season_interaction'] = df['rn_day'] * df['season']\n",
    "        df['rain_weekend_interaction'] = df['rn_day'] * df['is_weekend']\n",
    "    \n",
    "    # 지사별 상호작용 (상위 3개 지사만)\n",
    "    if 'branch_id' in df.columns and 'ta' in df.columns:\n",
    "        top_branches = df['branch_id'].value_counts().head(3).index.tolist()\n",
    "        for branch in top_branches:\n",
    "            branch_dummy = (df['branch_id'] == branch).astype(int)\n",
    "            df[f'branch_{branch}_temp'] = branch_dummy * df['ta']\n",
    "            if 'HDD_18' in df.columns:\n",
    "                df[f'branch_{branch}_hdd'] = branch_dummy * df['HDD_18']\n",
    "    \n",
    "    interaction_cols = [col for col in df.columns if 'interaction' in col or col.startswith('branch_')]\n",
    "    print(f\"   ✅ 상호작용 특성 생성 완료! (총 {len(interaction_cols)}개)\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# 상호작용 특성 생성 실행\n",
    "train_df = create_interaction_features(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6️⃣ 최종 전처리 및 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 최종 특성 준비 중...\n",
      "   🔧 결측치 최종 처리...\n",
      "   📝 특성 선택...\n",
      "   ✅ 총 114개 특성 선택\n",
      "   📋 범주형 변수: ['branch_id']\n",
      "   🔄 원핫 인코딩 수행...\n",
      "   ✅ 원핫 인코딩 완료: 3개 더미 변수 생성\n",
      "   📏 스케일링 수행...\n",
      "   🔧 무한값 및 극값 처리...\n",
      "   ✅ 스케일링 완료! 최종 데이터 형태: (52557, 117)\n"
     ]
    }
   ],
   "source": [
    "def prepare_final_features(df, target_col='heat_demand'):\n",
    "    \"\"\"\n",
    "    최종 특성 준비, 인코딩, 스케일링을 수행합니다.\n",
    "    \"\"\"\n",
    "    print(\"🎯 최종 특성 준비 중...\")\n",
    "    df = df.copy()\n",
    "    \n",
    "    # 6-1. 결측치 최종 처리\n",
    "    print(\"   🔧 결측치 최종 처리...\")\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    df[numeric_cols] = df[numeric_cols].fillna(method='ffill').fillna(method='bfill').fillna(0)\n",
    "    \n",
    "    # 6-2. 특성 선택\n",
    "    print(\"   📝 특성 선택...\")\n",
    "    \n",
    "    # 제외할 컬럼들\n",
    "    exclude_cols = ['tm', 'datetime', 'year']  # 기본 제외\n",
    "    if target_col in df.columns:\n",
    "        exclude_cols.append(target_col)  # 타겟 변수 제외\n",
    "    \n",
    "    # 사용할 특성 컬럼 선택\n",
    "    feature_cols = [col for col in df.columns if col not in exclude_cols]\n",
    "    \n",
    "    # 범주형 컬럼 식별\n",
    "    categorical_cols = []\n",
    "    if 'branch_id' in feature_cols:\n",
    "        categorical_cols.append('branch_id')\n",
    "    \n",
    "    print(f\"   ✅ 총 {len(feature_cols)}개 특성 선택\")\n",
    "    print(f\"   📋 범주형 변수: {categorical_cols}\")\n",
    "    \n",
    "    # 6-3. 원핫 인코딩\n",
    "    print(\"   🔄 원핫 인코딩 수행...\")\n",
    "    if categorical_cols:\n",
    "        df_encoded = pd.get_dummies(df[feature_cols + [target_col] if target_col in df.columns else feature_cols], \n",
    "                                  columns=categorical_cols, \n",
    "                                  prefix=categorical_cols)\n",
    "        print(f\"   ✅ 원핫 인코딩 완료: {df_encoded.shape[1] - len(df[feature_cols].columns)}개 더미 변수 생성\")\n",
    "    else:\n",
    "        df_encoded = df[feature_cols + [target_col] if target_col in df.columns else feature_cols].copy()\n",
    "    \n",
    "    # 6-4. 스케일링\n",
    "    print(\"   📏 스케일링 수행...\")\n",
    "    \n",
    "    if target_col in df_encoded.columns:\n",
    "        feature_cols_encoded = [col for col in df_encoded.columns if col != target_col]\n",
    "        X = df_encoded[feature_cols_encoded]\n",
    "        y = df_encoded[target_col]\n",
    "    else:\n",
    "        feature_cols_encoded = df_encoded.columns.tolist()\n",
    "        X = df_encoded\n",
    "        y = None\n",
    "    \n",
    "    # 무한값 및 극값 처리\n",
    "    print(\"   🔧 무한값 및 극값 처리...\")\n",
    "    \n",
    "    # 무한값을 NaN으로 변환\n",
    "    X = X.replace([np.inf, -np.inf], np.nan)\n",
    "    \n",
    "    # 극값 처리 (99.9% 분위수로 클리핑)\n",
    "    for col in X.columns:\n",
    "        if X[col].dtype in ['float64', 'float32', 'int64', 'int32']:\n",
    "            # 분위수 계산 (NaN 제외)\n",
    "            q99 = X[col].quantile(0.999)\n",
    "            q01 = X[col].quantile(0.001)\n",
    "            \n",
    "            # 극값 클리핑\n",
    "            X[col] = X[col].clip(lower=q01, upper=q99)\n",
    "    \n",
    "    # 남은 NaN 값 처리\n",
    "    X = X.fillna(X.median()).fillna(0)\n",
    "    \n",
    "    # 데이터 타입 확인 및 변환\n",
    "    X = X.astype(np.float64)\n",
    "    \n",
    "    # 최종 무한값 체크\n",
    "    if np.any(np.isinf(X.values)) or np.any(np.isnan(X.values)):\n",
    "        print(\"   ⚠️ 여전히 무한값/NaN이 존재합니다. 추가 처리 중...\")\n",
    "        # 남은 문제 컬럼 확인\n",
    "        remaining_inf_cols = X.columns[np.any(np.isinf(X.values), axis=0)]\n",
    "        remaining_nan_cols = X.columns[np.any(np.isnan(X.values), axis=0)]\n",
    "        if len(remaining_inf_cols) > 0:\n",
    "            print(f\"      - 남은 무한값 컬럼: {list(remaining_inf_cols)}\")\n",
    "        if len(remaining_nan_cols) > 0:\n",
    "            print(f\"      - 남은 NaN 컬럼: {list(remaining_nan_cols)}\")\n",
    "        X = X.replace([np.inf, -np.inf, np.nan], 0)\n",
    "    # MinMax 스케일링\n",
    "    scaler = MinMaxScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    X_scaled_df = pd.DataFrame(X_scaled, columns=feature_cols_encoded, index=X.index)\n",
    "    \n",
    "    if y is not None:\n",
    "        final_df = X_scaled_df.copy()\n",
    "        final_df[target_col] = y.values\n",
    "    else:\n",
    "        final_df = X_scaled_df.copy()\n",
    "    \n",
    "    print(f\"   ✅ 스케일링 완료! 최종 데이터 형태: {final_df.shape}\")\n",
    "    \n",
    "    return final_df, scaler, feature_cols_encoded\n",
    "\n",
    "# 최종 전처리 실행\n",
    "final_train_df, scaler, feature_columns = prepare_final_features(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7️⃣ 데이터 분할 (필요 시 진행)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 연도별 데이터 분할 중...\n",
      "   ✅ 데이터 분할 완료:\n",
      "      훈련 데이터: (21022, 117)\n",
      "      검증 데이터: (5255, 117)\n",
      "      테스트 데이터: (26280, 117)\n"
     ]
    }
   ],
   "source": [
    "def split_data_by_year(df, train_years=[2021], test_years=[2022], val_ratio=0.2):\n",
    "    \"\"\"\n",
    "    연도별로 데이터를 분할합니다.\n",
    "    \"\"\"\n",
    "    print(\"📊 연도별 데이터 분할 중...\")\n",
    "    \n",
    "    # 원본 데이터에서 연도 정보 가져오기\n",
    "    df_with_year = df.copy()\n",
    "    if 'year' not in df_with_year.columns and 'datetime' in train_df.columns:\n",
    "        df_with_year['year'] = train_df['datetime'].dt.year\n",
    "    elif 'year' not in df_with_year.columns and 'tm' in train_df.columns:\n",
    "        df_with_year['year'] = train_df['tm'].astype(str).str[:4].astype(int)\n",
    "    \n",
    "    # 훈련 데이터\n",
    "    train_mask = df_with_year['year'].isin(train_years)\n",
    "    train_data = df[train_mask].copy()\n",
    "    \n",
    "    # 테스트 데이터\n",
    "    test_mask = df_with_year['year'].isin(test_years)\n",
    "    test_data = df[test_mask].copy()\n",
    "    \n",
    "    # 검증 데이터 (훈련 데이터에서 시간순으로 분할)\n",
    "    if val_ratio > 0:\n",
    "        val_size = int(len(train_data) * val_ratio)\n",
    "        val_data = train_data.iloc[-val_size:].copy()\n",
    "        train_data = train_data.iloc[:-val_size].copy()\n",
    "    else:\n",
    "        val_data = None\n",
    "    \n",
    "    print(f\"   ✅ 데이터 분할 완료:\")\n",
    "    print(f\"      훈련 데이터: {train_data.shape}\")\n",
    "    if val_data is not None:\n",
    "        print(f\"      검증 데이터: {val_data.shape}\")\n",
    "    print(f\"      테스트 데이터: {test_data.shape}\")\n",
    "    \n",
    "    return train_data, val_data, test_data\n",
    "\n",
    "# 데이터 분할 실행\n",
    "train_data, val_data, test_data = split_data_by_year(final_train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8️⃣ 결과 요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎉 전처리 완료!\n",
      "\n",
      "📊 최종 데이터 정보:\n",
      "   훈련 데이터: (21022, 117)\n",
      "   테스트 데이터: (26280, 117)\n",
      "\n",
      "📈 생성된 특성:\n",
      "   시간 특성: 28개\n",
      "   기상 기본: 8개\n",
      "   기상 파생: 6개\n",
      "   Rolling 통계: 40개\n",
      "   Lag 변수: 13개\n",
      "   상호작용: 18개\n",
      "   열수요 관련: 27개\n",
      "\n",
      "💾 데이터 저장 준비 완료\n",
      "   - train_data: 모델 훈련용\n",
      "   - test_data: 최종 평가용\n",
      "   - scaler: 스케일러 객체 (예측시 역변환 필요)\n",
      "   - feature_columns: 특성 컬럼 리스트\n",
      "\n",
      "🚀 전처리 완료! 이제 모델링을 시작할 수 있습니다!\n"
     ]
    }
   ],
   "source": [
    "print(\"🎉 전처리 완료!\")\n",
    "print(f\"\\n📊 최종 데이터 정보:\")\n",
    "print(f\"   훈련 데이터: {train_data.shape}\")\n",
    "# if val_data is not None:\n",
    "#     print(f\"   검증 데이터: {val_data.shape}\")\n",
    "if test_data is not None:\n",
    "    print(f\"   테스트 데이터: {test_data.shape}\")\n",
    "\n",
    "print(f\"\\n📈 생성된 특성:\")\n",
    "feature_types = {\n",
    "    '시간 특성': [col for col in feature_columns if any(keyword in col for keyword in ['hour', 'month', 'day', 'week', 'season'])],\n",
    "    '기상 기본': [col for col in feature_columns if col in ['ta', 'wd', 'ws', 'rn_day', 'rn_hr1', 'hm', 'si', 'ta_chi']],\n",
    "    '기상 파생': [col for col in feature_columns if any(keyword in col for keyword in ['HDD', 'CDD', 'wind_chill', 'discomfort'])],\n",
    "    'Rolling 통계': [col for col in feature_columns if any(keyword in col for keyword in ['mean_', 'std_', 'max_', 'min_', 'sum_'])],\n",
    "    'Lag 변수': [col for col in feature_columns if 'lag_' in col],\n",
    "    '상호작용': [col for col in feature_columns if 'interaction' in col or col.startswith('branch_')],\n",
    "    '열수요 관련': [col for col in feature_columns if col.startswith('demand_')]\n",
    "}\n",
    "\n",
    "for feature_type, cols in feature_types.items():\n",
    "    if cols:\n",
    "        print(f\"   {feature_type}: {len(cols)}개\")\n",
    "\n",
    "print(f\"\\n💾 데이터 저장 준비 완료\")\n",
    "print(\"   - train_data: 모델 훈련용\")\n",
    "# print(\"   - val_data: 모델 검증용\") \n",
    "print(\"   - test_data: 최종 평가용\")\n",
    "print(\"   - scaler: 스케일러 객체 (예측시 역변환 필요)\")\n",
    "print(\"   - feature_columns: 특성 컬럼 리스트\")\n",
    "\n",
    "print(\"\\n🚀 전처리 완료! 이제 모델링을 시작할 수 있습니다!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리 파이프라인 실행 완료! 🎯\n"
     ]
    }
   ],
   "source": [
    "# 필요시 CSV 파일로 저장\n",
    "train_data.to_csv('processed_train_data.csv', index=False)\n",
    "if val_data is not None:\n",
    "    val_data.to_csv('processed_val_data.csv', index=False)\n",
    "if test_data is not None:\n",
    "    test_data.to_csv('processed_test_data.csv', index=False)\n",
    "\n",
    "\n",
    "print(\"전처리 파이프라인 실행 완료! 🎯\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용 예시: 간단한 모델 훈련\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# X_train = train_data.drop(columns=['heat_demand'])\n",
    "# y_train = train_data['heat_demand']\n",
    "# X_val = val_data.drop(columns=['heat_demand']) if val_data is not None else None\n",
    "# y_val = val_data['heat_demand'] if val_data is not None else None\n",
    "\n",
    "# model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "# model.fit(X_train, y_train)\n",
    "\n",
    "# if X_val is not None:\n",
    "#     y_pred = model.predict(X_val)\n",
    "#     rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "#     print(f\"Validation RMSE: {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 개선된 전처리 파이프라인 시작!\n",
      "============================================================\n",
      "\n",
      "1️⃣ 데이터 로드...\n",
      "📊 데이터 로드 중...\n",
      "✅ 훈련 데이터 로드 완료: (52557, 11)\n",
      "   컬럼: ['tm', 'branch_id', 'ta', 'wd', 'ws', 'rn_day', 'rn_hr1', 'hm', 'si', 'ta_chi', 'heat_demand']\n",
      "✅ 테스트 데이터 로드 완료: (26280, 11)\n",
      "\n",
      "2️⃣ 결측치 처리...\n",
      "🔧 결측치 처리 시작...\n",
      "   컬럼명 정리 완료: ['tm', 'branch_id', 'ta', 'wd', 'ws', 'rn_day', 'rn_hr1', 'hm', 'si', 'ta_chi', 'heat_demand']\n",
      "   🔄 -99 값을 NaN으로 변환 중...\n",
      "   ✅ 총 54449개의 -99 값을 NaN으로 변환\n",
      "   ☀️ 일사량(si) 특별 처리 중...\n",
      "   ✅ 야간시간대 일사량 23796개를 0으로 처리\n",
      "   📈 지사별 선형보간 처리 중...\n",
      "   ✅ 선형보간 완료\n",
      "   🎉 모든 결측치 처리 완료!\n",
      "\n",
      "3️⃣ 기상 시계열 파생변수 생성...\n",
      "🌡️ 기상 시계열 파생변수 생성 중...\n",
      "   📅 시간 기본 변수 생성...\n",
      "   🔄 계절성 순환 변수 생성...\n",
      "🔥 난방 관련 시간 변수 생성...\n",
      "   ✅ 난방 관련 시간 변수 생성 완료\n",
      "🌤️ 기상 파생변수 생성...\n",
      "   ✅ 기상 파생변수 생성 완료\n",
      "\n",
      "4️⃣ Rolling 통계 및 지연 변수 생성...\n",
      "📊 Rolling 통계 및 지연 변수 생성...\n",
      "   ✅ Rolling 통계 및 지연 변수 생성 완료! (총 32개)\n",
      "\n",
      "5️⃣ 열수요 관련 파생변수 생성...\n",
      "🔥 열수요 관련 파생변수 생성 중...\n",
      "   ✅ 열수요 관련 파생변수 생성 완료! (총 29개)\n",
      "\n",
      "6️⃣ 상호작용 특성 생성...\n",
      "🔗 상호작용 특성 생성 중...\n",
      "   ✅ 상호작용 특성 생성 완료! (총 16개)\n",
      "\n",
      "7️⃣ 최종 전처리 및 인코딩...\n",
      "🎯 최종 특성 준비 중...\n",
      "   🔧 결측치 최종 처리...\n",
      "   📝 특성 선택...\n",
      "   ✅ 총 114개 특성 선택\n",
      "   📋 범주형 변수: ['branch_id']\n",
      "   🔄 원핫 인코딩 수행...\n",
      "   ✅ 원핫 인코딩 완료: 3개 더미 변수 생성\n",
      "   📏 스케일링 수행...\n",
      "   🔧 무한값 및 극값 처리...\n",
      "   ✅ 스케일링 완료! 최종 데이터 형태: (52557, 117)\n",
      "\n",
      "🎉 개선된 전처리 완료!\n",
      "최종 데이터 형태: (52557, 117)\n",
      "특성 개수: 116\n",
      "무한값: 0개, NaN: 0개\n",
      "✅ 무한값/NaN 문제 해결 완료!\n"
     ]
    }
   ],
   "source": [
    "# 🔧 개선된 전처리 파이프라인 실행\n",
    "print(\"🚀 개선된 전처리 파이프라인 시작!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1. 데이터 로드\n",
    "print(\"\\n1️⃣ 데이터 로드...\")\n",
    "train_df_new, test_df_new = load_data('train_heat_ABD.csv', 'test_heat_ABD.csv')\n",
    "\n",
    "# 2. 결측치 처리\n",
    "print(\"\\n2️⃣ 결측치 처리...\")\n",
    "train_df_new = handle_missing_values(train_df_new)\n",
    "\n",
    "# 3. 기상 시계열 파생변수 생성\n",
    "print(\"\\n3️⃣ 기상 시계열 파생변수 생성...\")\n",
    "train_df_new = create_weather_time_features(train_df_new)\n",
    "train_df_new = create_heating_related_features(train_df_new)\n",
    "train_df_new = create_weather_derived_features(train_df_new)\n",
    "\n",
    "# 4. Rolling 통계 및 지연 변수 생성 (개선된 버전)\n",
    "print(\"\\n4️⃣ Rolling 통계 및 지연 변수 생성...\")\n",
    "train_df_new = create_rolling_and_lag_features(train_df_new)\n",
    "\n",
    "# 5. 열수요 관련 파생변수 생성 (개선된 버전)\n",
    "print(\"\\n5️⃣ 열수요 관련 파생변수 생성...\")\n",
    "train_df_new = create_heat_demand_features(train_df_new)\n",
    "\n",
    "# 6. 상호작용 특성 생성\n",
    "print(\"\\n6️⃣ 상호작용 특성 생성...\")\n",
    "train_df_new = create_interaction_features(train_df_new)\n",
    "\n",
    "# 7. 최종 전처리 및 인코딩\n",
    "print(\"\\n7️⃣ 최종 전처리 및 인코딩...\")\n",
    "final_train_df_new, scaler_new, feature_columns_new = prepare_final_features(train_df_new)\n",
    "\n",
    "print(\"\\n🎉 개선된 전처리 완료!\")\n",
    "print(f\"최종 데이터 형태: {final_train_df_new.shape}\")\n",
    "print(f\"특성 개수: {len(feature_columns_new)}\")\n",
    "\n",
    "# 무한값 최종 체크\n",
    "inf_check = np.isinf(final_train_df_new.select_dtypes(include=[np.number]).values).sum()\n",
    "nan_check = np.isnan(final_train_df_new.select_dtypes(include=[np.number]).values).sum()\n",
    "print(f\"무한값: {inf_check}개, NaN: {nan_check}개\")\n",
    "\n",
    "if inf_check == 0 and nan_check == 0:\n",
    "    print(\"✅ 무한값/NaN 문제 해결 완료!\")\n",
    "else:\n",
    "    print(\"⚠️ 여전히 문제가 있습니다.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### (추가) 🚨 무한값 발생 원인 및 해결책 정리\n",
    "\n",
    "### 📋 **주요 원인들**\n",
    "\n",
    "#### 1️⃣ **0으로 나누기 연산**\n",
    "```python\n",
    "# 🔥 문제가 되었던 코드들:\n",
    "branch_data['demand_pct_change_1h'] = branch_data['heat_demand'].pct_change()\n",
    "branch_data['demand_vs_hourly_avg'] = branch_data['heat_demand'] / (hourly_avg + 1e-8)\n",
    "branch_data['heating_efficiency'] = branch_data['heat_demand'] / (branch_data['HDD_18'] + 1e-8)\n",
    "branch_data['temp_sensitivity'] = branch_data['demand_diff_1h'] / (branch_data['ta_diff_1h'] + 1e-8)\n",
    "```\n",
    "\n",
    "#### 2️⃣ **구체적인 문제 상황들**\n",
    "- **`pct_change()` 함수**: 이전 값이 0일 때 무한값 생성\n",
    "- **HDD_18이 0인 경우**: 여름철에 난방도일이 0이 되어 나눗셈에서 문제\n",
    "- **기온 차분이 0인 경우**: 연속된 시간에 기온이 동일할 때 0으로 나누기\n",
    "- **시간대별 평균이 0인 경우**: 특정 시간대에 열수요가 0일 때 문제\n",
    "- **Rolling 표준편차**: 단일 값으로만 구성된 윈도우에서 std() = 0\n",
    "\n",
    "### ✅ **적용된 해결책들**\n",
    "\n",
    "#### 1️⃣ **안전한 나눗셈 처리**\n",
    "```python\n",
    "# 기존: 위험한 방식\n",
    "value / (denominator + 1e-8)\n",
    "\n",
    "# 개선: 안전한 방식\n",
    "safe_denominator = np.where(np.abs(denominator) < 1e-6, 1e-6, denominator)\n",
    "result = value / safe_denominator\n",
    "result = np.clip(result, min_value, max_value)  # 극값 클리핑\n",
    "```\n",
    "\n",
    "#### 2️⃣ **퍼센트 변화율 안전 계산**\n",
    "```python\n",
    "# 기존: pct_change() 직접 사용\n",
    "branch_data['demand_pct_change_1h'] = branch_data['heat_demand'].pct_change()\n",
    "\n",
    "# 개선: 수동으로 안전하게 계산\n",
    "prev_demand = branch_data['heat_demand'].shift(1)\n",
    "demand_change = branch_data['heat_demand'] - prev_demand\n",
    "safe_prev_demand = np.where(np.abs(prev_demand) < 1e-6, 1e-6, prev_demand)\n",
    "branch_data['demand_pct_change_1h'] = np.clip(demand_change / safe_prev_demand, -10, 10)\n",
    "```\n",
    "\n",
    "#### 3️⃣ **Rolling 통계 NaN 처리**\n",
    "```python\n",
    "# 표준편차가 NaN일 수 있는 경우 처리\n",
    "branch_data[f'ta_std_{window}h'] = rolling_ta.std().fillna(0)\n",
    "```\n",
    "\n",
    "#### 4️⃣ **단계별 무한값 체크 및 처리**\n",
    "```python\n",
    "# 각 단계마다 무한값 체크\n",
    "for col in branch_data.columns:\n",
    "    if branch_data[col].dtype in ['float64', 'float32']:\n",
    "        branch_data[col] = branch_data[col].replace([np.inf, -np.inf], np.nan)\n",
    "        branch_data[col] = branch_data[col].fillna(0)  # 또는 적절한 대체값\n",
    "```\n",
    "\n",
    "### 🎯 **핵심 교훈**\n",
    "\n",
    "1. **1e-8 같은 작은 값 더하기는 완전한 해결책이 아님**\n",
    "2. **`np.where()`를 사용한 조건부 처리가 더 안전**\n",
    "3. **극값 클리핑으로 현실적인 범위 유지**\n",
    "4. **각 단계마다 무한값/NaN 체크 필요**\n",
    "5. **pandas의 `pct_change()` 같은 함수도 주의 필요**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
