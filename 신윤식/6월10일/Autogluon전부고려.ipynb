{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyaBWhE9SPaQ",
        "outputId": "23ec23b6-23c5-4597-861c-90520d2348b2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install autogluon"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MtTrfI3CU-Va",
        "outputId": "e0aa8828-9bb8-49e3-c5a2-62d6d9a77101"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting autogluon\n",
            "  Downloading autogluon-1.3.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting autogluon.core==1.3.1 (from autogluon.core[all]==1.3.1->autogluon)\n",
            "  Downloading autogluon.core-1.3.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting autogluon.features==1.3.1 (from autogluon)\n",
            "  Downloading autogluon.features-1.3.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting autogluon.tabular==1.3.1 (from autogluon.tabular[all]==1.3.1->autogluon)\n",
            "  Downloading autogluon.tabular-1.3.1-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting autogluon.multimodal==1.3.1 (from autogluon)\n",
            "  Downloading autogluon.multimodal-1.3.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting autogluon.timeseries==1.3.1 (from autogluon.timeseries[all]==1.3.1->autogluon)\n",
            "  Downloading autogluon.timeseries-1.3.1-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: numpy<2.3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon) (2.0.2)\n",
            "Requirement already satisfied: scipy<1.16,>=1.5.4 in /usr/local/lib/python3.11/dist-packages (from autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon) (1.15.3)\n",
            "Requirement already satisfied: scikit-learn<1.7.0,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon) (1.6.1)\n",
            "Requirement already satisfied: networkx<4,>=3.0 in /usr/local/lib/python3.11/dist-packages (from autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon) (3.5)\n",
            "Requirement already satisfied: pandas<2.3.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon) (2.2.2)\n",
            "Requirement already satisfied: tqdm<5,>=4.38 in /usr/local/lib/python3.11/dist-packages (from autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon) (2.32.3)\n",
            "Requirement already satisfied: matplotlib<3.11,>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon) (3.10.0)\n",
            "Collecting boto3<2,>=1.10 (from autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon)\n",
            "  Downloading boto3-1.38.33-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting autogluon.common==1.3.1 (from autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon)\n",
            "  Downloading autogluon.common-1.3.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting ray<2.45,>=2.10.0 (from ray[default]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.3.1->autogluon)\n",
            "  Downloading ray-2.44.1-cp311-cp311-manylinux2014_x86_64.whl.metadata (19 kB)\n",
            "Requirement already satisfied: hyperopt<0.2.8,>=0.2.7 in /usr/local/lib/python3.11/dist-packages (from autogluon.core[all]==1.3.1->autogluon) (0.2.7)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from autogluon.core[all]==1.3.1->autogluon) (18.1.0)\n",
            "Requirement already satisfied: Pillow<12,>=10.0.1 in /usr/local/lib/python3.11/dist-packages (from autogluon.multimodal==1.3.1->autogluon) (11.2.1)\n",
            "Requirement already satisfied: torch<2.7,>=2.2 in /usr/local/lib/python3.11/dist-packages (from autogluon.multimodal==1.3.1->autogluon) (2.6.0+cu124)\n",
            "Collecting lightning<2.7,>=2.2 (from autogluon.multimodal==1.3.1->autogluon)\n",
            "  Downloading lightning-2.5.1.post0-py3-none-any.whl.metadata (39 kB)\n",
            "Collecting transformers<4.50,>=4.38.0 (from transformers[sentencepiece]<4.50,>=4.38.0->autogluon.multimodal==1.3.1->autogluon)\n",
            "  Downloading transformers-4.49.0-py3-none-any.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: accelerate<2.0,>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from autogluon.multimodal==1.3.1->autogluon) (1.7.0)\n",
            "Collecting jsonschema<4.24,>=4.18 (from autogluon.multimodal==1.3.1->autogluon)\n",
            "  Downloading jsonschema-4.23.0-py3-none-any.whl.metadata (7.9 kB)\n",
            "Collecting seqeval<1.3.0,>=1.2.2 (from autogluon.multimodal==1.3.1->autogluon)\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting evaluate<0.5.0,>=0.4.0 (from autogluon.multimodal==1.3.1->autogluon)\n",
            "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting timm<1.0.7,>=0.9.5 (from autogluon.multimodal==1.3.1->autogluon)\n",
            "  Downloading timm-1.0.3-py3-none-any.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchvision<0.22.0,>=0.16.0 in /usr/local/lib/python3.11/dist-packages (from autogluon.multimodal==1.3.1->autogluon) (0.21.0+cu124)\n",
            "Requirement already satisfied: scikit-image<0.26.0,>=0.19.1 in /usr/local/lib/python3.11/dist-packages (from autogluon.multimodal==1.3.1->autogluon) (0.25.2)\n",
            "Requirement already satisfied: text-unidecode<1.4,>=1.3 in /usr/local/lib/python3.11/dist-packages (from autogluon.multimodal==1.3.1->autogluon) (1.3)\n",
            "Collecting torchmetrics<1.8,>=1.2.0 (from autogluon.multimodal==1.3.1->autogluon)\n",
            "  Downloading torchmetrics-1.7.2-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: omegaconf<2.4.0,>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from autogluon.multimodal==1.3.1->autogluon) (2.3.0)\n",
            "Collecting pytorch-metric-learning<2.9,>=1.3.0 (from autogluon.multimodal==1.3.1->autogluon)\n",
            "  Downloading pytorch_metric_learning-2.8.1-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting nlpaug<1.2.0,>=1.1.10 (from autogluon.multimodal==1.3.1->autogluon)\n",
            "  Downloading nlpaug-1.1.11-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting nltk<3.9,>=3.4.5 (from autogluon.multimodal==1.3.1->autogluon)\n",
            "  Downloading nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting openmim<0.4.0,>=0.3.7 (from autogluon.multimodal==1.3.1->autogluon)\n",
            "  Downloading openmim-0.3.9-py2.py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: defusedxml<0.7.2,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from autogluon.multimodal==1.3.1->autogluon) (0.7.1)\n",
            "Requirement already satisfied: jinja2<3.2,>=3.0.3 in /usr/local/lib/python3.11/dist-packages (from autogluon.multimodal==1.3.1->autogluon) (3.1.6)\n",
            "Requirement already satisfied: tensorboard<3,>=2.9 in /usr/local/lib/python3.11/dist-packages (from autogluon.multimodal==1.3.1->autogluon) (2.18.0)\n",
            "Collecting pytesseract<0.4,>=0.3.9 (from autogluon.multimodal==1.3.1->autogluon)\n",
            "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting nvidia-ml-py3<8.0,>=7.352.0 (from autogluon.multimodal==1.3.1->autogluon)\n",
            "  Downloading nvidia-ml-py3-7.352.0.tar.gz (19 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pdf2image<1.19,>=1.17.0 (from autogluon.multimodal==1.3.1->autogluon)\n",
            "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting catboost<1.3,>=1.2 (from autogluon.tabular[all]==1.3.1->autogluon)\n",
            "  Downloading catboost-1.2.8-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: einops<0.9,>=0.7 in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular[all]==1.3.1->autogluon) (0.8.1)\n",
            "Requirement already satisfied: xgboost<3.1,>=2.0 in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular[all]==1.3.1->autogluon) (2.1.4)\n",
            "Requirement already satisfied: fastai<2.9,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular[all]==1.3.1->autogluon) (2.7.19)\n",
            "Requirement already satisfied: huggingface-hub[torch] in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular[all]==1.3.1->autogluon) (0.32.4)\n",
            "Requirement already satisfied: lightgbm<4.7,>=4.0 in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular[all]==1.3.1->autogluon) (4.5.0)\n",
            "Requirement already satisfied: spacy<3.9 in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular[all]==1.3.1->autogluon) (3.8.7)\n",
            "Requirement already satisfied: joblib<2,>=1.1 in /usr/local/lib/python3.11/dist-packages (from autogluon.timeseries==1.3.1->autogluon.timeseries[all]==1.3.1->autogluon) (1.5.1)\n",
            "Collecting pytorch-lightning (from autogluon.timeseries==1.3.1->autogluon.timeseries[all]==1.3.1->autogluon)\n",
            "  Downloading pytorch_lightning-2.5.1.post0-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting gluonts<0.17,>=0.15.0 (from autogluon.timeseries==1.3.1->autogluon.timeseries[all]==1.3.1->autogluon)\n",
            "  Downloading gluonts-0.16.1-py3-none-any.whl.metadata (9.8 kB)\n",
            "Collecting statsforecast<2.0.2,>=1.7.0 (from autogluon.timeseries==1.3.1->autogluon.timeseries[all]==1.3.1->autogluon)\n",
            "  Downloading statsforecast-2.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (29 kB)\n",
            "Collecting mlforecast<0.14,>0.13 (from autogluon.timeseries==1.3.1->autogluon.timeseries[all]==1.3.1->autogluon)\n",
            "  Downloading mlforecast-0.13.6-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting utilsforecast<0.2.11,>=0.2.3 (from autogluon.timeseries==1.3.1->autogluon.timeseries[all]==1.3.1->autogluon)\n",
            "  Downloading utilsforecast-0.2.10-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting coreforecast<0.0.16,>=0.0.12 (from autogluon.timeseries==1.3.1->autogluon.timeseries[all]==1.3.1->autogluon)\n",
            "  Downloading coreforecast-0.0.15-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Collecting fugue>=0.9.0 (from autogluon.timeseries==1.3.1->autogluon.timeseries[all]==1.3.1->autogluon)\n",
            "  Downloading fugue-0.9.1-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: orjson~=3.9 in /usr/local/lib/python3.11/dist-packages (from autogluon.timeseries==1.3.1->autogluon.timeseries[all]==1.3.1->autogluon) (3.10.18)\n",
            "Requirement already satisfied: psutil<7.1.0,>=5.7.3 in /usr/local/lib/python3.11/dist-packages (from autogluon.common==1.3.1->autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon) (5.9.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate<2.0,>=0.34.0->autogluon.multimodal==1.3.1->autogluon) (24.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate<2.0,>=0.34.0->autogluon.multimodal==1.3.1->autogluon) (6.0.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate<2.0,>=0.34.0->autogluon.multimodal==1.3.1->autogluon) (0.5.3)\n",
            "Collecting botocore<1.39.0,>=1.38.33 (from boto3<2,>=1.10->autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon)\n",
            "  Downloading botocore-1.38.33-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3<2,>=1.10->autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.14.0,>=0.13.0 (from boto3<2,>=1.10->autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon)\n",
            "  Downloading s3transfer-0.13.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from catboost<1.3,>=1.2->autogluon.tabular[all]==1.3.1->autogluon) (0.20.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from catboost<1.3,>=1.2->autogluon.tabular[all]==1.3.1->autogluon) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from catboost<1.3,>=1.2->autogluon.tabular[all]==1.3.1->autogluon) (1.17.0)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.3.1->autogluon) (2.14.4)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.3.1->autogluon) (0.3.7)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.3.1->autogluon) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.3.1->autogluon) (0.70.15)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.3.1->autogluon) (2025.3.2)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (from fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.3.1->autogluon) (24.1.2)\n",
            "Requirement already satisfied: fastdownload<2,>=0.0.5 in /usr/local/lib/python3.11/dist-packages (from fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.3.1->autogluon) (0.0.7)\n",
            "Requirement already satisfied: fastcore<1.8,>=1.5.29 in /usr/local/lib/python3.11/dist-packages (from fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.3.1->autogluon) (1.7.29)\n",
            "Requirement already satisfied: fastprogress>=0.2.4 in /usr/local/lib/python3.11/dist-packages (from fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.3.1->autogluon) (1.0.3)\n",
            "Collecting triad>=0.9.7 (from fugue>=0.9.0->autogluon.timeseries==1.3.1->autogluon.timeseries[all]==1.3.1->autogluon)\n",
            "  Downloading triad-0.9.8-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting adagio>=0.2.4 (from fugue>=0.9.0->autogluon.timeseries==1.3.1->autogluon.timeseries[all]==1.3.1->autogluon)\n",
            "  Downloading adagio-0.2.6-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.7 in /usr/local/lib/python3.11/dist-packages (from gluonts<0.17,>=0.15.0->autogluon.timeseries==1.3.1->autogluon.timeseries[all]==1.3.1->autogluon) (2.11.5)\n",
            "Requirement already satisfied: toolz~=0.10 in /usr/local/lib/python3.11/dist-packages (from gluonts<0.17,>=0.15.0->autogluon.timeseries==1.3.1->autogluon.timeseries[all]==1.3.1->autogluon) (0.12.1)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gluonts<0.17,>=0.15.0->autogluon.timeseries==1.3.1->autogluon.timeseries[all]==1.3.1->autogluon) (4.14.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.3.1->autogluon) (1.0.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.3.1->autogluon) (3.1.1)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.11/dist-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.3.1->autogluon) (0.10.9.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2<3.2,>=3.0.3->autogluon.multimodal==1.3.1->autogluon) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema<4.24,>=4.18->autogluon.multimodal==1.3.1->autogluon) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema<4.24,>=4.18->autogluon.multimodal==1.3.1->autogluon) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema<4.24,>=4.18->autogluon.multimodal==1.3.1->autogluon) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema<4.24,>=4.18->autogluon.multimodal==1.3.1->autogluon) (0.25.1)\n",
            "Collecting lightning-utilities<2.0,>=0.10.0 (from lightning<2.7,>=2.2->autogluon.multimodal==1.3.1->autogluon)\n",
            "  Downloading lightning_utilities-0.14.3-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon) (4.58.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon) (2.9.0.post0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from mlforecast<0.14,>0.13->autogluon.timeseries==1.3.1->autogluon.timeseries[all]==1.3.1->autogluon) (0.60.0)\n",
            "Collecting optuna (from mlforecast<0.14,>0.13->autogluon.timeseries==1.3.1->autogluon.timeseries[all]==1.3.1->autogluon)\n",
            "  Downloading optuna-4.3.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting window-ops (from mlforecast<0.14,>0.13->autogluon.timeseries==1.3.1->autogluon.timeseries[all]==1.3.1->autogluon)\n",
            "  Downloading window_ops-0.0.15-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: gdown>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.3.1->autogluon) (5.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk<3.9,>=3.4.5->autogluon.multimodal==1.3.1->autogluon) (8.2.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk<3.9,>=3.4.5->autogluon.multimodal==1.3.1->autogluon) (2024.11.6)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from omegaconf<2.4.0,>=2.1.1->autogluon.multimodal==1.3.1->autogluon) (4.9.3)\n",
            "Collecting colorama (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.3.1->autogluon)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Collecting model-index (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.3.1->autogluon)\n",
            "  Downloading model_index-0.1.11-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting opendatalab (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.3.1->autogluon)\n",
            "  Downloading opendatalab-0.0.10-py3-none-any.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.3.1->autogluon) (13.9.4)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.3.1->autogluon) (0.9.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<2.3.0,>=2.0.0->autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<2.3.0,>=2.0.0->autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon) (2025.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from ray<2.45,>=2.10.0->ray[default]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.3.1->autogluon) (3.18.0)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ray<2.45,>=2.10.0->ray[default]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.3.1->autogluon) (1.1.0)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.11/dist-packages (from ray<2.45,>=2.10.0->ray[default]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.3.1->autogluon) (5.29.5)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.11/dist-packages (from ray<2.45,>=2.10.0->ray[default]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.3.1->autogluon) (1.3.2)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.11/dist-packages (from ray<2.45,>=2.10.0->ray[default]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.3.1->autogluon) (1.6.0)\n",
            "Requirement already satisfied: aiohttp>=3.7 in /usr/local/lib/python3.11/dist-packages (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.3.1->autogluon) (3.11.15)\n",
            "Collecting aiohttp_cors (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.3.1->autogluon)\n",
            "  Downloading aiohttp_cors-0.8.1-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting colorful (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.3.1->autogluon)\n",
            "  Downloading colorful-0.5.6-py2.py3-none-any.whl.metadata (16 kB)\n",
            "Collecting py-spy>=0.2.0 (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.3.1->autogluon)\n",
            "  Downloading py_spy-0.4.0-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: grpcio>=1.42.0 in /usr/local/lib/python3.11/dist-packages (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.3.1->autogluon) (1.72.1)\n",
            "Collecting opencensus (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.3.1->autogluon)\n",
            "  Downloading opencensus-0.11.4-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: prometheus_client>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.3.1->autogluon) (0.22.1)\n",
            "Requirement already satisfied: smart_open in /usr/local/lib/python3.11/dist-packages (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.3.1->autogluon) (7.1.0)\n",
            "Collecting virtualenv!=20.21.1,>=20.0.24 (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.3.1->autogluon)\n",
            "  Downloading virtualenv-20.31.2-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting tensorboardX>=1.9 (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.3.1->autogluon)\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon) (2025.4.26)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image<0.26.0,>=0.19.1->autogluon.multimodal==1.3.1->autogluon) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image<0.26.0,>=0.19.1->autogluon.multimodal==1.3.1->autogluon) (2025.6.1)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image<0.26.0,>=0.19.1->autogluon.multimodal==1.3.1->autogluon) (0.4)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<1.7.0,>=1.4.0->autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon) (3.6.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.3.1->autogluon) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.3.1->autogluon) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.3.1->autogluon) (1.0.13)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.3.1->autogluon) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.3.1->autogluon) (3.0.10)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.3.1->autogluon) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.3.1->autogluon) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.3.1->autogluon) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.3.1->autogluon) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.3.1->autogluon) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.3.1->autogluon) (0.16.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.3.1->autogluon) (75.2.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.3.1->autogluon) (3.5.0)\n",
            "Requirement already satisfied: statsmodels>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from statsforecast<2.0.2,>=1.7.0->autogluon.timeseries==1.3.1->autogluon.timeseries[all]==1.3.1->autogluon) (0.14.4)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.3.1->autogluon) (1.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.3.1->autogluon) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.3.1->autogluon) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.3.1->autogluon) (3.1.3)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<2.7,>=2.2->autogluon.multimodal==1.3.1->autogluon)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<2.7,>=2.2->autogluon.multimodal==1.3.1->autogluon)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<2.7,>=2.2->autogluon.multimodal==1.3.1->autogluon)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<2.7,>=2.2->autogluon.multimodal==1.3.1->autogluon)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<2.7,>=2.2->autogluon.multimodal==1.3.1->autogluon)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<2.7,>=2.2->autogluon.multimodal==1.3.1->autogluon)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<2.7,>=2.2->autogluon.multimodal==1.3.1->autogluon)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<2.7,>=2.2->autogluon.multimodal==1.3.1->autogluon)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<2.7,>=2.2->autogluon.multimodal==1.3.1->autogluon)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<2.7,>=2.2->autogluon.multimodal==1.3.1->autogluon) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<2.7,>=2.2->autogluon.multimodal==1.3.1->autogluon) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<2.7,>=2.2->autogluon.multimodal==1.3.1->autogluon) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<2.7,>=2.2->autogluon.multimodal==1.3.1->autogluon)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<2.7,>=2.2->autogluon.multimodal==1.3.1->autogluon) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<2.7,>=2.2->autogluon.multimodal==1.3.1->autogluon) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<2.7,>=2.2->autogluon.multimodal==1.3.1->autogluon) (1.3.0)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<4.50,>=4.38.0->transformers[sentencepiece]<4.50,>=4.38.0->autogluon.multimodal==1.3.1->autogluon) (0.21.1)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /usr/local/lib/python3.11/dist-packages (from transformers[sentencepiece]<4.50,>=4.38.0->autogluon.multimodal==1.3.1->autogluon) (0.2.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub[torch]; extra == \"all\"->autogluon.tabular[all]==1.3.1->autogluon) (1.1.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.7->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.3.1->autogluon) (2.6.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.7->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.3.1->autogluon) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.7->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.3.1->autogluon) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.7->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.3.1->autogluon) (1.20.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.3.1->autogluon) (4.13.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.9->autogluon.tabular[all]==1.3.1->autogluon) (1.3.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->mlforecast<0.14,>0.13->autogluon.timeseries==1.3.1->autogluon.timeseries[all]==1.3.1->autogluon) (0.43.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.7->gluonts<0.17,>=0.15.0->autogluon.timeseries==1.3.1->autogluon.timeseries[all]==1.3.1->autogluon) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.7->gluonts<0.17,>=0.15.0->autogluon.timeseries==1.3.1->autogluon.timeseries[all]==1.3.1->autogluon) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.7->gluonts<0.17,>=0.15.0->autogluon.timeseries==1.3.1->autogluon.timeseries[all]==1.3.1->autogluon) (0.4.1)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.11/dist-packages (from statsmodels>=0.13.2->statsforecast<2.0.2,>=1.7.0->autogluon.timeseries==1.3.1->autogluon.timeseries[all]==1.3.1->autogluon) (1.0.1)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy<3.9->autogluon.tabular[all]==1.3.1->autogluon) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy<3.9->autogluon.tabular[all]==1.3.1->autogluon) (0.1.5)\n",
            "Collecting fs (from triad>=0.9.7->fugue>=0.9.0->autogluon.timeseries==1.3.1->autogluon.timeseries[all]==1.3.1->autogluon)\n",
            "  Downloading fs-2.4.16-py2.py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.9->autogluon.tabular[all]==1.3.1->autogluon) (1.5.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.3.1->autogluon) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.3.1->autogluon) (2.19.1)\n",
            "Collecting distlib<1,>=0.3.7 (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.3.1->autogluon)\n",
            "  Downloading distlib-0.3.9-py2.py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: platformdirs<5,>=3.9.1 in /usr/local/lib/python3.11/dist-packages (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.3.1->autogluon) (4.3.8)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.9->autogluon.tabular[all]==1.3.1->autogluon) (0.21.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart_open->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.3.1->autogluon) (1.17.2)\n",
            "Collecting ordered-set (from model-index->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.3.1->autogluon)\n",
            "  Downloading ordered_set-4.1.0-py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting opencensus-context>=0.1.3 (from opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.3.1->autogluon)\n",
            "  Downloading opencensus_context-0.1.3-py2.py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.3.1->autogluon) (2.25.0)\n",
            "Collecting pycryptodome (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.3.1->autogluon)\n",
            "  Downloading pycryptodome-3.23.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Collecting openxlab (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.3.1->autogluon)\n",
            "  Downloading openxlab-0.1.2-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna->mlforecast<0.14,>0.13->autogluon.timeseries==1.3.1->autogluon.timeseries[all]==1.3.1->autogluon)\n",
            "  Downloading alembic-1.16.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting colorlog (from optuna->mlforecast<0.14,>0.13->autogluon.timeseries==1.3.1->autogluon.timeseries[all]==1.3.1->autogluon)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna->mlforecast<0.14,>0.13->autogluon.timeseries==1.3.1->autogluon.timeseries[all]==1.3.1->autogluon) (2.0.41)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->catboost<1.3,>=1.2->autogluon.tabular[all]==1.3.1->autogluon) (9.1.2)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna->mlforecast<0.14,>0.13->autogluon.timeseries==1.3.1->autogluon.timeseries[all]==1.3.1->autogluon) (1.1.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.3.1->autogluon) (1.70.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.3.1->autogluon) (1.26.1)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.3.1->autogluon) (2.38.0)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.9->autogluon.tabular[all]==1.3.1->autogluon) (1.2.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.3.1->autogluon) (0.1.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna->mlforecast<0.14,>0.13->autogluon.timeseries==1.3.1->autogluon.timeseries[all]==1.3.1->autogluon) (3.2.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.3.1->autogluon) (2.7)\n",
            "Collecting appdirs~=1.4.3 (from fs->triad>=0.9.7->fugue>=0.9.0->autogluon.timeseries==1.3.1->autogluon.timeseries[all]==1.3.1->autogluon)\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting filelock (from ray<2.45,>=2.10.0->ray[default]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.3.1->autogluon)\n",
            "  Downloading filelock-3.14.0-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting oss2~=2.17.0 (from openxlab->opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.3.1->autogluon)\n",
            "  Downloading oss2-2.17.0.tar.gz (259 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.5/259.5 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pytz>=2020.1 (from pandas<2.3.0,>=2.0.0->autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon)\n",
            "  Downloading pytz-2023.4-py2.py3-none-any.whl.metadata (22 kB)\n",
            "INFO: pip is looking at multiple versions of openxlab to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting openxlab (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.3.1->autogluon)\n",
            "  Downloading openxlab-0.1.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.38-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.37-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.36-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.35-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.34-py3-none-any.whl.metadata (3.8 kB)\n",
            "INFO: pip is still looking at multiple versions of openxlab to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading openxlab-0.0.33-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.32-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.31-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.30-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.29-py3-none-any.whl.metadata (3.8 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading openxlab-0.0.28-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.27-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.26-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.25-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.24-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.23-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.22-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.21-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.20-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.19-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.18-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.17-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.16-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.15-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.14-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.13-py3-none-any.whl.metadata (4.5 kB)\n",
            "  Downloading openxlab-0.0.12-py3-none-any.whl.metadata (4.5 kB)\n",
            "  Downloading openxlab-0.0.11-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.3.1->autogluon) (1.7.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.3.1->autogluon) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.3.1->autogluon) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.3.1->autogluon) (4.9.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.3.1->autogluon) (0.6.1)\n",
            "Downloading autogluon-1.3.1-py3-none-any.whl (9.8 kB)\n",
            "Downloading autogluon.core-1.3.1-py3-none-any.whl (222 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m222.7/222.7 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autogluon.features-1.3.1-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autogluon.multimodal-1.3.1-py3-none-any.whl (454 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.5/454.5 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autogluon.tabular-1.3.1-py3-none-any.whl (382 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m382.4/382.4 kB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autogluon.timeseries-1.3.1-py3-none-any.whl (181 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.3/181.3 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autogluon.common-1.3.1-py3-none-any.whl (69 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/69.1 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading boto3-1.38.33-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.9/139.9 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading catboost-1.2.8-cp311-cp311-manylinux2014_x86_64.whl (99.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coreforecast-0.0.15-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (275 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m275.8/275.8 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fugue-0.9.1-py3-none-any.whl (278 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gluonts-0.16.1-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m75.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonschema-4.23.0-py3-none-any.whl (88 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.5/88.5 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning-2.5.1.post0-py3-none-any.whl (819 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m819.0/819.0 kB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mlforecast-0.13.6-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.4/71.4 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nlpaug-1.1.11-py3-none-any.whl (410 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.5/410.5 kB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m79.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openmim-0.3.9-py2.py3-none-any.whl (52 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
            "Downloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
            "Downloading pytorch_metric_learning-2.8.1-py3-none-any.whl (125 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.9/125.9 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ray-2.44.1-cp311-cp311-manylinux2014_x86_64.whl (68.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.1/68.1 MB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading statsforecast-2.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (354 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m354.4/354.4 kB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading timm-1.0.3-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m85.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m110.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m93.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m57.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m94.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchmetrics-1.7.2-py3-none-any.whl (962 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m962.5/962.5 kB\u001b[0m \u001b[31m61.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.49.0-py3-none-any.whl (10.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m106.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading utilsforecast-0.2.10-py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_lightning-2.5.1.post0-py3-none-any.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.1/823.1 kB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading adagio-0.2.6-py3-none-any.whl (19 kB)\n",
            "Downloading botocore-1.38.33-py3-none-any.whl (13.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.6/13.6 MB\u001b[0m \u001b[31m116.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading lightning_utilities-0.14.3-py3-none-any.whl (28 kB)\n",
            "Downloading py_spy-0.4.0-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (2.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m94.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading s3transfer-0.13.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.2/85.2 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triad-0.9.8-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading virtualenv-20.31.2-py3-none-any.whl (6.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m118.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiohttp_cors-0.8.1-py3-none-any.whl (25 kB)\n",
            "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading colorful-0.5.6-py2.py3-none-any.whl (201 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.4/201.4 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading model_index-0.1.11-py3-none-any.whl (34 kB)\n",
            "Downloading opencensus-0.11.4-py2.py3-none-any.whl (128 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opendatalab-0.0.10-py3-none-any.whl (29 kB)\n",
            "Downloading optuna-4.3.0-py3-none-any.whl (386 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.6/386.6 kB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading window_ops-0.0.15-py3-none-any.whl (15 kB)\n",
            "Downloading alembic-1.16.1-py3-none-any.whl (242 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading distlib-0.3.9-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencensus_context-0.1.3-py2.py3-none-any.whl (5.1 kB)\n",
            "Downloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading fs-2.4.16-py2.py3-none-any.whl (135 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.3/135.3 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openxlab-0.0.11-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.3/55.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
            "Downloading pycryptodome-3.23.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m91.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Building wheels for collected packages: nvidia-ml-py3, seqeval\n",
            "  Building wheel for nvidia-ml-py3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nvidia-ml-py3: filename=nvidia_ml_py3-7.352.0-py3-none-any.whl size=19172 sha256=ed4475af96fcc4758de9aabf6fd0d72d556a74608836c61799f7b33cea200721\n",
            "  Stored in directory: /root/.cache/pip/wheels/47/50/9e/29dc79037d74c3c1bb4a8661fb608e8674b7e4260d6a3f8f51\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=32fedc60e9235dc4d55bcb5924d18ade8fc1cc25553ee8e895099bc47717c398\n",
            "  Stored in directory: /root/.cache/pip/wheels/bc/92/f0/243288f899c2eacdfa8c5f9aede4c71a9bad0ee26a01dc5ead\n",
            "Successfully built nvidia-ml-py3 seqeval\n",
            "Installing collected packages: py-spy, opencensus-context, nvidia-ml-py3, distlib, colorful, appdirs, virtualenv, tensorboardX, pytesseract, pycryptodome, pdf2image, ordered-set, openxlab, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nltk, lightning-utilities, jmespath, fs, coreforecast, colorlog, colorama, window-ops, nvidia-cusparse-cu12, nvidia-cudnn-cu12, model-index, botocore, alembic, utilsforecast, triad, seqeval, s3transfer, optuna, opendatalab, nvidia-cusolver-cu12, jsonschema, gluonts, catboost, aiohttp_cors, transformers, ray, openmim, opencensus, nlpaug, mlforecast, boto3, adagio, torchmetrics, pytorch-metric-learning, fugue, evaluate, autogluon.common, timm, statsforecast, pytorch-lightning, autogluon.features, autogluon.core, lightning, autogluon.tabular, autogluon.multimodal, autogluon.timeseries, autogluon\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.9.1\n",
            "    Uninstalling nltk-3.9.1:\n",
            "      Successfully uninstalled nltk-3.9.1\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: jsonschema\n",
            "    Found existing installation: jsonschema 4.24.0\n",
            "    Uninstalling jsonschema-4.24.0:\n",
            "      Successfully uninstalled jsonschema-4.24.0\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.52.4\n",
            "    Uninstalling transformers-4.52.4:\n",
            "      Successfully uninstalled transformers-4.52.4\n",
            "  Attempting uninstall: timm\n",
            "    Found existing installation: timm 1.0.15\n",
            "    Uninstalling timm-1.0.15:\n",
            "      Successfully uninstalled timm-1.0.15\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "textblob 0.19.0 requires nltk>=3.9, but you have nltk 3.8.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed adagio-0.2.6 aiohttp_cors-0.8.1 alembic-1.16.1 appdirs-1.4.4 autogluon-1.3.1 autogluon.common-1.3.1 autogluon.core-1.3.1 autogluon.features-1.3.1 autogluon.multimodal-1.3.1 autogluon.tabular-1.3.1 autogluon.timeseries-1.3.1 boto3-1.38.33 botocore-1.38.33 catboost-1.2.8 colorama-0.4.6 colorful-0.5.6 colorlog-6.9.0 coreforecast-0.0.15 distlib-0.3.9 evaluate-0.4.3 fs-2.4.16 fugue-0.9.1 gluonts-0.16.1 jmespath-1.0.1 jsonschema-4.23.0 lightning-2.5.1.post0 lightning-utilities-0.14.3 mlforecast-0.13.6 model-index-0.1.11 nlpaug-1.1.11 nltk-3.8.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-ml-py3-7.352.0 nvidia-nvjitlink-cu12-12.4.127 opencensus-0.11.4 opencensus-context-0.1.3 opendatalab-0.0.10 openmim-0.3.9 openxlab-0.0.11 optuna-4.3.0 ordered-set-4.1.0 pdf2image-1.17.0 py-spy-0.4.0 pycryptodome-3.23.0 pytesseract-0.3.13 pytorch-lightning-2.5.1.post0 pytorch-metric-learning-2.8.1 ray-2.44.1 s3transfer-0.13.0 seqeval-1.2.2 statsforecast-2.0.1 tensorboardX-2.6.2.2 timm-1.0.3 torchmetrics-1.7.2 transformers-4.49.0 triad-0.9.8 utilsforecast-0.2.10 virtualenv-20.31.2 window-ops-0.0.15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from autogluon.tabular import TabularPredictor\n",
        "from sklearn.metrics import  mean_squared_error\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "dB547DkSSMNO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. 데이터 불러오기 & 기본 전처리 ---\n",
        "df = pd.read_csv('/content/gdrive/MyDrive/train_heat.csv', encoding='CP949')\n",
        "df = df.replace(-99, np.nan).drop(columns='Unnamed: 0')\n",
        "#코드 다돌리고 추가1\n",
        "df['train_heat.wd'] = df['train_heat.wd'].replace(-9.9, np.nan)\n",
        "# 시간 전처리\n",
        "df['month'] = df['train_heat.tm'].astype(str).str[4:6].astype(int)\n",
        "df['hour'] = df['train_heat.tm'].astype(str).str[8:10].astype(int)\n",
        "df['date'] = pd.to_datetime(df['train_heat.tm'].astype(str).str[:8])\n",
        "df['weekday'] = df['date'].dt.weekday\n",
        "df['is_weekend'] = (df['weekday'] >= 5).astype(int)\n",
        "df['train_heat.tm'] = pd.to_datetime(df['train_heat.tm'].astype(str), format='%Y%m%d%H')\n",
        "df = df.sort_values('train_heat.tm').set_index('train_heat.tm')\n",
        "\n",
        "# 결측치 선형보간\n",
        "for col in df.columns[df.isnull().any()]:\n",
        "    df[col] = df[col].interpolate(method='linear')\n",
        "\n",
        "# --- 2. 파생변수 생성 (기존 + 추가) ---\n",
        "\n",
        "# 계절 구분\n",
        "df['heating_season'] = df['month'].apply(lambda x: 1 if x in [10, 11, 12, 1, 2, 3, 4] else 0)\n",
        "df['temp_category'] = df['train_heat.ta'].apply(lambda x: 1 if x >= 20 else 0)\n",
        "\n",
        "def peak_time_category(hour):\n",
        "    if 0 <= hour <= 6:\n",
        "        return 0  # 심야\n",
        "    elif 6 < hour <= 11:\n",
        "        return 1  # 오전\n",
        "    elif 11 < hour <= 18:\n",
        "        return 2  # 오후\n",
        "    else:\n",
        "        return 3  # 저녁\n",
        "\n",
        "df['peak_time'] = df['hour'].apply(peak_time_category)\n",
        "\n",
        "# lag\n",
        "for lag in [1, 2, 3]:\n",
        "    df[f'ta_lag_{lag}'] = df['train_heat.ta'].shift(lag).interpolate(method='linear')\n",
        "\n",
        "# HDD, CDD\n",
        "base_temp = 18.0\n",
        "df['HDD'] = (base_temp - df['train_heat.ta']).clip(lower=0)\n",
        "df['CDD'] = (df['train_heat.ta'] - base_temp).clip(lower=0)\n",
        "\n",
        "# 편차\n",
        "df['branch_temp_abs_deviation'] = (\n",
        "    df['train_heat.ta'] - df.groupby('train_heat.branch_id')['train_heat.ta'].transform('mean')\n",
        ").abs()\n",
        "\n",
        "# ========== [추천 파생변수 추가] ==========\n",
        "\n",
        "# 변수별 변화량(diff) 및 24시간 이동평균\n",
        "for var in ['train_heat.ta', 'train_heat.si', 'train_heat.ta_chi', 'train_heat.ws', 'train_heat.wd', 'train_heat.rn_day', 'train_heat.rn_hr1', 'train_heat.heat_demand']:\n",
        "    if var in df.columns:\n",
        "        df[f'{var}_diff'] = df[var].diff().fillna(0)\n",
        "        df[f'{var}_ma24'] = df[var].rolling(window=24, min_periods=1).mean()\n",
        "\n",
        "# 누적 강수량(최근 3/6/12/24시간)\n",
        "for h in [3, 6, 12, 24]:\n",
        "    if 'train_heat.rn_hr1' in df.columns:\n",
        "        df[f'train_heat.rn_hr1_sum{h}'] = df['train_heat.rn_hr1'].rolling(h, min_periods=1).sum()\n",
        "\n",
        "# 최고/최저 기온(최근 6/12/24시간)\n",
        "for h in [6, 12, 24]:\n",
        "    if 'train_heat.ta' in df.columns:\n",
        "        df[f'train_heat.ta_max{h}'] = df['train_heat.ta'].rolling(h, min_periods=1).max()\n",
        "        df[f'train_heat.ta_min{h}'] = df['train_heat.ta'].rolling(h, min_periods=1).min()\n",
        "\n",
        "# 체감온도-실제온도 차\n",
        "if 'train_heat.ta_chi' in df.columns and 'train_heat.ta' in df.columns:\n",
        "    df['diff_ta_chi'] = df['train_heat.ta_chi'] - df['train_heat.ta']\n",
        "\n",
        "# 풍속 급변(2-step 차분)\n",
        "if 'train_heat.ws' in df.columns:\n",
        "    df['ws_diff2'] = df['train_heat.ws'].diff(2).fillna(0)\n",
        "\n",
        "# 당일 누적 강수량\n",
        "if 'train_heat.rn_day' in df.columns:\n",
        "    df['rn_day_cumsum'] = df['train_heat.rn_day'].cumsum()\n",
        "\n",
        "# 전일 평균/최고/최저 기온\n",
        "if 'train_heat.ta' in df.columns:\n",
        "    df['ta_yesterday_avg'] = df['train_heat.ta'].shift(24).rolling(24).mean()\n",
        "    df['ta_yesterday_max'] = df['train_heat.ta'].shift(24).rolling(24).max()\n",
        "    df['ta_yesterday_min'] = df['train_heat.ta'].shift(24).rolling(24).min()\n",
        "\n",
        "# 임계치 이탈 플래그\n",
        "if 'train_heat.ta' in df.columns:\n",
        "    df['cold_flag'] = (df['train_heat.ta'] < 5).astype(int)\n",
        "    df['hot_flag'] = (df['train_heat.ta'] > 25).astype(int)\n",
        "\n",
        "# ========== [겹치지 않는 추가 파생변수 아이디어] ==========\n",
        "\n",
        "# 1. 최근 3시간 평균/최대/최소 열수요 (수요 패턴 반영)\n",
        "df['heat_demand_ma3'] = df['train_heat.heat_demand'].rolling(3, min_periods=1).mean()\n",
        "df['heat_demand_max3'] = df['train_heat.heat_demand'].rolling(3, min_periods=1).max()\n",
        "df['heat_demand_min3'] = df['train_heat.heat_demand'].rolling(3, min_periods=1).min()\n",
        "\n",
        "# 2. 전주 같은 시간대 열수요 (주기성 반영)\n",
        "df['heat_demand_lastweek'] = df['train_heat.heat_demand'].shift(24*7)\n",
        "\n",
        "# 3. 시간대별 평균 열수요와의 차이 (이상치 탐지, 패턴 반영)\n",
        "df['hourly_avg_heat_demand'] = df.groupby('hour')['train_heat.heat_demand'].transform('mean')\n",
        "df['heat_demand_hourly_dev'] = df['train_heat.heat_demand'] - df['hourly_avg_heat_demand']\n",
        "\n",
        "# 4. 전일 동시간대 열수요\n",
        "df['heat_demand_yesterday'] = df['train_heat.heat_demand'].shift(24)\n",
        "\n",
        "# 5. 최근 6시간 기온 표준편차 (기온 변동성)\n",
        "df['ta_std6'] = df['train_heat.ta'].rolling(6, min_periods=1).std().fillna(0)\n",
        "\n",
        "# 6. 최근 6시간 풍속 표준편차 (풍속 변동성)\n",
        "df['ws_std6'] = df['train_heat.ws'].rolling(6, min_periods=1).std().fillna(0)\n",
        "\n",
        "# 7. 최근 24시간 내 강수 발생 여부 (이진 플래그)\n",
        "df['rain_flag_24h'] = (df['train_heat.rn_hr1'].rolling(24, min_periods=1).sum() > 0).astype(int)\n",
        "\n",
        "# 8. 월별 평균 기온과의 차이 (계절적 이상치)\n",
        "df['monthly_avg_ta'] = df.groupby('month')['train_heat.ta'].transform('mean')\n",
        "df['ta_monthly_dev'] = df['train_heat.ta'] - df['monthly_avg_ta']\n",
        "\n",
        "# 9. 주말/평일 플래그 (is_weekend는 이미 있음, is_holiday는 없으므로 주말만)\n",
        "# 이미 is_weekend 있음\n",
        "\n",
        "# 10. 최근 12시간 열수요 증가폭 (트렌드)\n",
        "df['heat_demand_trend12'] = df['train_heat.heat_demand'] - df['train_heat.heat_demand'].shift(12)\n",
        "\n",
        "# --- 3. 학습 및 평가용 Walk-Forward 구조 ---\n",
        "target = 'train_heat.heat_demand'\n",
        "# 새로 추가된 파생변수도 features에 포함\n",
        "features = [\n",
        "    \"train_heat.branch_id\", \"train_heat.ta\", \"train_heat.wd\", \"train_heat.ws\", \"train_heat.rn_day\",\n",
        "    \"train_heat.rn_hr1\", \"train_heat.hm\", \"train_heat.si\", \"train_heat.ta_chi\",\n",
        "    \"month\", \"weekday\", \"heating_season\", \"temp_category\", \"peak_time\", \"is_weekend\",\n",
        "    \"ta_lag_1\", \"ta_lag_2\", \"ta_lag_3\", \"HDD\", \"CDD\", \"branch_temp_abs_deviation\",\n",
        "    # 기존 diff/ma24\n",
        "    \"train_heat.ta_diff\", \"train_heat.ta_ma24\", \"train_heat.si_diff\", \"train_heat.si_ma24\",\n",
        "    \"train_heat.ta_chi_diff\", \"train_heat.ta_chi_ma24\", \"train_heat.ws_diff\", \"train_heat.ws_ma24\",\n",
        "    \"train_heat.wd_diff\", \"train_heat.wd_ma24\", \"train_heat.rn_day_diff\", \"train_heat.rn_day_ma24\",\n",
        "    \"train_heat.rn_hr1_diff\", \"train_heat.rn_hr1_ma24\", \"train_heat.heat_demand_diff\", \"train_heat.heat_demand_ma24\",\n",
        "    # 누적 강수량\n",
        "    \"train_heat.rn_hr1_sum3\", \"train_heat.rn_hr1_sum6\", \"train_heat.rn_hr1_sum12\", \"train_heat.rn_hr1_sum24\",\n",
        "    # 최고/최저 기온\n",
        "    \"train_heat.ta_max6\", \"train_heat.ta_max12\", \"train_heat.ta_max24\",\n",
        "    \"train_heat.ta_min6\", \"train_heat.ta_min12\", \"train_heat.ta_min24\",\n",
        "    # 체감온도-실제온도 차, 풍속 급변, 누적 강수량, 전일 기온, 임계치 플래그\n",
        "    \"diff_ta_chi\", \"ws_diff2\", \"rn_day_cumsum\",\n",
        "    \"ta_yesterday_avg\", \"ta_yesterday_max\", \"ta_yesterday_min\",\n",
        "    \"cold_flag\", \"hot_flag\",\n",
        "    # 추가 파생변수\n",
        "    \"heat_demand_ma3\", \"heat_demand_max3\", \"heat_demand_min3\",\n",
        "    \"heat_demand_lastweek\", \"heat_demand_hourly_dev\", \"heat_demand_yesterday\",\n",
        "    \"ta_std6\", \"ws_std6\", \"rain_flag_24h\", \"ta_monthly_dev\", \"heat_demand_trend12\"\n",
        "]\n",
        "categorical_cols = [\n",
        "    \"train_heat.branch_id\", \"month\", \"weekday\", \"heating_season\", \"temp_category\", \"peak_time\", \"is_weekend\",\n",
        "    \"cold_flag\", \"hot_flag\", \"rain_flag_24h\"\n",
        "]\n",
        "\n",
        "# 풍향이 범주형이면 추가\n",
        "if df['train_heat.wd'].nunique() < 20:\n",
        "    categorical_cols.append(\"train_heat.wd\")\n",
        "\n",
        "\n",
        "\n",
        "#코드 다 돌리고 추가2\n",
        "#전처리마지막에 결측치\n",
        "for col in df.columns[df.isnull().any()]:\n",
        "    df[col] = df[col].interpolate(method='linear')\n",
        "for col in df.columns[df.isnull().any()]:\n",
        "    df[col] = df[col].fillna(0)\n",
        "\n"
      ],
      "metadata": {
        "id": "DG9Mm5D7VMIb"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. train/val/test 분할\n",
        "df_trainval = df[df['date'].dt.year.isin([2021, 2022])].reset_index(drop=True)\n",
        "df_test = df[df['date'].dt.year == 2023].reset_index(drop=True)\n",
        "\n",
        "# 2. Walk-Forward (TimeSeriesSplit) 설정\n",
        "n_splits = 5  # fold 개수는 데이터 크기에 따라 조정\n",
        "tscv = TimeSeriesSplit(n_splits=n_splits)\n",
        "\n",
        "results = []\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(tscv.split(df_trainval)):\n",
        "    print(f\"\\n===== Fold {fold+1} =====\")\n",
        "    df_train = df_trainval.iloc[train_idx].copy()\n",
        "    df_val = df_trainval.iloc[val_idx].copy()\n",
        "\n",
        "    # 인코딩\n",
        "    df_train_encoded = pd.get_dummies(df_train[features + [target]], columns=categorical_cols)\n",
        "    df_val_encoded = pd.get_dummies(df_val[features + [target]], columns=categorical_cols)\n",
        "    df_test_encoded = pd.get_dummies(df_test[features + [target]], columns=categorical_cols)\n",
        "\n",
        "    # 열 맞추기\n",
        "    df_val_encoded = df_val_encoded.reindex(columns=df_train_encoded.columns, fill_value=0)\n",
        "    df_test_encoded = df_test_encoded.reindex(columns=df_train_encoded.columns, fill_value=0)\n",
        "\n",
        "    # 스케일링\n",
        "    features_encoded = [col for col in df_train_encoded.columns if col != target]\n",
        "    scaler = MinMaxScaler()\n",
        "    X_train_scaled = scaler.fit_transform(df_train_encoded[features_encoded])\n",
        "    X_val_scaled = scaler.transform(df_val_encoded[features_encoded])\n",
        "    X_test_scaled = scaler.transform(df_test_encoded[features_encoded])\n",
        "\n",
        "    df_train_scaled = pd.DataFrame(X_train_scaled, columns=features_encoded)\n",
        "    df_train_scaled[target] = df_train_encoded[target].values\n",
        "\n",
        "    df_val_scaled = pd.DataFrame(X_val_scaled, columns=features_encoded)\n",
        "    df_val_scaled[target] = df_val_encoded[target].values\n",
        "\n",
        "    df_test_scaled = pd.DataFrame(X_test_scaled, columns=features_encoded)\n",
        "    df_test_scaled[target] = df_test_encoded[target].values\n",
        "\n",
        "    # AutoGluon 학습 (train/val)\n",
        "    predictor = TabularPredictor(\n",
        "    label=target,\n",
        "    problem_type='regression',\n",
        "    path=f\"AutogluonModels_fold{fold+1}\"\n",
        "    ).fit(\n",
        "    train_data=df_train_scaled,\n",
        "    tuning_data=df_val_scaled,\n",
        "    presets='best_quality',\n",
        "    use_bag_holdout=True,\n",
        "    ag_args_fit={'num_gpus': 1}#코드 다돌리고 추가3\n",
        "    )\n",
        "\n",
        "    # 검증셋 평가\n",
        "    y_val_true = df_val_scaled[target]\n",
        "    y_val_pred = predictor.predict(df_val_scaled[features_encoded])\n",
        "    val_rmse = mean_squared_error(y_val_true, y_val_pred) ** 0.5\n",
        "\n",
        "    # 테스트셋 평가 (2023)\n",
        "    y_test_true = df_test_scaled[target]\n",
        "    y_test_pred = predictor.predict(df_test_scaled[features_encoded])\n",
        "    test_rmse = mean_squared_error(y_test_true, y_test_pred) ** 0.5\n",
        "\n",
        "    print(f\"Fold {fold+1} | Val RMSE: {val_rmse:.4f} | Test RMSE: {test_rmse:.4f}\")\n",
        "\n",
        "    results.append({\n",
        "        'fold': fold+1,\n",
        "        'val_rmse': val_rmse,\n",
        "        'test_rmse': test_rmse\n",
        "    })\n",
        "\n",
        "# 결과 DataFrame\n",
        "results_df = pd.DataFrame(results)\n",
        "print(\"\\n===== 전체 Fold 결과 =====\")\n",
        "print(results_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TibJhYTKbUVC",
        "outputId": "9d43e9e1-8dd8-4454-dee5-4c78c8890768"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== Fold 1 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Verbosity: 2 (Standard Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.3.1\n",
            "Python Version:     3.11.13\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP PREEMPT_DYNAMIC Sun Mar 30 16:01:29 UTC 2025\n",
            "CPU Count:          12\n",
            "Memory Avail:       80.15 GB / 83.48 GB (96.0%)\n",
            "Disk Space Avail:   193.17 GB / 235.68 GB (82.0%)\n",
            "===================================================\n",
            "Presets specified: ['best_quality']\n",
            "Setting dynamic_stacking from 'auto' to False. Reason: Skip dynamic_stacking when use_bag_holdout is enabled. (use_bag_holdout=True)\n",
            "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
            "Beginning AutoGluon training ... Time limit = 3600s\n",
            "AutoGluon will save models to \"/content/AutogluonModels_fold1\"\n",
            "Train Data Rows:    55481\n",
            "Train Data Columns: 103\n",
            "Tuning Data Rows:    55476\n",
            "Tuning Data Columns: 103\n",
            "Label Column:       train_heat.heat_demand\n",
            "Problem Type:       regression\n",
            "Preprocessing data ...\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    81972.87 MB\n",
            "\tTrain Data (Original)  Memory Usage: 87.19 MB (0.1% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 47 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 103 | ['train_heat.ta', 'train_heat.wd', 'train_heat.ws', 'train_heat.rn_day', 'train_heat.rn_hr1', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 56 | ['train_heat.ta', 'train_heat.wd', 'train_heat.ws', 'train_heat.rn_day', 'train_heat.rn_hr1', ...]\n",
            "\t\t('int', ['bool']) : 47 | ['train_heat.branch_id_A', 'train_heat.branch_id_B', 'train_heat.branch_id_C', 'train_heat.branch_id_D', 'train_heat.branch_id_E', ...]\n",
            "\t1.1s = Fit runtime\n",
            "\t103 features in original data used to generate 103 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 52.38 MB (0.1% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 1.25s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
            "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "use_bag_holdout=True, will use tuning_data as holdout (will not be used for early stopping).\n",
            "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
            "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
            "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
            "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
            "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
            "}\n",
            "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
            "Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 2398.56s of the 3598.73s of remaining time.\n",
            "\t-32.1398\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.09s\t = Training   runtime\n",
            "\t3.8s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 2391.04s of the 3591.21s of remaining time.\n",
            "\t-32.1184\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.08s\t = Training   runtime\n",
            "\t3.53s\t = Validation runtime\n",
            "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 2383.53s of the 3583.70s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.23%)\n",
            "\t-5.6652\t = Validation score   (-root_mean_squared_error)\n",
            "\t153.34s\t = Training   runtime\n",
            "\t49.19s\t = Validation runtime\n",
            "Fitting model: LightGBM_BAG_L1 ... Training model for up to 2167.74s of the 3367.92s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.23%)\n",
            "\t-4.5062\t = Validation score   (-root_mean_squared_error)\n",
            "\t158.48s\t = Training   runtime\n",
            "\t48.78s\t = Validation runtime\n",
            "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 1949.42s of the 3149.59s of remaining time.\n",
            "\t-3.9012\t = Validation score   (-root_mean_squared_error)\n",
            "\t95.98s\t = Training   runtime\n",
            "\t1.14s\t = Validation runtime\n",
            "Fitting model: CatBoost_BAG_L1 ... Training model for up to 1846.89s of the 3047.06s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.79%)\n",
            "\t-4.9211\t = Validation score   (-root_mean_squared_error)\n",
            "\t517.53s\t = Training   runtime\n",
            "\t1.26s\t = Validation runtime\n",
            "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 1326.56s of the 2526.73s of remaining time.\n",
            "\t-4.5737\t = Validation score   (-root_mean_squared_error)\n",
            "\t28.69s\t = Training   runtime\n",
            "\t1.25s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 1290.91s of the 2491.08s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.36%)\n",
            "\t-17.0527\t = Validation score   (-root_mean_squared_error)\n",
            "\t81.54s\t = Training   runtime\n",
            "\t7.89s\t = Validation runtime\n",
            "Fitting model: XGBoost_BAG_L1 ... Training model for up to 1199.67s of the 2399.84s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.32%)\n",
            "\t-5.2231\t = Validation score   (-root_mean_squared_error)\n",
            "\t960.88s\t = Training   runtime\n",
            "\t67.52s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 157.48s of the 1357.66s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.20%)\n",
            "\t-12.2912\t = Validation score   (-root_mean_squared_error)\n",
            "\t56.84s\t = Training   runtime\n",
            "\t2.9s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 96.01s of the 1296.18s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.32%)\n",
            "\t-4.0312\t = Validation score   (-root_mean_squared_error)\n",
            "\t81.09s\t = Training   runtime\n",
            "\t14.22s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 1194.73s of remaining time.\n",
            "\tEnsemble Weights: {'RandomForestMSE_BAG_L1': 0.583, 'LightGBMLarge_BAG_L1': 0.375, 'CatBoost_BAG_L1': 0.042}\n",
            "\t-3.7235\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.08s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting 106 L2 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 1194.64s of the 1194.58s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.26%)\n",
            "\t-4.4068\t = Validation score   (-root_mean_squared_error)\n",
            "\t165.47s\t = Training   runtime\n",
            "\t46.23s\t = Validation runtime\n",
            "Fitting model: LightGBM_BAG_L2 ... Training model for up to 971.82s of the 971.76s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.26%)\n",
            "\t-4.3405\t = Validation score   (-root_mean_squared_error)\n",
            "\t198.04s\t = Training   runtime\n",
            "\t48.08s\t = Validation runtime\n",
            "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 715.29s of the 715.23s of remaining time.\n",
            "\t-4.1403\t = Validation score   (-root_mean_squared_error)\n",
            "\t126.04s\t = Training   runtime\n",
            "\t1.05s\t = Validation runtime\n",
            "Fitting model: CatBoost_BAG_L2 ... Training model for up to 582.52s of the 582.46s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.84%)\n",
            "\t-4.0848\t = Validation score   (-root_mean_squared_error)\n",
            "\t467.02s\t = Training   runtime\n",
            "\t1.26s\t = Validation runtime\n",
            "Fitting model: ExtraTreesMSE_BAG_L2 ... Training model for up to 112.48s of the 112.42s of remaining time.\n",
            "\t-4.164\t = Validation score   (-root_mean_squared_error)\n",
            "\t31.18s\t = Training   runtime\n",
            "\t1.26s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 73.84s of the 73.78s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.40%)\n",
            "\t-5.7046\t = Validation score   (-root_mean_squared_error)\n",
            "\t61.5s\t = Training   runtime\n",
            "\t6.17s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the 4.21s of remaining time.\n",
            "\tEnsemble Weights: {'RandomForestMSE_BAG_L1': 0.529, 'CatBoost_BAG_L2': 0.235, 'LightGBMLarge_BAG_L1': 0.176, 'RandomForestMSE_BAG_L2': 0.059}\n",
            "\t-3.6904\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.12s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 3595.98s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 272.2 rows/s (55476 batch size)\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/AutogluonModels_fold1\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 | Val RMSE: 3.6904 | Test RMSE: 6.1827\n",
            "\n",
            "===== Fold 2 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Verbosity: 2 (Standard Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.3.1\n",
            "Python Version:     3.11.13\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP PREEMPT_DYNAMIC Sun Mar 30 16:01:29 UTC 2025\n",
            "CPU Count:          12\n",
            "Memory Avail:       74.55 GB / 83.48 GB (89.3%)\n",
            "Disk Space Avail:   189.27 GB / 235.68 GB (80.3%)\n",
            "===================================================\n",
            "Presets specified: ['best_quality']\n",
            "Setting dynamic_stacking from 'auto' to False. Reason: Skip dynamic_stacking when use_bag_holdout is enabled. (use_bag_holdout=True)\n",
            "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
            "Beginning AutoGluon training ... Time limit = 3600s\n",
            "AutoGluon will save models to \"/content/AutogluonModels_fold2\"\n",
            "Train Data Rows:    110957\n",
            "Train Data Columns: 107\n",
            "Tuning Data Rows:    55476\n",
            "Tuning Data Columns: 107\n",
            "Label Column:       train_heat.heat_demand\n",
            "Problem Type:       regression\n",
            "Preprocessing data ...\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    76372.58 MB\n",
            "\tTrain Data (Original)  Memory Usage: 135.87 MB (0.2% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 51 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 107 | ['train_heat.ta', 'train_heat.wd', 'train_heat.ws', 'train_heat.rn_day', 'train_heat.rn_hr1', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 56 | ['train_heat.ta', 'train_heat.wd', 'train_heat.ws', 'train_heat.rn_day', 'train_heat.rn_hr1', ...]\n",
            "\t\t('int', ['bool']) : 51 | ['train_heat.branch_id_A', 'train_heat.branch_id_B', 'train_heat.branch_id_C', 'train_heat.branch_id_D', 'train_heat.branch_id_E', ...]\n",
            "\t1.4s = Fit runtime\n",
            "\t107 features in original data used to generate 107 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 79.20 MB (0.1% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 1.7s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
            "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "use_bag_holdout=True, will use tuning_data as holdout (will not be used for early stopping).\n",
            "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
            "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
            "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
            "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
            "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
            "}\n",
            "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
            "Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 2398.26s of the 3598.29s of remaining time.\n",
            "\t-55.1366\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.2s\t = Training   runtime\n",
            "\t7.35s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 2376.02s of the 3576.04s of remaining time.\n",
            "\t-55.1205\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.2s\t = Training   runtime\n",
            "\t7.19s\t = Validation runtime\n",
            "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 2354.12s of the 3554.14s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.46%)\n",
            "\t-6.0929\t = Validation score   (-root_mean_squared_error)\n",
            "\t271.3s\t = Training   runtime\n",
            "\t50.34s\t = Validation runtime\n",
            "Fitting model: LightGBM_BAG_L1 ... Training model for up to 2010.59s of the 3210.62s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.46%)\n",
            "\t-4.5705\t = Validation score   (-root_mean_squared_error)\n",
            "\t302.59s\t = Training   runtime\n",
            "\t45.9s\t = Validation runtime\n",
            "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 1646.06s of the 2846.08s of remaining time.\n",
            "\t-3.2092\t = Validation score   (-root_mean_squared_error)\n",
            "\t227.41s\t = Training   runtime\n",
            "\t1.33s\t = Validation runtime\n",
            "Fitting model: CatBoost_BAG_L1 ... Training model for up to 1406.84s of the 2606.86s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.06%)\n",
            "\t-5.9206\t = Validation score   (-root_mean_squared_error)\n",
            "\t695.0s\t = Training   runtime\n",
            "\t1.13s\t = Validation runtime\n",
            "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 708.95s of the 1908.97s of remaining time.\n",
            "\t-3.4995\t = Validation score   (-root_mean_squared_error)\n",
            "\t67.5s\t = Training   runtime\n",
            "\t1.29s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 629.78s of the 1829.81s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.76%)\n",
            "\t-17.6813\t = Validation score   (-root_mean_squared_error)\n",
            "\t155.3s\t = Training   runtime\n",
            "\t6.07s\t = Validation runtime\n",
            "Fitting model: XGBoost_BAG_L1 ... Training model for up to 466.02s of the 1666.04s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.63%)\n",
            "\t-4.6142\t = Validation score   (-root_mean_squared_error)\n",
            "\t373.69s\t = Training   runtime\n",
            "\t8.76s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 79.01s of the 1279.03s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.42%)\n",
            "\t-14.9867\t = Validation score   (-root_mean_squared_error)\n",
            "\t65.81s\t = Training   runtime\n",
            "\t3.02s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 7.98s of the 1208.00s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.55%)\n",
            "\t-29.4669\t = Validation score   (-root_mean_squared_error)\n",
            "\t9.67s\t = Training   runtime\n",
            "\t0.8s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 1195.78s of remaining time.\n",
            "\tEnsemble Weights: {'RandomForestMSE_BAG_L1': 0.706, 'ExtraTreesMSE_BAG_L1': 0.235, 'XGBoost_BAG_L1': 0.059}\n",
            "\t-3.1455\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.08s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting 106 L2 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 1195.69s of the 1195.62s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.50%)\n",
            "\t-5.7884\t = Validation score   (-root_mean_squared_error)\n",
            "\t305.6s\t = Training   runtime\n",
            "\t48.75s\t = Validation runtime\n",
            "Fitting model: LightGBM_BAG_L2 ... Training model for up to 823.19s of the 823.12s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.50%)\n",
            "\t-4.0184\t = Validation score   (-root_mean_squared_error)\n",
            "\t325.39s\t = Training   runtime\n",
            "\t45.12s\t = Validation runtime\n",
            "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 437.06s of the 436.99s of remaining time.\n",
            "\t-3.8197\t = Validation score   (-root_mean_squared_error)\n",
            "\t304.45s\t = Training   runtime\n",
            "\t1.33s\t = Validation runtime\n",
            "Fitting model: CatBoost_BAG_L2 ... Training model for up to 119.60s of the 119.53s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.12%)\n",
            "\t-4.7585\t = Validation score   (-root_mean_squared_error)\n",
            "\t96.19s\t = Training   runtime\n",
            "\t0.36s\t = Validation runtime\n",
            "Fitting model: ExtraTreesMSE_BAG_L2 ... Training model for up to 20.86s of the 20.79s of remaining time.\n",
            "\tNot enough time to generate out-of-fold predictions for model. Estimated time required was 20.11s compared to 10s of available time.\n",
            "\tTime limit exceeded... Skipping ExtraTreesMSE_BAG_L2.\n",
            "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the -59.06s of remaining time.\n",
            "\tEnsemble Weights: {'RandomForestMSE_BAG_L1': 0.64, 'ExtraTreesMSE_BAG_L1': 0.16, 'RandomForestMSE_BAG_L2': 0.12, 'LightGBM_BAG_L2': 0.08}\n",
            "\t-3.108\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.1s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 3659.26s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 308.9 rows/s (55476 batch size)\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/AutogluonModels_fold2\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 | Val RMSE: 3.1080 | Test RMSE: 3.0315\n",
            "\n",
            "===== Fold 3 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Verbosity: 2 (Standard Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.3.1\n",
            "Python Version:     3.11.13\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP PREEMPT_DYNAMIC Sun Mar 30 16:01:29 UTC 2025\n",
            "CPU Count:          12\n",
            "Memory Avail:       72.51 GB / 83.48 GB (86.9%)\n",
            "Disk Space Avail:   186.29 GB / 235.68 GB (79.0%)\n",
            "===================================================\n",
            "Presets specified: ['best_quality']\n",
            "Setting dynamic_stacking from 'auto' to False. Reason: Skip dynamic_stacking when use_bag_holdout is enabled. (use_bag_holdout=True)\n",
            "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
            "Beginning AutoGluon training ... Time limit = 3600s\n",
            "AutoGluon will save models to \"/content/AutogluonModels_fold3\"\n",
            "Train Data Rows:    166433\n",
            "Train Data Columns: 110\n",
            "Tuning Data Rows:    55476\n",
            "Tuning Data Columns: 110\n",
            "Label Column:       train_heat.heat_demand\n",
            "Problem Type:       regression\n",
            "Preprocessing data ...\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    74196.99 MB\n",
            "\tTrain Data (Original)  Memory Usage: 186.23 MB (0.3% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 54 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 110 | ['train_heat.ta', 'train_heat.wd', 'train_heat.ws', 'train_heat.rn_day', 'train_heat.rn_hr1', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 56 | ['train_heat.ta', 'train_heat.wd', 'train_heat.ws', 'train_heat.rn_day', 'train_heat.rn_hr1', ...]\n",
            "\t\t('int', ['bool']) : 54 | ['train_heat.branch_id_A', 'train_heat.branch_id_B', 'train_heat.branch_id_C', 'train_heat.branch_id_D', 'train_heat.branch_id_E', ...]\n",
            "\t1.8s = Fit runtime\n",
            "\t110 features in original data used to generate 110 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 106.24 MB (0.1% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 2.15s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
            "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "use_bag_holdout=True, will use tuning_data as holdout (will not be used for early stopping).\n",
            "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
            "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
            "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
            "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
            "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
            "}\n",
            "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
            "Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 2397.96s of the 3597.84s of remaining time.\n",
            "\t-44.227\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.38s\t = Training   runtime\n",
            "\t10.53s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 2353.86s of the 3553.73s of remaining time.\n",
            "\t-44.0243\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.37s\t = Training   runtime\n",
            "\t10.47s\t = Validation runtime\n",
            "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 2310.62s of the 3510.49s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.70%)\n",
            "\t-7.2717\t = Validation score   (-root_mean_squared_error)\n",
            "\t417.45s\t = Training   runtime\n",
            "\t51.35s\t = Validation runtime\n",
            "Fitting model: LightGBM_BAG_L1 ... Training model for up to 1817.43s of the 3017.30s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.70%)\n",
            "\t-5.6782\t = Validation score   (-root_mean_squared_error)\n",
            "\t406.86s\t = Training   runtime\n",
            "\t45.6s\t = Validation runtime\n",
            "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 1340.81s of the 2540.68s of remaining time.\n",
            "\t-3.3495\t = Validation score   (-root_mean_squared_error)\n",
            "\t346.66s\t = Training   runtime\n",
            "\t1.36s\t = Validation runtime\n",
            "Fitting model: CatBoost_BAG_L1 ... Training model for up to 977.18s of the 2177.05s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.32%)\n",
            "\t-6.8351\t = Validation score   (-root_mean_squared_error)\n",
            "\t782.63s\t = Training   runtime\n",
            "\t1.22s\t = Validation runtime\n",
            "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 191.28s of the 1391.15s of remaining time.\n",
            "\t-3.5931\t = Validation score   (-root_mean_squared_error)\n",
            "\t108.78s\t = Training   runtime\n",
            "\t1.28s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 66.07s of the 1265.94s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.16%)\n",
            "\t-4.755\t = Validation score   (-root_mean_squared_error)\n",
            "\t54.67s\t = Training   runtime\n",
            "\t5.79s\t = Validation runtime\n",
            "Fitting model: XGBoost_BAG_L1 ... Training model for up to 3.34s of the 1203.21s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.93%)\n",
            "\t-142.9133\t = Validation score   (-root_mean_squared_error)\n",
            "\t5.04s\t = Training   runtime\n",
            "\t1.68s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 1194.34s of remaining time.\n",
            "\tEnsemble Weights: {'RandomForestMSE_BAG_L1': 0.773, 'NeuralNetFastAI_BAG_L1': 0.182, 'ExtraTreesMSE_BAG_L1': 0.045}\n",
            "\t-3.2481\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.07s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting 106 L2 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 1194.26s of the 1194.18s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.74%)\n",
            "\t-6.1486\t = Validation score   (-root_mean_squared_error)\n",
            "\t434.51s\t = Training   runtime\n",
            "\t48.99s\t = Validation runtime\n",
            "Fitting model: LightGBM_BAG_L2 ... Training model for up to 689.08s of the 689.00s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.74%)\n",
            "\t-4.5656\t = Validation score   (-root_mean_squared_error)\n",
            "\t441.9s\t = Training   runtime\n",
            "\t44.84s\t = Validation runtime\n",
            "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 171.73s of the 171.65s of remaining time.\n",
            "\tNot enough time to generate out-of-fold predictions for model. Estimated time required was 28.68s compared to 17.15s of available time.\n",
            "\tTime limit exceeded... Skipping RandomForestMSE_BAG_L2.\n",
            "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the -262.91s of remaining time.\n",
            "\tEnsemble Weights: {'RandomForestMSE_BAG_L1': 0.72, 'NeuralNetFastAI_BAG_L1': 0.16, 'LightGBM_BAG_L2': 0.08, 'ExtraTreesMSE_BAG_L1': 0.04}\n",
            "\t-3.2383\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.08s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 3863.15s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 318.6 rows/s (55476 batch size)\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/AutogluonModels_fold3\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 | Val RMSE: 3.2383 | Test RMSE: 2.9354\n",
            "\n",
            "===== Fold 4 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Verbosity: 2 (Standard Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.3.1\n",
            "Python Version:     3.11.13\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP PREEMPT_DYNAMIC Sun Mar 30 16:01:29 UTC 2025\n",
            "CPU Count:          12\n",
            "Memory Avail:       72.02 GB / 83.48 GB (86.3%)\n",
            "Disk Space Avail:   183.93 GB / 235.68 GB (78.0%)\n",
            "===================================================\n",
            "Presets specified: ['best_quality']\n",
            "Setting dynamic_stacking from 'auto' to False. Reason: Skip dynamic_stacking when use_bag_holdout is enabled. (use_bag_holdout=True)\n",
            "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
            "Beginning AutoGluon training ... Time limit = 3600s\n",
            "AutoGluon will save models to \"/content/AutogluonModels_fold4\"\n",
            "Train Data Rows:    221909\n",
            "Train Data Columns: 110\n",
            "Tuning Data Rows:    55476\n",
            "Tuning Data Columns: 110\n",
            "Label Column:       train_heat.heat_demand\n",
            "Problem Type:       regression\n",
            "Preprocessing data ...\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    73632.06 MB\n",
            "\tTrain Data (Original)  Memory Usage: 232.79 MB (0.3% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 54 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 110 | ['train_heat.ta', 'train_heat.wd', 'train_heat.ws', 'train_heat.rn_day', 'train_heat.rn_hr1', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 56 | ['train_heat.ta', 'train_heat.wd', 'train_heat.ws', 'train_heat.rn_day', 'train_heat.rn_hr1', ...]\n",
            "\t\t('int', ['bool']) : 54 | ['train_heat.branch_id_A', 'train_heat.branch_id_B', 'train_heat.branch_id_C', 'train_heat.branch_id_D', 'train_heat.branch_id_E', ...]\n",
            "\t2.1s = Fit runtime\n",
            "\t110 features in original data used to generate 110 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 132.80 MB (0.2% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 2.55s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
            "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "use_bag_holdout=True, will use tuning_data as holdout (will not be used for early stopping).\n",
            "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
            "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
            "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
            "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
            "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
            "}\n",
            "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
            "Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 2397.70s of the 3597.44s of remaining time.\n",
            "\t-29.2241\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.42s\t = Training   runtime\n",
            "\t14.53s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 2325.80s of the 3525.54s of remaining time.\n",
            "\t-29.1952\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.42s\t = Training   runtime\n",
            "\t14.17s\t = Validation runtime\n",
            "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 2255.00s of the 3454.74s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.93%)\n",
            "\t-3.7753\t = Validation score   (-root_mean_squared_error)\n",
            "\t504.58s\t = Training   runtime\n",
            "\t47.13s\t = Validation runtime\n",
            "Fitting model: LightGBM_BAG_L1 ... Training model for up to 1672.27s of the 2872.01s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.93%)\n",
            "\t-3.4198\t = Validation score   (-root_mean_squared_error)\n",
            "\t486.54s\t = Training   runtime\n",
            "\t44.85s\t = Validation runtime\n",
            "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 1109.86s of the 2309.60s of remaining time.\n",
            "\t-2.1778\t = Validation score   (-root_mean_squared_error)\n",
            "\t463.54s\t = Training   runtime\n",
            "\t1.29s\t = Validation runtime\n",
            "Fitting model: CatBoost_BAG_L1 ... Training model for up to 624.66s of the 1824.40s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.55%)\n",
            "\t-3.6368\t = Validation score   (-root_mean_squared_error)\n",
            "\t500.43s\t = Training   runtime\n",
            "\t0.91s\t = Validation runtime\n",
            "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 121.21s of the 1320.95s of remaining time.\n",
            "\tNot enough time to generate out-of-fold predictions for model. Estimated time required was 37.23s compared to 12.09s of available time.\n",
            "\tTime limit exceeded... Skipping ExtraTreesMSE_BAG_L1.\n",
            "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 1174.25s of remaining time.\n",
            "\tEnsemble Weights: {'RandomForestMSE_BAG_L1': 0.824, 'LightGBM_BAG_L1': 0.176}\n",
            "\t-2.0974\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.05s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting 106 L2 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 1174.19s of the 1174.11s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.96%)\n",
            "\t-2.2587\t = Validation score   (-root_mean_squared_error)\n",
            "\t546.44s\t = Training   runtime\n",
            "\t42.21s\t = Validation runtime\n",
            "Fitting model: LightGBM_BAG_L2 ... Training model for up to 555.65s of the 555.57s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.95%)\n",
            "\t-2.0374\t = Validation score   (-root_mean_squared_error)\n",
            "\t448.73s\t = Training   runtime\n",
            "\t41.13s\t = Validation runtime\n",
            "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 21.51s of the 21.43s of remaining time.\n",
            "\tNot enough time to generate out-of-fold predictions for model. Estimated time required was 41.95s compared to 10s of available time.\n",
            "\tTime limit exceeded... Skipping RandomForestMSE_BAG_L2.\n",
            "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the -507.33s of remaining time.\n",
            "\tEnsemble Weights: {'LightGBM_BAG_L2': 0.579, 'RandomForestMSE_BAG_L1': 0.421}\n",
            "\t-1.8693\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.06s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 4107.58s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 338.2 rows/s (55476 batch size)\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/AutogluonModels_fold4\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 4 | Val RMSE: 1.8693 | Test RMSE: 2.3416\n",
            "\n",
            "===== Fold 5 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Verbosity: 2 (Standard Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.3.1\n",
            "Python Version:     3.11.13\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP PREEMPT_DYNAMIC Sun Mar 30 16:01:29 UTC 2025\n",
            "CPU Count:          12\n",
            "Memory Avail:       73.54 GB / 83.48 GB (88.1%)\n",
            "Disk Space Avail:   182.17 GB / 235.68 GB (77.3%)\n",
            "===================================================\n",
            "Presets specified: ['best_quality']\n",
            "Setting dynamic_stacking from 'auto' to False. Reason: Skip dynamic_stacking when use_bag_holdout is enabled. (use_bag_holdout=True)\n",
            "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
            "Beginning AutoGluon training ... Time limit = 3600s\n",
            "AutoGluon will save models to \"/content/AutogluonModels_fold5\"\n",
            "Train Data Rows:    277385\n",
            "Train Data Columns: 110\n",
            "Tuning Data Rows:    55476\n",
            "Tuning Data Columns: 110\n",
            "Label Column:       train_heat.heat_demand\n",
            "Problem Type:       regression\n",
            "Preprocessing data ...\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    75208.57 MB\n",
            "\tTrain Data (Original)  Memory Usage: 279.35 MB (0.4% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 54 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 110 | ['train_heat.ta', 'train_heat.wd', 'train_heat.ws', 'train_heat.rn_day', 'train_heat.rn_hr1', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 56 | ['train_heat.ta', 'train_heat.wd', 'train_heat.ws', 'train_heat.rn_day', 'train_heat.rn_hr1', ...]\n",
            "\t\t('int', ['bool']) : 54 | ['train_heat.branch_id_A', 'train_heat.branch_id_B', 'train_heat.branch_id_C', 'train_heat.branch_id_D', 'train_heat.branch_id_E', ...]\n",
            "\t2.4s = Fit runtime\n",
            "\t110 features in original data used to generate 110 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 159.36 MB (0.2% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 2.89s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
            "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "use_bag_holdout=True, will use tuning_data as holdout (will not be used for early stopping).\n",
            "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
            "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
            "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
            "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
            "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
            "}\n",
            "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
            "Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 2397.47s of the 3597.10s of remaining time.\n",
            "\t-39.7563\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.6s\t = Training   runtime\n",
            "\t17.96s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 2290.54s of the 3490.17s of remaining time.\n",
            "\t-39.7166\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.59s\t = Training   runtime\n",
            "\t18.18s\t = Validation runtime\n",
            "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 2184.06s of the 3383.68s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.14%)\n",
            "\t-4.9562\t = Validation score   (-root_mean_squared_error)\n",
            "\t661.49s\t = Training   runtime\n",
            "\t49.4s\t = Validation runtime\n",
            "Fitting model: LightGBM_BAG_L1 ... Training model for up to 1432.50s of the 2632.13s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.14%)\n",
            "\t-3.6939\t = Validation score   (-root_mean_squared_error)\n",
            "\t592.59s\t = Training   runtime\n",
            "\t43.55s\t = Validation runtime\n",
            "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 757.31s of the 1956.93s of remaining time.\n",
            "\t-2.4904\t = Validation score   (-root_mean_squared_error)\n",
            "\t577.49s\t = Training   runtime\n",
            "\t1.29s\t = Validation runtime\n",
            "Fitting model: CatBoost_BAG_L1 ... Training model for up to 153.61s of the 1353.24s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.74%)\n",
            "\t-4.5677\t = Validation score   (-root_mean_squared_error)\n",
            "\t123.43s\t = Training   runtime\n",
            "\t0.32s\t = Validation runtime\n",
            "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 27.60s of the 1227.23s of remaining time.\n",
            "\tNot enough time to generate out-of-fold predictions for model. Estimated time required was 53.23s compared to 10s of available time.\n",
            "\tTime limit exceeded... Skipping ExtraTreesMSE_BAG_L1.\n",
            "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 1036.76s of remaining time.\n",
            "\tEnsemble Weights: {'RandomForestMSE_BAG_L1': 0.87, 'LightGBM_BAG_L1': 0.087, 'LightGBMXT_BAG_L1': 0.043}\n",
            "\t-2.4512\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.05s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting 106 L2 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 1036.70s of the 1036.60s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.18%)\n",
            "\t-4.3478\t = Validation score   (-root_mean_squared_error)\n",
            "\t642.02s\t = Training   runtime\n",
            "\t48.79s\t = Validation runtime\n",
            "Fitting model: LightGBM_BAG_L2 ... Training model for up to 296.26s of the 296.17s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=1.18%)\n",
            "\t-2.8567\t = Validation score   (-root_mean_squared_error)\n",
            "\t240.63s\t = Training   runtime\n",
            "\t18.3s\t = Validation runtime\n",
            "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 13.27s of the 13.18s of remaining time.\n",
            "\tNot enough time to generate out-of-fold predictions for model. Estimated time required was 48.38s compared to 10s of available time.\n",
            "\tTime limit exceeded... Skipping RandomForestMSE_BAG_L2.\n",
            "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the -662.32s of remaining time.\n",
            "\tEnsemble Weights: {'RandomForestMSE_BAG_L1': 0.692, 'LightGBM_BAG_L2': 0.308}\n",
            "\t-2.3903\t = Validation score   (-root_mean_squared_error)\n",
            "\t0.06s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 4262.61s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 372.3 rows/s (55476 batch size)\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/AutogluonModels_fold5\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 5 | Val RMSE: 2.3903 | Test RMSE: 2.2346\n",
            "\n",
            "===== 전체 Fold 결과 =====\n",
            "   fold  val_rmse  test_rmse\n",
            "0     1  3.690414   6.182712\n",
            "1     2  3.107984   3.031546\n",
            "2     3  3.238282   2.935401\n",
            "3     4  1.869292   2.341616\n",
            "4     5  2.390270   2.234618\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fold loop 끝난 뒤, 마지막 fold의 predictor와 df_test_scaled, features_encoded, target 사용\n",
        "y_test_true = df_test_scaled[target]\n",
        "y_test_pred = predictor.predict(df_test_scaled[features_encoded])\n",
        "\n",
        "plt.figure(figsize=(18, 6))\n",
        "plt.plot(y_test_true.values, label='실제값 (True)', color='black', linewidth=2)\n",
        "plt.plot(y_test_pred.values, label='예측값 (Predicted)', color='red', alpha=0.7)\n",
        "plt.title('마지막 fold AutoGluon: 2023년 열수요 예측값 vs 실제값')\n",
        "plt.xlabel('Time Index')\n",
        "plt.ylabel('Heat Demand')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AhgFDBIGkgWX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ksEfF0yzkgUf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6JuFxe1okgSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VicylNUMkgQB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PtyNHftFkgNf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RKP21r-_kgLA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YP5RXAzjkgI6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J2gMn3pVkgB1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#체감온도 직접만든 변수\n",
        "def calc_wind_chill(Ta, RH, WS):\n",
        "    # 겨울철 조건: 기온 10℃ 이하, 풍속 1.3m/s 이상\n",
        "    cond = (Ta <= 10) & (WS >= 1.3)\n",
        "    Tw = np.full_like(Ta, np.nan, dtype=np.float64)\n",
        "    # 공식 적용\n",
        "    Ta_ = Ta[cond]\n",
        "    RH_ = RH[cond]\n",
        "    WS_ = WS[cond]\n",
        "    # 공식 (수정된 식)\n",
        "    Tw_calc = (\n",
        "        Ta_ * np.arctan(0.151977 * np.sqrt(RH_ + 8.313659))\n",
        "        + np.arctan(Ta_ + RH_)\n",
        "        - np.arctan(RH_ - 1.67633)\n",
        "        + 0.00391838 * RH_ ** 1.5 * np.arctan(0.023101 * RH_)\n",
        "        - 4.686035\n",
        "    )\n",
        "    # 겨울형 기간 동안 산출된 체감온도가 기온보다 높으면 기온과 같게\n",
        "    Tw_calc = np.where(Tw_calc > Ta_, Ta_, Tw_calc)\n",
        "    Tw[cond] = Tw_calc\n",
        "    return Tw\n",
        "\n",
        "# 적용\n",
        "df['ta_chi_formula'] = calc_wind_chill(df['train_heat.ta'].values, df['train_heat.hm'].values, df['train_heat.ws'].values)"
      ],
      "metadata": {
        "id": "Z9kCuBw9jJL3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}