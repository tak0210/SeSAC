{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9N8kUTzi6IA"
      },
      "source": [
        "# 🔥 지역난방 열수요 예측: 시즌별-브랜치별 LightGBM 모델\n",
        "\n",
        "## 📋 모델링 전략\n",
        "- **시즌 분할**: Heating Season vs Non-Heating Season\n",
        "- **브랜치별 개별 모델**: 각 branch_id마다 전용 모델\n",
        "- **LightGBM**: 모든 모델에 LightGBM 사용\n",
        "- **하이퍼파라미터 최적화**: Optuna TPE 사용\n",
        "- **총 모델 수**: 38개 (2시즌 × 19브랜치)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "6nmbT6Edi6ID"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "💻 로컬 환경에서 실행 중...\n"
          ]
        }
      ],
      "source": [
        "# Google Colab 환경 확인 및 패키지 설치\n",
        "import sys\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "\n",
        "if IN_COLAB:\n",
        "    print(\"🔥 Google Colab 환경에서 실행 중...\")\n",
        "    !pip install xgboost optuna\n",
        "    from google.colab import files, drive\n",
        "    print(\"✅ 패키지 설치 완료!\")\n",
        "else:\n",
        "    print(\"💻 로컬 환경에서 실행 중...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "cc2w0lOti6IH"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🚀 TensorFlow 버전: 2.19.0\n",
            "💻 CPU 사용\n"
          ]
        }
      ],
      "source": [
        "# 1. 라이브러리 import 수정\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# TensorFlow/Keras (LSTM용)\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "# 기존 머신러닝\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "\n",
        "# Optuna\n",
        "import optuna\n",
        "from optuna.samplers import TPESampler\n",
        "\n",
        "# GPU 설정\n",
        "print(f\"🚀 TensorFlow 버전: {tf.__version__}\")\n",
        "if tf.config.list_physical_devices('GPU'):\n",
        "    print(f\"✅ GPU 사용 가능: {tf.config.list_physical_devices('GPU')}\")\n",
        "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "    if gpus:\n",
        "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
        "else:\n",
        "    print(\"💻 CPU 사용\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "HsWjgGvyi6II"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ 파일 경로 설정 완료\n"
          ]
        }
      ],
      "source": [
        "# 데이터 파일 로드\n",
        "if IN_COLAB:\n",
        "    print(\"📁 파일 업로드 방법 선택:\")\n",
        "    print(\"1. 직접 업로드\")\n",
        "    print(\"2. Google Drive\")\n",
        "\n",
        "    method = input(\"선택 (1 또는 2): \")\n",
        "\n",
        "    if method == \"1\":\n",
        "        uploaded = files.upload()\n",
        "        files_list = list(uploaded.keys())\n",
        "        train_path = [f for f in files_list if 'train' in f.lower()][0]\n",
        "        test_path = [f for f in files_list if 'test' in f.lower()][0]\n",
        "    else:\n",
        "        drive.mount('/content/drive')\n",
        "        train_path = \"/content/drive/MyDrive/train_heat.csv\"\n",
        "        test_path = \"/content/drive/MyDrive/test_heat.csv\"\n",
        "else:\n",
        "    train_path = 'dataset/train_data_2122.csv'\n",
        "    test_path = 'dataset/test_data_23.csv'\n",
        "\n",
        "print(f\"✅ 파일 경로 설정 완료\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BnYi_t0i6IJ"
      },
      "source": [
        "## 1️⃣ 데이터 로드 및 전처리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "iy4VEB5gi6IK"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📊 데이터 로드 및 전처리...\n",
            "   훈련: (332861, 15), 테스트: (166440, 15)\n",
            "   기간: 2021-01-01 01:00:00 ~ 2023-12-31 23:00:00\n",
            "   브랜치: ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S']\n"
          ]
        }
      ],
      "source": [
        "def load_and_preprocess(train_path, test_path):\n",
        "    print(\"📊 데이터 로드 및 전처리...\")\n",
        "\n",
        "    # 데이터 로드\n",
        "    train_df = pd.read_csv(train_path)\n",
        "    test_df = pd.read_csv(test_path)\n",
        "\n",
        "    def process_df(df):\n",
        "        # 컬럼명 정리\n",
        "        if 'Unnamed: 0' in df.columns:\n",
        "            df = df.drop(columns=['Unnamed: 0'])\n",
        "        df.columns = [col.replace('train_heat.', '') for col in df.columns]\n",
        "\n",
        "        # 시간 변수\n",
        "        df['datetime'] = pd.to_datetime(df['tm'], format='%Y%m%d%H')\n",
        "        # df['year'] = df['datetime'].dt.year\n",
        "        df['month'] = df['datetime'].dt.month\n",
        "        # df['day'] = df['datetime'].dt.day\n",
        "        df['hour'] = df['datetime'].dt.hour\n",
        "        df['dayofweek'] = df['datetime'].dt.dayofweek\n",
        "\n",
        "        # 결측치 처리\n",
        "        missing_cols = ['ta', 'wd', 'ws', 'rn_day', 'rn_hr1', 'hm', 'si', 'ta_chi']\n",
        "        if 'heat_demand' in df.columns:\n",
        "            missing_cols.append('heat_demand')\n",
        "\n",
        "        for col in missing_cols:\n",
        "            if col in df.columns:\n",
        "                df[col] = df[col].replace(-99, np.nan)\n",
        "\n",
        "        # wd -9.9 결측치 처리\n",
        "        df.loc[df['wd'] == -9.9, 'wd'] = np.nan\n",
        "\n",
        "        # 일사량 야간 처리\n",
        "        if 'si' in df.columns:\n",
        "            night_mask = (df['hour'] < 8) | (df['hour'] > 18)\n",
        "            df.loc[night_mask & df['si'].isna(), 'si'] = 0\n",
        "\n",
        "        # 지사별 보간\n",
        "        df = df.sort_values(['branch_id', 'datetime'])\n",
        "        numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
        "\n",
        "        for branch in df['branch_id'].unique():\n",
        "            mask = df['branch_id'] == branch\n",
        "            df.loc[mask, numeric_cols] = df.loc[mask, numeric_cols].interpolate().fillna(method='ffill').fillna(method='bfill')\n",
        "\n",
        "        return df\n",
        "\n",
        "    train_df = process_df(train_df)\n",
        "    test_df = process_df(test_df)\n",
        "\n",
        "    print(f\"   훈련: {train_df.shape}, 테스트: {test_df.shape}\")\n",
        "    print(f\"   기간: {train_df['datetime'].min()} ~ {test_df['datetime'].max()}\")\n",
        "    print(f\"   브랜치: {sorted(train_df['branch_id'].unique())}\")\n",
        "\n",
        "    return train_df, test_df\n",
        "\n",
        "train_df, test_df = load_and_preprocess(train_path, test_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnbWsoYUi6IK"
      },
      "source": [
        "## 2️⃣ 파생변수 생성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "qmwGrilMi6IL"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ 파생변수 생성 완료: 37개 컬럼\n"
          ]
        }
      ],
      "source": [
        "def create_features(df):\n",
        "    \"\"\"HDD, wind_chill, 순환형 인코딩, 범주형 변수 생성\"\"\"\n",
        "    df = df.copy()\n",
        "\n",
        "    # ⭐ HDD (수치형)\n",
        "    if 'ta' in df.columns:\n",
        "        df['HDD_18'] = np.maximum(18 - df['ta'], 0)\n",
        "        df['HDD_20'] = np.maximum(20 - df['ta'], 0)\n",
        "\n",
        "    # ⭐ wind_chill (수치형)\n",
        "    if 'ta' in df.columns and 'ws' in df.columns:\n",
        "        df['wind_chill'] = np.where(\n",
        "            (df['ta'] <= 10) & (df['ws'] > 0),\n",
        "            13.12 + 0.6215 * df['ta'] - 11.37 * (df['ws'] ** 0.16) + 0.3965 * df['ta'] * (df['ws'] ** 0.16),\n",
        "            df['ta']\n",
        "        )\n",
        "\n",
        "    # ⭐ heating_season (범주형)\n",
        "    df['heating_season'] = df['month'].isin([10, 11, 12, 1, 2, 3, 4]).astype(int)\n",
        "\n",
        "    # 시간대 범주형\n",
        "    df['is_weekend'] = (df['dayofweek'] >= 5).astype(int)\n",
        "    df['is_peak_morning'] = ((df['hour'] >= 7) & (df['hour'] <= 9)).astype(int)\n",
        "    df['is_peak_evening'] = ((df['hour'] >= 18) & (df['hour'] <= 22)).astype(int)\n",
        "    df['is_night'] = ((df['hour'] >= 23) | (df['hour'] <= 5)).astype(int)\n",
        "\n",
        "    # 피크시간 통합\n",
        "    df['peak_time_category'] = 0\n",
        "    df.loc[df['is_peak_morning'] == 1, 'peak_time_category'] = 1\n",
        "    df.loc[df['is_peak_evening'] == 1, 'peak_time_category'] = 2\n",
        "    df.loc[df['is_night'] == 1, 'peak_time_category'] = 3\n",
        "\n",
        "    # ⭐ 기온 범주 (범주형)\n",
        "    if 'ta' in df.columns:\n",
        "        df['temp_category'] = pd.cut(df['ta'],\n",
        "                                   bins=[-np.inf, 0, 10, 20, 30, np.inf],\n",
        "                                   labels=[0, 1, 2, 3, 4]).astype(int)\n",
        "\n",
        "    # ⭐ 강수 강도 (범주형)\n",
        "    if 'rn_day' in df.columns:\n",
        "        df['rain_intensity'] = pd.cut(df['rn_day'],\n",
        "                                   bins=[-1, 0, 1, 5, 10, np.inf],\n",
        "                                   labels=[0, 1, 2, 3, 4]).astype(int)\n",
        "\n",
        "    # ⭐ 순환형 인코딩 (시간 cos, sin)\n",
        "    df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)\n",
        "    df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)\n",
        "    df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)\n",
        "    df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)\n",
        "    df['dayofweek_sin'] = np.sin(2 * np.pi * df['dayofweek'] / 7)\n",
        "    df['dayofweek_cos'] = np.cos(2 * np.pi * df['dayofweek'] / 7)\n",
        "\n",
        "    # 시간 기반 파생변수\n",
        "    df['hour_squared'] = df['hour'] ** 2\n",
        "    df['month_day_interaction'] = df['month'] * df['datetime'].dt.day\n",
        "    \n",
        "    # 기온 관련 파생변수\n",
        "    if 'ta' in df.columns:\n",
        "        df['ta_squared'] = df['ta'] ** 2\n",
        "        df['ta_cubed'] = df['ta'] ** 3\n",
        "    \n",
        "    # 습도와 기온 상호작용\n",
        "    if 'hm' in df.columns and 'ta' in df.columns:\n",
        "        df['hm_ta_interaction'] = df['hm'] * df['ta']\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "# 파생변수 생성\n",
        "train_df = create_features(train_df)\n",
        "test_df = create_features(test_df)\n",
        "\n",
        "print(f\"✅ 파생변수 생성 완료: {train_df.shape[1]}개 컬럼\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BnrDxhRi6IM"
      },
      "source": [
        "## 3️⃣ 시즌별-브랜치별 데이터 분할"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "jmdSkH3Ci6IN"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📊 데이터 분할 정보:\n",
            "   브랜치: 19개 - ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S']\n",
            "   시즌: 2개 - ['비난방', '난방']\n",
            "   총 조합: 38개\n",
            "   비난방_A: 7,344개 데이터\n",
            "   비난방_B: 7,344개 데이터\n",
            "   비난방_C: 7,344개 데이터\n",
            "   비난방_D: 7,344개 데이터\n",
            "   비난방_E: 7,344개 데이터\n",
            "   비난방_F: 7,344개 데이터\n",
            "   비난방_G: 7,344개 데이터\n",
            "   비난방_H: 7,344개 데이터\n",
            "   비난방_I: 7,344개 데이터\n",
            "   비난방_J: 7,344개 데이터\n",
            "   비난방_K: 7,344개 데이터\n",
            "   비난방_L: 7,344개 데이터\n",
            "   비난방_M: 7,344개 데이터\n",
            "   비난방_N: 7,344개 데이터\n",
            "   비난방_O: 7,344개 데이터\n",
            "   비난방_P: 7,344개 데이터\n",
            "   비난방_Q: 7,344개 데이터\n",
            "   비난방_R: 7,344개 데이터\n",
            "   비난방_S: 7,344개 데이터\n",
            "   난방_A: 10,175개 데이터\n",
            "   난방_B: 10,175개 데이터\n",
            "   난방_C: 10,175개 데이터\n",
            "   난방_D: 10,175개 데이터\n",
            "   난방_E: 10,175개 데이터\n",
            "   난방_F: 10,175개 데이터\n",
            "   난방_G: 10,175개 데이터\n",
            "   난방_H: 10,175개 데이터\n",
            "   난방_I: 10,175개 데이터\n",
            "   난방_J: 10,175개 데이터\n",
            "   난방_K: 10,175개 데이터\n",
            "   난방_L: 10,175개 데이터\n",
            "   난방_M: 10,175개 데이터\n",
            "   난방_N: 10,175개 데이터\n",
            "   난방_O: 10,175개 데이터\n",
            "   난방_P: 10,175개 데이터\n",
            "   난방_Q: 10,175개 데이터\n",
            "   난방_R: 10,175개 데이터\n",
            "   난방_S: 10,175개 데이터\n",
            "📊 데이터 분할 정보:\n",
            "   브랜치: 19개 - ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S']\n",
            "   시즌: 2개 - ['비난방', '난방']\n",
            "   총 조합: 38개\n",
            "   비난방_A: 3,672개 데이터\n",
            "   비난방_B: 3,672개 데이터\n",
            "   비난방_C: 3,672개 데이터\n",
            "   비난방_D: 3,672개 데이터\n",
            "   비난방_E: 3,672개 데이터\n",
            "   비난방_F: 3,672개 데이터\n",
            "   비난방_G: 3,672개 데이터\n",
            "   비난방_H: 3,672개 데이터\n",
            "   비난방_I: 3,672개 데이터\n",
            "   비난방_J: 3,672개 데이터\n",
            "   비난방_K: 3,672개 데이터\n",
            "   비난방_L: 3,672개 데이터\n",
            "   비난방_M: 3,672개 데이터\n",
            "   비난방_N: 3,672개 데이터\n",
            "   비난방_O: 3,672개 데이터\n",
            "   비난방_P: 3,672개 데이터\n",
            "   비난방_Q: 3,672개 데이터\n",
            "   비난방_R: 3,672개 데이터\n",
            "   비난방_S: 3,672개 데이터\n",
            "   난방_A: 5,088개 데이터\n",
            "   난방_B: 5,088개 데이터\n",
            "   난방_C: 5,088개 데이터\n",
            "   난방_D: 5,088개 데이터\n",
            "   난방_E: 5,088개 데이터\n",
            "   난방_F: 5,088개 데이터\n",
            "   난방_G: 5,088개 데이터\n",
            "   난방_H: 5,088개 데이터\n",
            "   난방_I: 5,088개 데이터\n",
            "   난방_J: 5,088개 데이터\n",
            "   난방_K: 5,088개 데이터\n",
            "   난방_L: 5,088개 데이터\n",
            "   난방_M: 5,088개 데이터\n",
            "   난방_N: 5,088개 데이터\n",
            "   난방_O: 5,088개 데이터\n",
            "   난방_P: 5,088개 데이터\n",
            "   난방_Q: 5,088개 데이터\n",
            "   난방_R: 5,088개 데이터\n",
            "   난방_S: 5,088개 데이터\n",
            "\n",
            "✅ 훈련 데이터: 38개 분할\n",
            "✅ 테스트 데이터: 38개 분할\n"
          ]
        }
      ],
      "source": [
        "# 시즌별-브랜치별 데이터 분할\n",
        "def split_by_season_and_branch(df):\n",
        "    data_splits = {}\n",
        "    \n",
        "    branches = sorted(df['branch_id'].unique())\n",
        "    seasons = [0, 1]  # 0: 비난방시즌, 1: 난방시즌\n",
        "    season_names = {0: '비난방', 1: '난방'}\n",
        "    \n",
        "    print(f\"📊 데이터 분할 정보:\")\n",
        "    print(f\"   브랜치: {len(branches)}개 - {branches}\")\n",
        "    print(f\"   시즌: {len(seasons)}개 - {[season_names[s] for s in seasons]}\")\n",
        "    print(f\"   총 조합: {len(branches) * len(seasons)}개\")\n",
        "    \n",
        "    for season in seasons:\n",
        "        for branch in branches:\n",
        "            key = f\"{season_names[season]}_{branch}\"\n",
        "            \n",
        "            # 시즌과 브랜치로 필터링\n",
        "            subset = df[(df['heating_season'] == season) & (df['branch_id'] == branch)].copy()\n",
        "            \n",
        "            if len(subset) > 0:\n",
        "                data_splits[key] = subset\n",
        "                print(f\"   {key}: {len(subset):,}개 데이터\")\n",
        "            else:\n",
        "                print(f\"   {key}: 데이터 없음 ⚠️\")\n",
        "    \n",
        "    return data_splits\n",
        "\n",
        "# 훈련 및 테스트 데이터 분할\n",
        "train_splits = split_by_season_and_branch(train_df)\n",
        "test_splits = split_by_season_and_branch(test_df)\n",
        "\n",
        "print(f\"\\n✅ 훈련 데이터: {len(train_splits)}개 분할\")\n",
        "print(f\"✅ 테스트 데이터: {len(test_splits)}개 분할\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 📌 Validation시 월별 추출"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_temporal_split_indices(df, test_size=0.2, min_val_samples=10):\n",
        "    \"\"\"시간 기반 분할 인덱스 반환\"\"\"\n",
        "    \n",
        "    month_counts = df['month'].value_counts()\n",
        "    valid_months = month_counts[month_counts >= min_val_samples * 2].index\n",
        "    \n",
        "    if len(valid_months) < 3:\n",
        "        # 폴백: 기존 방식\n",
        "        split_idx = int(len(df) * (1 - test_size))\n",
        "        return df.index[:split_idx], df.index[split_idx:]\n",
        "    \n",
        "    train_indices = []\n",
        "    val_indices = []\n",
        "    \n",
        "    for month in valid_months:\n",
        "        month_data = df[df['month'] == month].sort_values('datetime')\n",
        "        val_size = max(min_val_samples, int(len(month_data) * test_size))\n",
        "        \n",
        "        train_indices.extend(month_data.iloc[:-val_size].index)\n",
        "        val_indices.extend(month_data.iloc[-val_size:].index)\n",
        "    \n",
        "    print(f\"      📅 월별 분할: {len(valid_months)}개월, 검증 {len(val_indices)}개\")\n",
        "    \n",
        "    return train_indices, val_indices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# *. 🔥 브랜치 선별 필터링 함수 (중간 추가)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. 타겟 브랜치 정의 및 데이터 필터링 함수\n",
        "TARGET_BRANCHES = ['A', 'B', 'C', 'D', 'G', 'H']\n",
        "TARGET_SEASON = 'heating'  # 난방시즌만\n",
        "\n",
        "def filter_target_splits(splits_dict, target_branches=TARGET_BRANCHES, target_season='난방'):\n",
        "    \"\"\"기존 train_splits/test_splits에서 타겟 브랜치만 필터링\"\"\"\n",
        "    \n",
        "    print(f\"🎯 타겟 브랜치 필터링: {target_season}시즌 {target_branches}\")\n",
        "    \n",
        "    filtered_splits = {}\n",
        "    \n",
        "    for key, data in splits_dict.items():\n",
        "        # key 형태: \"난방_A\", \"비난방_B\" 등\n",
        "        season, branch = key.split('_')\n",
        "        \n",
        "        if season == target_season and branch in target_branches:\n",
        "            filtered_splits[key] = data\n",
        "            print(f\"   ✅ {key}: {len(data):,}개 데이터\")\n",
        "        else:\n",
        "            print(f\"   ⏭️ {key}: 건너뛰기\")\n",
        "    \n",
        "    print(f\"📊 필터링 결과: {len(filtered_splits)}개 모델 (기존 {len(splits_dict)}개)\")\n",
        "    return filtered_splits\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# *. LSTM 데이터 전처리 함수"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_lstm_sequences(X, y, sequence_length=24):\n",
        "    \"\"\"LSTM용 시퀀스 데이터 생성\"\"\"\n",
        "    X_seq, y_seq = [], []\n",
        "    \n",
        "    for i in range(sequence_length, len(X)):\n",
        "        X_seq.append(X.iloc[i-sequence_length:i].values)\n",
        "        y_seq.append(y.iloc[i])\n",
        "    \n",
        "    return np.array(X_seq), np.array(y_seq)\n",
        "\n",
        "def create_branch_lstm_data(df, feature_cols, target_col, sequence_length=24):\n",
        "    \"\"\"브랜치별 LSTM 시퀀스 데이터 생성\"\"\"\n",
        "    # 시간순 정렬\n",
        "    df_sorted = df.sort_values('datetime').copy()\n",
        "    \n",
        "    X = df_sorted[feature_cols]\n",
        "    y = df_sorted[target_col]\n",
        "    \n",
        "    if len(X) > sequence_length:\n",
        "        X_seq, y_seq = create_lstm_sequences(X, y, sequence_length)\n",
        "        print(f\"      📊 시퀀스 생성: {len(X_seq)}개 (원본 {len(X)}개)\")\n",
        "        return X_seq, y_seq\n",
        "    else:\n",
        "        print(f\"      ⚠️ 데이터 부족: {len(X)}개 (최소 {sequence_length+1}개 필요)\")\n",
        "        return np.array([]), np.array([])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmL7oLW1i6IN"
      },
      "source": [
        "## 4️⃣ LSTM 모델 클래스 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ LSTM 모델 클래스 정의 완료\n"
          ]
        }
      ],
      "source": [
        "class OptimizedLSTMModel:\n",
        "    def __init__(self, model_name):\n",
        "        self.model_name = model_name\n",
        "        self.model = None\n",
        "        self.best_params = None\n",
        "        self.feature_cols = None\n",
        "        self.study = None\n",
        "        self.best_score = None\n",
        "        self.sequence_length = 24\n",
        "        self.scaler_X = MinMaxScaler()\n",
        "        self.scaler_y = MinMaxScaler()\n",
        "        \n",
        "    def define_feature_columns(self, df):\n",
        "        \"\"\"특성 컬럼 정의\"\"\"\n",
        "        exclude_cols = [\n",
        "            'tm', 'datetime', 'year', 'heat_demand', 'branch_id'\n",
        "        ]\n",
        "        \n",
        "        self.feature_cols = [col for col in df.columns \n",
        "                           if col not in exclude_cols and df[col].dtype in ['int64', 'float64']]\n",
        "        \n",
        "        print(f\"   📋 {self.model_name}: {len(self.feature_cols)}개 특성 사용\")\n",
        "        return self.feature_cols\n",
        "    \n",
        "    def get_temporal_split_indices_lstm(self, df, test_size=0.2):\n",
        "        \"\"\"LSTM용 시간 기반 분할 (순차성 유지)\"\"\"\n",
        "        df_sorted = df.sort_values('datetime')\n",
        "        split_idx = int(len(df_sorted) * (1 - test_size))\n",
        "        \n",
        "        train_indices = df_sorted.index[:split_idx]\n",
        "        val_indices = df_sorted.index[split_idx:]\n",
        "        \n",
        "        print(f\"      📅 시계열 분할: 훈련 {len(train_indices)}개, 검증 {len(val_indices)}개\")\n",
        "        \n",
        "        return train_indices, val_indices\n",
        "    \n",
        "    def build_lstm_model(self, input_shape, trial=None):\n",
        "        \"\"\"LSTM 모델 구조 정의\"\"\"\n",
        "        if trial is not None:\n",
        "            lstm_units_1 = trial.suggest_int('lstm_units_1', 32, 128)\n",
        "            lstm_units_2 = trial.suggest_int('lstm_units_2', 16, 64)\n",
        "            dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
        "            learning_rate = trial.suggest_float('learning_rate', 1e-4, 1e-2, log=True)\n",
        "            l2_reg = trial.suggest_float('l2_reg', 1e-6, 1e-3, log=True)\n",
        "        else:\n",
        "            lstm_units_1 = 64\n",
        "            lstm_units_2 = 32\n",
        "            dropout_rate = 0.3\n",
        "            learning_rate = 0.001\n",
        "            l2_reg = 1e-4\n",
        "        \n",
        "        model = Sequential([\n",
        "            LSTM(lstm_units_1, \n",
        "                 return_sequences=True,\n",
        "                 input_shape=input_shape,\n",
        "                 kernel_regularizer=l2(l2_reg)),\n",
        "            BatchNormalization(),\n",
        "            Dropout(dropout_rate),\n",
        "            \n",
        "            LSTM(lstm_units_2,\n",
        "                 return_sequences=False,\n",
        "                 kernel_regularizer=l2(l2_reg)),\n",
        "            BatchNormalization(),\n",
        "            Dropout(dropout_rate),\n",
        "            \n",
        "            Dense(32, activation='relu', kernel_regularizer=l2(l2_reg)),\n",
        "            Dropout(dropout_rate * 0.5),\n",
        "            Dense(16, activation='relu'),\n",
        "            Dense(1, activation='linear')\n",
        "        ])\n",
        "        \n",
        "        optimizer = Adam(learning_rate=learning_rate)\n",
        "        model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
        "        \n",
        "        return model, {\n",
        "            'lstm_units_1': lstm_units_1,\n",
        "            'lstm_units_2': lstm_units_2,\n",
        "            'dropout_rate': dropout_rate,\n",
        "            'learning_rate': learning_rate,\n",
        "            'l2_reg': l2_reg\n",
        "        }\n",
        "    \n",
        "    def objective(self, trial, X_train_seq, y_train_seq, X_val_seq, y_val_seq):\n",
        "        \"\"\"Optuna 목적 함수\"\"\"\n",
        "        \n",
        "        input_shape = (X_train_seq.shape[1], X_train_seq.shape[2])\n",
        "        model, params = self.build_lstm_model(input_shape, trial)\n",
        "        \n",
        "        early_stopping = EarlyStopping(\n",
        "            monitor='val_loss',\n",
        "            patience=10,\n",
        "            restore_best_weights=True,\n",
        "            verbose=0\n",
        "        )\n",
        "        \n",
        "        model.fit(\n",
        "            X_train_seq, y_train_seq,\n",
        "            validation_data=(X_val_seq, y_val_seq),\n",
        "            epochs=50,  # 시간 단축을 위해 축소\n",
        "            batch_size=32,\n",
        "            callbacks=[early_stopping],\n",
        "            verbose=0\n",
        "        )\n",
        "        \n",
        "        y_pred_scaled = model.predict(X_val_seq, verbose=0)\n",
        "        y_pred = self.scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1)).flatten()\n",
        "        y_val_orig = self.scaler_y.inverse_transform(y_val_seq.reshape(-1, 1)).flatten()\n",
        "        \n",
        "        rmse = np.sqrt(mean_squared_error(y_val_orig, y_pred))\n",
        "        \n",
        "        del model\n",
        "        tf.keras.backend.clear_session()\n",
        "        \n",
        "        return rmse\n",
        "    \n",
        "    def fit(self, df, target_col='heat_demand', n_trials=5):\n",
        "        \"\"\"모델 훈련 (기존 방식과 동일)\"\"\"\n",
        "        print(f\"\\n🔍 {self.model_name} LSTM 모델 훈련 시작...\")\n",
        "        \n",
        "        if len(df) < self.sequence_length * 3:\n",
        "            print(f\"   ⚠️ 데이터 부족 ({len(df)}개) - 기본 모델 사용\")\n",
        "            self._fit_basic_model(df, target_col)\n",
        "            return\n",
        "        \n",
        "        # 1. 분할 인덱스 구하기\n",
        "        train_indices, val_indices = self.get_temporal_split_indices_lstm(df, test_size=0.2)\n",
        "        \n",
        "        # 2. 특성 컬럼 정의\n",
        "        self.define_feature_columns(df)\n",
        "        \n",
        "        # 3. 데이터 준비\n",
        "        X = df[self.feature_cols].copy()\n",
        "        y = df[target_col].copy()\n",
        "        \n",
        "        # 스케일러 피팅\n",
        "        self.scaler_X.fit(X)\n",
        "        self.scaler_y.fit(y.values.reshape(-1, 1))\n",
        "        \n",
        "        # 4. 훈련/검증 분할\n",
        "        train_df = df.loc[train_indices]\n",
        "        val_df = df.loc[val_indices]\n",
        "        \n",
        "        # 5. 시퀀스 데이터 생성\n",
        "        X_train_seq, y_train_seq = create_branch_lstm_data(\n",
        "            train_df, self.feature_cols, target_col, self.sequence_length\n",
        "        )\n",
        "        X_val_seq, y_val_seq = create_branch_lstm_data(\n",
        "            val_df, self.feature_cols, target_col, self.sequence_length\n",
        "        )\n",
        "        \n",
        "        if len(X_train_seq) == 0 or len(X_val_seq) == 0:\n",
        "            print(f\"   ⚠️ 시퀀스 생성 실패 - 기본 모델 사용\")\n",
        "            self._fit_basic_model(df, target_col)\n",
        "            return\n",
        "        \n",
        "        # 6. 시퀀스 데이터 스케일링\n",
        "        X_train_seq_scaled = np.zeros_like(X_train_seq)\n",
        "        X_val_seq_scaled = np.zeros_like(X_val_seq)\n",
        "        \n",
        "        for i in range(X_train_seq.shape[0]):\n",
        "            X_train_seq_scaled[i] = self.scaler_X.transform(X_train_seq[i])\n",
        "        for i in range(X_val_seq.shape[0]):\n",
        "            X_val_seq_scaled[i] = self.scaler_X.transform(X_val_seq[i])\n",
        "            \n",
        "        y_train_seq_scaled = self.scaler_y.transform(y_train_seq.reshape(-1, 1)).flatten()\n",
        "        y_val_seq_scaled = self.scaler_y.transform(y_val_seq.reshape(-1, 1)).flatten()\n",
        "        \n",
        "        print(f\"      📊 시퀀스 훈련: {len(X_train_seq_scaled):,}개, 검증: {len(X_val_seq_scaled):,}개\")\n",
        "        \n",
        "        # Optuna 최적화\n",
        "        print(f\"   🎯 하이퍼파라미터 최적화: \", end=\"\", flush=True)\n",
        "        \n",
        "        try:\n",
        "            optuna.logging.set_verbosity(optuna.logging.ERROR)\n",
        "            \n",
        "            self.study = optuna.create_study(\n",
        "                direction='minimize',\n",
        "                sampler=TPESampler(seed=42),\n",
        "                study_name=f\"lstm_{self.model_name}\"\n",
        "            )\n",
        "            \n",
        "            def progress_callback(study, trial):\n",
        "                print(f\"\\r   🎯 하이퍼파라미터 최적화: {len(study.trials)}/{n_trials} (Best RMSE: {study.best_value:.4f})\", end=\"\", flush=True)\n",
        "            \n",
        "            self.study.optimize(\n",
        "                lambda trial: self.objective(trial, X_train_seq_scaled, y_train_seq_scaled, \n",
        "                                           X_val_seq_scaled, y_val_seq_scaled),\n",
        "                n_trials=n_trials,\n",
        "                callbacks=[progress_callback]\n",
        "            )\n",
        "            \n",
        "            print()\n",
        "            \n",
        "            if len(self.study.trials) > 0 and self.study.best_trial is not None:\n",
        "                self.best_score = self.study.best_value\n",
        "                self.best_params = self.study.best_params.copy()\n",
        "                \n",
        "                # 최적 파라미터로 최종 모델 훈련\n",
        "                input_shape = (X_train_seq_scaled.shape[1], X_train_seq_scaled.shape[2])\n",
        "                self.model, _ = self.build_lstm_model(input_shape)\n",
        "                \n",
        "                # 전체 시퀀스 데이터로 훈련\n",
        "                X_full_seq, y_full_seq = create_branch_lstm_data(\n",
        "                    df, self.feature_cols, target_col, self.sequence_length\n",
        "                )\n",
        "                \n",
        "                X_full_seq_scaled = np.zeros_like(X_full_seq)\n",
        "                for i in range(X_full_seq.shape[0]):\n",
        "                    X_full_seq_scaled[i] = self.scaler_X.transform(X_full_seq[i])\n",
        "                y_full_seq_scaled = self.scaler_y.transform(y_full_seq.reshape(-1, 1)).flatten()\n",
        "                \n",
        "                early_stopping = EarlyStopping(\n",
        "                    monitor='val_loss', patience=15, restore_best_weights=True, verbose=0\n",
        "                )\n",
        "                \n",
        "                self.model.fit(\n",
        "                    X_full_seq_scaled, y_full_seq_scaled,\n",
        "                    validation_data=(X_val_seq_scaled, y_val_seq_scaled),\n",
        "                    epochs=100,\n",
        "                    batch_size=32,\n",
        "                    callbacks=[early_stopping],\n",
        "                    verbose=0\n",
        "                )\n",
        "                \n",
        "                # 성능 정보\n",
        "                val_pred_scaled = self.model.predict(X_val_seq_scaled, verbose=0)\n",
        "                val_pred = self.scaler_y.inverse_transform(val_pred_scaled.reshape(-1, 1)).flatten()\n",
        "                y_val_orig = self.scaler_y.inverse_transform(y_val_seq_scaled.reshape(-1, 1)).flatten()\n",
        "                val_rmse = np.sqrt(mean_squared_error(y_val_orig, val_pred))\n",
        "                \n",
        "                print(f\"   📈 최적화 완료: Best RMSE = {self.best_score:.4f}\")\n",
        "                print(f\"   📊 검증 RMSE = {val_rmse:.4f}\")\n",
        "                print(f\"   🏆 최적 파라미터: lr={self.best_params.get('learning_rate', 0.001):.5f}, units={self.best_params.get('lstm_units_1', 64)}\")\n",
        "                \n",
        "            else:\n",
        "                print(f\"   ⚠️ 최적화 실패: 유효한 trial 없음 - 기본 모델 사용\")\n",
        "                self._fit_basic_model(df, target_col)\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(f\"\\n   ⚠️ 최적화 실패: {str(e)[:30]}... - 기본 모델 사용\")\n",
        "            self._fit_basic_model(df, target_col)\n",
        "    \n",
        "    def _fit_basic_model(self, df, target_col):\n",
        "        \"\"\"기본 모델 훈련\"\"\"\n",
        "        try:\n",
        "            X_full_seq, y_full_seq = create_branch_lstm_data(\n",
        "                df, self.feature_cols, target_col, self.sequence_length\n",
        "            )\n",
        "            \n",
        "            if len(X_full_seq) == 0:\n",
        "                print(f\"   ❌ 시퀀스 데이터 생성 실패\")\n",
        "                self.model = None\n",
        "                return\n",
        "            \n",
        "            X_full_seq_scaled = np.zeros_like(X_full_seq)\n",
        "            for i in range(X_full_seq.shape[0]):\n",
        "                X_full_seq_scaled[i] = self.scaler_X.transform(X_full_seq[i])\n",
        "            y_full_seq_scaled = self.scaler_y.transform(y_full_seq.reshape(-1, 1)).flatten()\n",
        "            \n",
        "            input_shape = (X_full_seq_scaled.shape[1], X_full_seq_scaled.shape[2])\n",
        "            self.model, _ = self.build_lstm_model(input_shape)\n",
        "            \n",
        "            self.model.fit(X_full_seq_scaled, y_full_seq_scaled, epochs=30, batch_size=32, verbose=0)\n",
        "            \n",
        "            self.best_score = None\n",
        "            self.best_params = None\n",
        "            print(f\"   🔧 기본 LSTM 모델 훈련 완료\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"   ❌ 기본 모델 훈련 실패: {str(e)[:30]}...\")\n",
        "            self.model = None\n",
        "    \n",
        "    def predict(self, df):\n",
        "        \"\"\"예측\"\"\"\n",
        "        if self.model is None:\n",
        "            return np.full(len(df), 0)\n",
        "        \n",
        "        try:\n",
        "            X_seq, _ = create_branch_lstm_data(\n",
        "                df, self.feature_cols, 'heat_demand', self.sequence_length\n",
        "            )\n",
        "            \n",
        "            if len(X_seq) == 0:\n",
        "                return np.full(len(df), 0)\n",
        "            \n",
        "            X_seq_scaled = np.zeros_like(X_seq)\n",
        "            for i in range(X_seq.shape[0]):\n",
        "                X_seq_scaled[i] = self.scaler_X.transform(X_seq[i])\n",
        "            \n",
        "            pred_scaled = self.model.predict(X_seq_scaled, verbose=0)\n",
        "            predictions = self.scaler_y.inverse_transform(pred_scaled.reshape(-1, 1)).flatten()\n",
        "            \n",
        "            # 시퀀스 길이만큼 앞의 데이터는 0으로 패딩\n",
        "            full_predictions = np.zeros(len(df))\n",
        "            full_predictions[self.sequence_length:self.sequence_length+len(predictions)] = predictions\n",
        "            \n",
        "            return np.maximum(full_predictions, 0)\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"   ❌ 예측 실패: {str(e)[:30]}...\")\n",
        "            return np.full(len(df), 0)\n",
        "\n",
        "print(\"✅ LSTM 모델 클래스 정의 완료\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SewcIVN_i6IR"
      },
      "source": [
        "## 5️⃣ 일단 일부만 모델 훈련"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🚀 6개 브랜치 LSTM 모델 훈련 시작!\n",
            "============================================================\n",
            "🎯 타겟 브랜치 필터링: 난방시즌 ['A', 'B', 'C', 'D', 'G', 'H']\n",
            "   ⏭️ 비난방_A: 건너뛰기\n",
            "   ⏭️ 비난방_B: 건너뛰기\n",
            "   ⏭️ 비난방_C: 건너뛰기\n",
            "   ⏭️ 비난방_D: 건너뛰기\n",
            "   ⏭️ 비난방_E: 건너뛰기\n",
            "   ⏭️ 비난방_F: 건너뛰기\n",
            "   ⏭️ 비난방_G: 건너뛰기\n",
            "   ⏭️ 비난방_H: 건너뛰기\n",
            "   ⏭️ 비난방_I: 건너뛰기\n",
            "   ⏭️ 비난방_J: 건너뛰기\n",
            "   ⏭️ 비난방_K: 건너뛰기\n",
            "   ⏭️ 비난방_L: 건너뛰기\n",
            "   ⏭️ 비난방_M: 건너뛰기\n",
            "   ⏭️ 비난방_N: 건너뛰기\n",
            "   ⏭️ 비난방_O: 건너뛰기\n",
            "   ⏭️ 비난방_P: 건너뛰기\n",
            "   ⏭️ 비난방_Q: 건너뛰기\n",
            "   ⏭️ 비난방_R: 건너뛰기\n",
            "   ⏭️ 비난방_S: 건너뛰기\n",
            "   ✅ 난방_A: 10,175개 데이터\n",
            "   ✅ 난방_B: 10,175개 데이터\n",
            "   ✅ 난방_C: 10,175개 데이터\n",
            "   ✅ 난방_D: 10,175개 데이터\n",
            "   ⏭️ 난방_E: 건너뛰기\n",
            "   ⏭️ 난방_F: 건너뛰기\n",
            "   ✅ 난방_G: 10,175개 데이터\n",
            "   ✅ 난방_H: 10,175개 데이터\n",
            "   ⏭️ 난방_I: 건너뛰기\n",
            "   ⏭️ 난방_J: 건너뛰기\n",
            "   ⏭️ 난방_K: 건너뛰기\n",
            "   ⏭️ 난방_L: 건너뛰기\n",
            "   ⏭️ 난방_M: 건너뛰기\n",
            "   ⏭️ 난방_N: 건너뛰기\n",
            "   ⏭️ 난방_O: 건너뛰기\n",
            "   ⏭️ 난방_P: 건너뛰기\n",
            "   ⏭️ 난방_Q: 건너뛰기\n",
            "   ⏭️ 난방_R: 건너뛰기\n",
            "   ⏭️ 난방_S: 건너뛰기\n",
            "📊 필터링 결과: 6개 모델 (기존 38개)\n",
            "🎯 타겟 브랜치 필터링: 난방시즌 ['A', 'B', 'C', 'D', 'G', 'H']\n",
            "   ⏭️ 비난방_A: 건너뛰기\n",
            "   ⏭️ 비난방_B: 건너뛰기\n",
            "   ⏭️ 비난방_C: 건너뛰기\n",
            "   ⏭️ 비난방_D: 건너뛰기\n",
            "   ⏭️ 비난방_E: 건너뛰기\n",
            "   ⏭️ 비난방_F: 건너뛰기\n",
            "   ⏭️ 비난방_G: 건너뛰기\n",
            "   ⏭️ 비난방_H: 건너뛰기\n",
            "   ⏭️ 비난방_I: 건너뛰기\n",
            "   ⏭️ 비난방_J: 건너뛰기\n",
            "   ⏭️ 비난방_K: 건너뛰기\n",
            "   ⏭️ 비난방_L: 건너뛰기\n",
            "   ⏭️ 비난방_M: 건너뛰기\n",
            "   ⏭️ 비난방_N: 건너뛰기\n",
            "   ⏭️ 비난방_O: 건너뛰기\n",
            "   ⏭️ 비난방_P: 건너뛰기\n",
            "   ⏭️ 비난방_Q: 건너뛰기\n",
            "   ⏭️ 비난방_R: 건너뛰기\n",
            "   ⏭️ 비난방_S: 건너뛰기\n",
            "   ✅ 난방_A: 5,088개 데이터\n",
            "   ✅ 난방_B: 5,088개 데이터\n",
            "   ✅ 난방_C: 5,088개 데이터\n",
            "   ✅ 난방_D: 5,088개 데이터\n",
            "   ⏭️ 난방_E: 건너뛰기\n",
            "   ⏭️ 난방_F: 건너뛰기\n",
            "   ✅ 난방_G: 5,088개 데이터\n",
            "   ✅ 난방_H: 5,088개 데이터\n",
            "   ⏭️ 난방_I: 건너뛰기\n",
            "   ⏭️ 난방_J: 건너뛰기\n",
            "   ⏭️ 난방_K: 건너뛰기\n",
            "   ⏭️ 난방_L: 건너뛰기\n",
            "   ⏭️ 난방_M: 건너뛰기\n",
            "   ⏭️ 난방_N: 건너뛰기\n",
            "   ⏭️ 난방_O: 건너뛰기\n",
            "   ⏭️ 난방_P: 건너뛰기\n",
            "   ⏭️ 난방_Q: 건너뛰기\n",
            "   ⏭️ 난방_R: 건너뛰기\n",
            "   ⏭️ 난방_S: 건너뛰기\n",
            "📊 필터링 결과: 6개 모델 (기존 38개)\n",
            "\n",
            "[ 1/6] 🔥 난방_A\n",
            "         📊 데이터: 10,175개\n",
            "\n",
            "🔍 난방_A LSTM 모델 훈련 시작...\n",
            "      📅 시계열 분할: 훈련 8140개, 검증 2035개\n",
            "   📋 난방_A: 21개 특성 사용\n",
            "      📊 시퀀스 생성: 8116개 (원본 8140개)\n",
            "      📊 시퀀스 생성: 2011개 (원본 2035개)\n",
            "      📊 시퀀스 훈련: 8,116개, 검증: 2,011개\n",
            "   🎯 하이퍼파라미터 최적화: WARNING:tensorflow:From c:\\Users\\dlsxk\\Python_Projects\\heat_demand\\MyProject\\.venv\\Lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
            "\n",
            "   🎯 하이퍼파라미터 최적화: 5/5 (Best RMSE: 20.9227)\n",
            "      📊 시퀀스 생성: 10151개 (원본 10175개)\n",
            "   📈 최적화 완료: Best RMSE = 20.9227\n",
            "   📊 검증 RMSE = 17.1153\n",
            "   🏆 최적 파라미터: lr=0.00158, units=68\n",
            "         ✅ 최적화 | RMSE: 20.923 | ⏱️ 759.2초\n",
            "\n",
            "[ 2/6] 🔥 난방_B\n",
            "         📊 데이터: 10,175개\n",
            "\n",
            "🔍 난방_B LSTM 모델 훈련 시작...\n",
            "      📅 시계열 분할: 훈련 8140개, 검증 2035개\n",
            "   📋 난방_B: 21개 특성 사용\n",
            "      📊 시퀀스 생성: 8116개 (원본 8140개)\n",
            "      📊 시퀀스 생성: 2011개 (원본 2035개)\n",
            "      📊 시퀀스 훈련: 8,116개, 검증: 2,011개\n",
            "   🎯 하이퍼파라미터 최적화: 5/5 (Best RMSE: 46.5207)\n",
            "      📊 시퀀스 생성: 10151개 (원본 10175개)\n",
            "   📈 최적화 완료: Best RMSE = 46.5207\n",
            "   📊 검증 RMSE = 36.0539\n",
            "   🏆 최적 파라미터: lr=0.00073, units=49\n",
            "         ✅ 최적화 | RMSE: 46.521 | ⏱️ 881.8초\n",
            "\n",
            "[ 3/6] 🔥 난방_C\n",
            "         📊 데이터: 10,175개\n",
            "\n",
            "🔍 난방_C LSTM 모델 훈련 시작...\n",
            "      📅 시계열 분할: 훈련 8140개, 검증 2035개\n",
            "   📋 난방_C: 21개 특성 사용\n",
            "      📊 시퀀스 생성: 8116개 (원본 8140개)\n",
            "      📊 시퀀스 생성: 2011개 (원본 2035개)\n",
            "      📊 시퀀스 훈련: 8,116개, 검증: 2,011개\n",
            "   🎯 하이퍼파라미터 최적화: 5/5 (Best RMSE: 33.7062)\n",
            "      📊 시퀀스 생성: 10151개 (원본 10175개)\n",
            "   📈 최적화 완료: Best RMSE = 33.7062\n",
            "   📊 검증 RMSE = 27.5349\n",
            "   🏆 최적 파라미터: lr=0.00158, units=68\n",
            "         ✅ 최적화 | RMSE: 33.706 | ⏱️ 983.4초\n",
            "\n",
            "[ 4/6] 🔥 난방_D\n",
            "         📊 데이터: 10,175개\n",
            "\n",
            "🔍 난방_D LSTM 모델 훈련 시작...\n",
            "      📅 시계열 분할: 훈련 8140개, 검증 2035개\n",
            "   📋 난방_D: 21개 특성 사용\n",
            "      📊 시퀀스 생성: 8116개 (원본 8140개)\n",
            "      📊 시퀀스 생성: 2011개 (원본 2035개)\n",
            "      📊 시퀀스 훈련: 8,116개, 검증: 2,011개\n",
            "   🎯 하이퍼파라미터 최적화: 5/5 (Best RMSE: 32.4766)\n",
            "      📊 시퀀스 생성: 10151개 (원본 10175개)\n",
            "   📈 최적화 완료: Best RMSE = 32.4766\n",
            "   📊 검증 RMSE = 25.3558\n",
            "   🏆 최적 파라미터: lr=0.00054, units=91\n",
            "         ✅ 최적화 | RMSE: 32.477 | ⏱️ 1335.0초\n",
            "\n",
            "[ 5/6] 🔥 난방_G\n",
            "         📊 데이터: 10,175개\n",
            "\n",
            "🔍 난방_G LSTM 모델 훈련 시작...\n",
            "      📅 시계열 분할: 훈련 8140개, 검증 2035개\n",
            "   📋 난방_G: 21개 특성 사용\n",
            "      📊 시퀀스 생성: 8116개 (원본 8140개)\n",
            "      📊 시퀀스 생성: 2011개 (원본 2035개)\n",
            "      📊 시퀀스 훈련: 8,116개, 검증: 2,011개\n",
            "   🎯 하이퍼파라미터 최적화: 5/5 (Best RMSE: 29.1212)\n",
            "      📊 시퀀스 생성: 10151개 (원본 10175개)\n",
            "   📈 최적화 완료: Best RMSE = 29.1212\n",
            "   📊 검증 RMSE = 23.6967\n",
            "   🏆 최적 파라미터: lr=0.00073, units=49\n",
            "         ✅ 최적화 | RMSE: 29.121 | ⏱️ 850.5초\n",
            "\n",
            "[ 6/6] 🔥 난방_H\n",
            "         📊 데이터: 10,175개\n",
            "\n",
            "🔍 난방_H LSTM 모델 훈련 시작...\n",
            "      📅 시계열 분할: 훈련 8140개, 검증 2035개\n",
            "   📋 난방_H: 21개 특성 사용\n",
            "      📊 시퀀스 생성: 8116개 (원본 8140개)\n",
            "      📊 시퀀스 생성: 2011개 (원본 2035개)\n",
            "      📊 시퀀스 훈련: 8,116개, 검증: 2,011개\n",
            "   🎯 하이퍼파라미터 최적화: 5/5 (Best RMSE: 37.3062)\n",
            "      📊 시퀀스 생성: 10151개 (원본 10175개)\n",
            "   📈 최적화 완료: Best RMSE = 37.3062\n",
            "   📊 검증 RMSE = 24.5256\n",
            "   🏆 최적 파라미터: lr=0.00054, units=91\n",
            "         ✅ 최적화 | RMSE: 37.306 | ⏱️ 711.4초\n",
            "\n",
            "============================================================\n",
            "🎉 6개 LSTM 모델 훈련 완료!\n",
            "⏱️  총 소요 시간: 92.0분\n",
            "📊 훈련 결과:\n",
            "   ✅ 성공: 6개\n",
            "   ❌ 실패: 0개\n",
            "   🎯 대상: 난방시즌 ['A', 'B', 'C', 'D', 'G', 'H'] 브랜치\n"
          ]
        }
      ],
      "source": [
        "# 🔥 6개 브랜치 LSTM 모델 훈련\n",
        "print(\"🚀 6개 브랜치 LSTM 모델 훈련 시작!\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# 1. 타겟 브랜치 필터링\n",
        "TARGET_BRANCHES = ['A', 'B', 'C', 'D', 'G', 'H']\n",
        "filtered_train_splits = filter_target_splits(train_splits, TARGET_BRANCHES, '난방')\n",
        "filtered_test_splits = filter_target_splits(test_splits, TARGET_BRANCHES, '난방')\n",
        "\n",
        "# 2. 6개 모델 훈련 (기존과 동일한 구조)\n",
        "models = {}\n",
        "training_results = {}\n",
        "n_trials_per_model = 5  # LSTM은 시간이 오래 걸리므로 축소\n",
        "\n",
        "start_time = datetime.now()\n",
        "success_count = 0\n",
        "failed_count = 0\n",
        "\n",
        "for i, (model_key, train_data) in enumerate(filtered_train_splits.items(), 1):\n",
        "    print(f\"\\n[{i:2d}/{len(filtered_train_splits)}] 🔥 {model_key}\")\n",
        "    print(f\"         📊 데이터: {len(train_data):,}개\")\n",
        "    \n",
        "    # LSTM 모델 생성 및 훈련\n",
        "    model = OptimizedLSTMModel(model_key)\n",
        "    \n",
        "    try:\n",
        "        model_start = datetime.now()\n",
        "        model.fit(train_data, n_trials=n_trials_per_model)\n",
        "        model_time = (datetime.now() - model_start).total_seconds()\n",
        "        \n",
        "        models[model_key] = model\n",
        "        \n",
        "        if model.best_score is not None:\n",
        "            success_count += 1\n",
        "            status = \"✅ 최적화\"\n",
        "            score_text = f\"RMSE: {model.best_score:.3f}\"\n",
        "        else:\n",
        "            status = \"🔧 기본모델\"\n",
        "            score_text = \"기본파라미터\"\n",
        "        \n",
        "        training_results[model_key] = {\n",
        "            'data_size': len(train_data),\n",
        "            'training_time': model_time,\n",
        "            'best_score': model.best_score,\n",
        "            'best_params': model.best_params,\n",
        "            'optimization_success': model.best_score is not None\n",
        "        }\n",
        "        \n",
        "        print(f\"         {status} | {score_text} | ⏱️ {model_time:.1f}초\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"         ❌ 훈련 실패: {str(e)[:30]}...\")\n",
        "        failed_count += 1\n",
        "        \n",
        "        # 더미 모델 저장\n",
        "        dummy_model = OptimizedLSTMModel(model_key)\n",
        "        dummy_model.model = None\n",
        "        models[model_key] = dummy_model\n",
        "        \n",
        "        training_results[model_key] = {\n",
        "            'data_size': len(train_data),\n",
        "            'training_time': 0,\n",
        "            'best_score': None,\n",
        "            'best_params': None,\n",
        "            'optimization_success': False,\n",
        "            'error': str(e)[:50]\n",
        "        }\n",
        "\n",
        "total_time = (datetime.now() - start_time).total_seconds()\n",
        "\n",
        "print(f\"\\n\" + \"=\" * 60)\n",
        "print(f\"🎉 6개 LSTM 모델 훈련 완료!\")\n",
        "print(f\"⏱️  총 소요 시간: {total_time/60:.1f}분\")\n",
        "print(f\"📊 훈련 결과:\")\n",
        "print(f\"   ✅ 성공: {success_count}개\")\n",
        "print(f\"   ❌ 실패: {failed_count}개\")\n",
        "print(f\"   🎯 대상: 난방시즌 {TARGET_BRANCHES} 브랜치\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xC-cKYeui6IS"
      },
      "source": [
        "## 6️⃣ 훈련 결과 분석"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ LSTM 훈련 결과 분석 함수 준비 완료\n",
            "\n",
            "📊 LSTM 훈련 결과 분석\n",
            "============================================================\n",
            "✅ 최적화 성공: 6개 모델\n",
            "🔧 기본 모델: 0개 모델\n",
            "❌ 완전 실패: 0개 모델\n",
            "\n",
            "🏆 LSTM 최적화 성능 통계:\n",
            "   평균 RMSE: 33.3423\n",
            "   최소 RMSE: 20.9227\n",
            "   최대 RMSE: 46.5207\n",
            "   표준편차: 8.5127\n",
            "\n",
            "📈 브랜치별 RMSE:\n",
            "   브랜치 A: RMSE = 20.9227 | 데이터 = 10,175개\n",
            "   브랜치 B: RMSE = 46.5207 | 데이터 = 10,175개\n",
            "   브랜치 C: RMSE = 33.7062 | 데이터 = 10,175개\n",
            "   브랜치 D: RMSE = 32.4766 | 데이터 = 10,175개\n",
            "   브랜치 G: RMSE = 29.1212 | 데이터 = 10,175개\n",
            "   브랜치 H: RMSE = 37.3062 | 데이터 = 10,175개\n",
            "\n",
            "🥇 성능 순위 (RMSE 낮은 순):\n",
            "   1. 브랜치 A: RMSE = 20.9227\n",
            "   2. 브랜치 G: RMSE = 29.1212\n",
            "   3. 브랜치 D: RMSE = 32.4766\n",
            "   4. 브랜치 C: RMSE = 33.7062\n",
            "   5. 브랜치 H: RMSE = 37.3062\n",
            "   6. 브랜치 B: RMSE = 46.5207\n",
            "\n",
            "⏱️ 훈련 시간 통계:\n",
            "   평균 모델당: 920.2초\n",
            "   총 훈련 시간: 92.0분\n",
            "\n",
            "📊 데이터 크기 vs 성능 분석:\n",
            "   브랜치 A: 10.2k개 → RMSE 20.9227\n",
            "   브랜치 B: 10.2k개 → RMSE 46.5207\n",
            "   브랜치 C: 10.2k개 → RMSE 33.7062\n",
            "   브랜치 D: 10.2k개 → RMSE 32.4766\n",
            "   브랜치 G: 10.2k개 → RMSE 29.1212\n",
            "   브랜치 H: 10.2k개 → RMSE 37.3062\n",
            "\n",
            "🔬 LSTM 모델 특성:\n",
            "   시퀀스 길이: 24시간\n",
            "   학습 대상: 난방시즌만\n",
            "   타겟 브랜치: A, B, C, D, G, H\n",
            "\n",
            "🎯 최적화된 하이퍼파라미터 분석:\n",
            "   브랜치 A: lr=0.00158, units=(68,62), dropout=0.393\n",
            "   브랜치 B: lr=0.00073, units=(49,30), dropout=0.310\n",
            "   브랜치 C: lr=0.00158, units=(68,62), dropout=0.393\n",
            "   브랜치 D: lr=0.00054, units=(91,22), dropout=0.217\n",
            "   브랜치 G: lr=0.00073, units=(49,30), dropout=0.310\n",
            "   브랜치 H: lr=0.00054, units=(91,22), dropout=0.217\n"
          ]
        }
      ],
      "source": [
        "def analyze_lstm_training_results(training_results, models):\n",
        "    \"\"\"6개 LSTM 모델 훈련 결과 분석\"\"\"\n",
        "    print(\"\\n📊 LSTM 훈련 결과 분석\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    # 결과 정리\n",
        "    results_list = []\n",
        "    for model_name, result in training_results.items():\n",
        "        # best_score를 안전하게 변환\n",
        "        best_score = result.get('best_score')\n",
        "        if best_score is not None:\n",
        "            try:\n",
        "                best_score = float(best_score)\n",
        "            except (ValueError, TypeError):\n",
        "                best_score = None\n",
        "        \n",
        "        # 안전한 딕셔너리 생성\n",
        "        safe_result = {\n",
        "            'model_name': model_name,\n",
        "            'branch': model_name.split('_')[1] if '_' in model_name else 'unknown',\n",
        "            'data_size': result.get('data_size', 0),\n",
        "            'training_time': result.get('training_time', 0),\n",
        "            'best_score': best_score,\n",
        "            'optimization_success': result.get('optimization_success', False),\n",
        "            'has_model': models.get(model_name) is not None and models.get(model_name).model is not None\n",
        "        }\n",
        "        results_list.append(safe_result)\n",
        "    \n",
        "    # DataFrame 생성\n",
        "    results_df = pd.DataFrame(results_list)\n",
        "    \n",
        "    # 성공/실패 통계\n",
        "    successful_models = results_df[results_df['optimization_success'] == True]\n",
        "    basic_models = results_df[(results_df['optimization_success'] == False) & (results_df['has_model'] == True)]\n",
        "    failed_models = results_df[results_df['has_model'] == False]\n",
        "    \n",
        "    print(f\"✅ 최적화 성공: {len(successful_models)}개 모델\")\n",
        "    print(f\"🔧 기본 모델: {len(basic_models)}개 모델\")\n",
        "    print(f\"❌ 완전 실패: {len(failed_models)}개 모델\")\n",
        "    \n",
        "    # 성공한 모델들의 성능 통계\n",
        "    if len(successful_models) > 0:\n",
        "        valid_scores = successful_models[successful_models['best_score'].notna()]\n",
        "        \n",
        "        if len(valid_scores) > 0:\n",
        "            print(f\"\\n🏆 LSTM 최적화 성능 통계:\")\n",
        "            print(f\"   평균 RMSE: {valid_scores['best_score'].mean():.4f}\")\n",
        "            print(f\"   최소 RMSE: {valid_scores['best_score'].min():.4f}\")\n",
        "            print(f\"   최대 RMSE: {valid_scores['best_score'].max():.4f}\")\n",
        "            print(f\"   표준편차: {valid_scores['best_score'].std():.4f}\")\n",
        "            \n",
        "            # 브랜치별 성능\n",
        "            print(f\"\\n📈 브랜치별 RMSE:\")\n",
        "            for _, row in valid_scores.iterrows():\n",
        "                print(f\"   브랜치 {row['branch']}: RMSE = {row['best_score']:.4f} | 데이터 = {row['data_size']:,}개\")\n",
        "            \n",
        "            # 성능 순위\n",
        "            print(f\"\\n🥇 성능 순위 (RMSE 낮은 순):\")\n",
        "            try:\n",
        "                # best_score를 숫자형으로 확실히 변환\n",
        "                valid_scores_copy = valid_scores.copy()\n",
        "                valid_scores_copy['best_score'] = pd.to_numeric(valid_scores_copy['best_score'], errors='coerce')\n",
        "                \n",
        "                # NaN 제거 후 정렬\n",
        "                top_models = valid_scores_copy.dropna(subset=['best_score']).nsmallest(6, 'best_score')\n",
        "                \n",
        "                for idx, (_, row) in enumerate(top_models.iterrows(), 1):\n",
        "                    print(f\"   {idx}. 브랜치 {row['branch']}: RMSE = {row['best_score']:.4f}\")\n",
        "                    \n",
        "            except Exception as e:\n",
        "                print(f\"   ⚠️ 순위 정렬 실패: {str(e)}\")\n",
        "                # 대안: 수동 정렬\n",
        "                try:\n",
        "                    scores_list = [(row['branch'], row['best_score']) \n",
        "                                 for _, row in valid_scores.iterrows() \n",
        "                                 if pd.notna(row['best_score'])]\n",
        "                    scores_list.sort(key=lambda x: float(x[1]))\n",
        "                    \n",
        "                    for idx, (branch, score) in enumerate(scores_list, 1):\n",
        "                        print(f\"   {idx}. 브랜치 {branch}: RMSE = {score:.4f}\")\n",
        "                except Exception as e2:\n",
        "                    print(f\"   ❌ 수동 정렬도 실패: {str(e2)}\")\n",
        "    \n",
        "    # 실패한 모델 정보\n",
        "    if len(failed_models) > 0:\n",
        "        print(f\"\\n⚠️ 실패한 모델들:\")\n",
        "        for _, row in failed_models.iterrows():\n",
        "            error_msg = training_results[row['model_name']].get('error', '알 수 없는 오류')\n",
        "            print(f\"   브랜치 {row['branch']}: {error_msg}\")\n",
        "    \n",
        "    # 훈련 시간 통계\n",
        "    avg_time = results_df['training_time'].mean()\n",
        "    total_time_min = results_df['training_time'].sum() / 60\n",
        "    print(f\"\\n⏱️ 훈련 시간 통계:\")\n",
        "    print(f\"   평균 모델당: {avg_time:.1f}초\")\n",
        "    print(f\"   총 훈련 시간: {total_time_min:.1f}분\")\n",
        "    \n",
        "    # 데이터 크기별 성능 분석\n",
        "    if len(successful_models) > 0:\n",
        "        print(f\"\\n📊 데이터 크기 vs 성능 분석:\")\n",
        "        for _, row in successful_models.iterrows():\n",
        "            if pd.notna(row['best_score']):\n",
        "                data_per_1k = row['data_size'] / 1000\n",
        "                print(f\"   브랜치 {row['branch']}: {data_per_1k:.1f}k개 → RMSE {row['best_score']:.4f}\")\n",
        "    \n",
        "    # LSTM 모델 특성 분석\n",
        "    print(f\"\\n🔬 LSTM 모델 특성:\")\n",
        "    print(f\"   시퀀스 길이: 24시간\")\n",
        "    print(f\"   학습 대상: 난방시즌만\")\n",
        "    print(f\"   타겟 브랜치: A, B, C, D, G, H\")\n",
        "    \n",
        "    # 하이퍼파라미터 분석 (성공한 모델들)\n",
        "    if len(successful_models) > 0:\n",
        "        print(f\"\\n🎯 최적화된 하이퍼파라미터 분석:\")\n",
        "        for _, row in successful_models.iterrows():\n",
        "            model = models.get(row['model_name'])\n",
        "            if model and model.best_params:\n",
        "                params = model.best_params\n",
        "                lr = params.get('learning_rate', 'N/A')\n",
        "                units1 = params.get('lstm_units_1', 'N/A')\n",
        "                units2 = params.get('lstm_units_2', 'N/A')\n",
        "                dropout = params.get('dropout_rate', 'N/A')\n",
        "                print(f\"   브랜치 {row['branch']}: lr={lr:.5f}, units=({units1},{units2}), dropout={dropout:.3f}\")\n",
        "    \n",
        "    return results_df, successful_models, failed_models\n",
        "\n",
        "# 실행 함수\n",
        "def run_lstm_analysis():\n",
        "    \"\"\"LSTM 훈련 결과 분석 실행\"\"\"\n",
        "    results_df, successful_models, failed_models = analyze_lstm_training_results(training_results, models)\n",
        "    return results_df, successful_models, failed_models\n",
        "\n",
        "print(\"✅ LSTM 훈련 결과 분석 함수 준비 완료\")\n",
        "\n",
        "# LSTM 훈련 결과 분석 실행\n",
        "results_df, successful_models, failed_models = run_lstm_analysis()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdr_IyHVi6IU"
      },
      "source": [
        "## 7️⃣ 테스트 예측"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🎯 6개 LSTM 모델 예측 시작...\n",
            "📊 난방_A: 5,088개 데이터 예측 중...\n",
            "      📊 시퀀스 생성: 5064개 (원본 5088개)\n",
            "   ✅ 완료: 평균=162.31\n",
            "📊 난방_B: 5,088개 데이터 예측 중...\n",
            "      📊 시퀀스 생성: 5064개 (원본 5088개)\n",
            "   ✅ 완료: 평균=348.25\n",
            "📊 난방_C: 5,088개 데이터 예측 중...\n",
            "      📊 시퀀스 생성: 5064개 (원본 5088개)\n",
            "   ✅ 완료: 평균=355.05\n",
            "📊 난방_D: 5,088개 데이터 예측 중...\n",
            "      📊 시퀀스 생성: 5064개 (원본 5088개)\n",
            "   ✅ 완료: 평균=233.65\n",
            "📊 난방_G: 5,088개 데이터 예측 중...\n",
            "      📊 시퀀스 생성: 5064개 (원본 5088개)\n",
            "   ✅ 완료: 평균=301.11\n",
            "📊 난방_H: 5,088개 데이터 예측 중...\n",
            "      📊 시퀀스 생성: 5064개 (원본 5088개)\n",
            "   ✅ 완료: 평균=207.50\n",
            "✅ 예측 완료: 6개 모델\n"
          ]
        }
      ],
      "source": [
        "# 시즌별 예측 (filtered_test_splits 사용)\n",
        "print(\"🎯 6개 LSTM 모델 예측 시작...\")\n",
        "\n",
        "predictions = {}\n",
        "\n",
        "for model_key, model in models.items():\n",
        "    if model_key in filtered_test_splits:\n",
        "        test_data = filtered_test_splits[model_key]\n",
        "        \n",
        "        print(f\"📊 {model_key}: {len(test_data):,}개 데이터 예측 중...\")\n",
        "        \n",
        "        try:\n",
        "            pred = model.predict(test_data)\n",
        "            predictions[model_key] = {\n",
        "                'data': test_data,\n",
        "                'predictions': pred\n",
        "            }\n",
        "            print(f\"   ✅ 완료: 평균={np.mean(pred):.2f}\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"   ❌ 예측 실패: {str(e)[:30]}...\")\n",
        "            predictions[model_key] = {\n",
        "                'data': test_data,\n",
        "                'predictions': np.zeros(len(test_data))\n",
        "            }\n",
        "\n",
        "print(f\"✅ 예측 완료: {len(predictions)}개 모델\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1lscpyji6IV"
      },
      "source": [
        "## 8️⃣ 예측 결과 통합"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "MmB8fvVHi6IV"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔄 예측 결과 통합 중...\n",
            "📊 난방_A: 5088개 인덱스에 할당\n",
            "📊 난방_B: 5088개 인덱스에 할당\n",
            "📊 난방_C: 5088개 인덱스에 할당\n",
            "📊 난방_D: 5088개 인덱스에 할당\n",
            "📊 난방_G: 5088개 인덱스에 할당\n",
            "📊 난방_H: 5088개 인덱스에 할당\n",
            "⚠️ 예측되지 않은 데이터: 135912개 (0으로 유지)\n",
            "\n",
            "✅ 예측 결과 통합 완료\n",
            "   📊 총 예측 개수: 166,440개\n",
            "   📈 예측값 통계: 평균=49.15, 최대=892.82\n"
          ]
        }
      ],
      "source": [
        "# 예측 결과를 원본 test_df 순서에 맞게 통합\n",
        "print(\"🔄 예측 결과 통합 중...\")\n",
        "\n",
        "# 결과를 저장할 배열 초기화\n",
        "final_predictions = np.zeros(len(test_df))\n",
        "prediction_counts = np.zeros(len(test_df))  # 각 인덱스별 예측 횟수 추적\n",
        "\n",
        "# 각 예측 결과를 해당 인덱스에 할당\n",
        "for model_key, pred_info in predictions.items():\n",
        "    test_data = pred_info['data']\n",
        "    pred_values = pred_info['predictions']\n",
        "    \n",
        "    # 원본 test_df에서 해당 데이터의 인덱스 찾기\n",
        "    season, branch = model_key.split('_')\n",
        "    season_num = 1 if season == '난방' else 0\n",
        "    \n",
        "    # 조건에 맞는 인덱스 찾기\n",
        "    mask = (test_df['heating_season'] == season_num) & (test_df['branch_id'] == branch)\n",
        "    indices = test_df[mask].index.tolist()\n",
        "    \n",
        "    print(f\"📊 {model_key}: {len(indices)}개 인덱스에 할당\")\n",
        "    \n",
        "    # 예측값 할당 (인덱스 개수와 예측값 개수가 맞는지 확인)\n",
        "    if len(indices) == len(pred_values):\n",
        "        for i, idx in enumerate(indices):\n",
        "            final_predictions[idx] = pred_values[i]\n",
        "            prediction_counts[idx] += 1\n",
        "    else:\n",
        "        print(f\"   ⚠️ 크기 불일치: 인덱스 {len(indices)}개 vs 예측값 {len(pred_values)}개\")\n",
        "        # 크기가 다르면 최소 개수만큼만 할당\n",
        "        min_len = min(len(indices), len(pred_values))\n",
        "        for i in range(min_len):\n",
        "            final_predictions[indices[i]] = pred_values[i]\n",
        "            prediction_counts[indices[i]] += 1\n",
        "\n",
        "# 예측되지 않은 데이터 확인\n",
        "unassigned_count = np.sum(prediction_counts == 0)\n",
        "if unassigned_count > 0:\n",
        "    print(f\"⚠️ 예측되지 않은 데이터: {unassigned_count}개 (0으로 유지)\")\n",
        "\n",
        "# 중복 예측 확인\n",
        "duplicate_count = np.sum(prediction_counts > 1)\n",
        "if duplicate_count > 0:\n",
        "    print(f\"⚠️ 중복 예측된 데이터: {duplicate_count}개\")\n",
        "\n",
        "print(f\"\\n✅ 예측 결과 통합 완료\")\n",
        "print(f\"   📊 총 예측 개수: {len(final_predictions):,}개\")\n",
        "print(f\"   📈 예측값 통계: 평균={np.mean(final_predictions):.2f}, 최대={np.max(final_predictions):.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3WOSlaHi6IV"
      },
      "source": [
        "## 9️⃣ 최종 결과 저장 및 평가"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "💾 최종 결과 저장...\n",
            "📁 결과 파일 저장: lightgbm_branch_season_predictions.csv\n",
            "\n",
            "📊 RMSE 성능 평가\n",
            "============================================================\n",
            "🏆 전체 성능:\n",
            "   RMSE: 70.8864\n",
            "   MAE:  52.6478\n",
            "   상관계수: 0.8915\n",
            "   유효 데이터: 166,440개\n",
            "\n",
            "📈 시즌별 RMSE 성능:\n",
            "   비난방시즌   : RMSE=51.8487 | MAE=40.9144 | 상관=   nan | 69,768개\n",
            "   난방시즌    : RMSE=81.9218 | MAE=61.1158 | 상관= 0.896 | 96,672개\n",
            "\n",
            "📊 브랜치별 RMSE 성능:\n",
            "   🥇 RMSE 우수 브랜치 (Top 5):\n",
            "      1. 브랜치 R: RMSE=17.1769 | MAE=14.6325 | 8,760개\n",
            "      2. 브랜치 S: RMSE=17.5521 | MAE=15.1737 | 8,760개\n",
            "      3. 브랜치 L: RMSE=29.6589 | MAE=23.1355 | 8,760개\n",
            "      4. 브랜치 A: RMSE=31.2909 | MAE=25.5237 | 8,760개\n",
            "      5. 브랜치 M: RMSE=44.5678 | MAE=35.3445 | 8,760개\n",
            "   🥉 RMSE 개선 필요 브랜치 (Bottom 5):\n",
            "      1. 브랜치 O: RMSE=85.3509 | MAE=65.9368 | 8,760개\n",
            "      2. 브랜치 I: RMSE=91.9005 | MAE=74.7925 | 8,760개\n",
            "      3. 브랜치 J: RMSE=102.2785 | MAE=87.2439 | 8,760개\n",
            "      4. 브랜치 N: RMSE=105.3003 | MAE=79.9602 | 8,760개\n",
            "      5. 브랜치 P: RMSE=116.2071 | MAE=96.9252 | 8,760개\n",
            "\n",
            "   📈 브랜치별 RMSE 통계:\n",
            "      평균: 65.0004\n",
            "      표준편차: 28.2812\n",
            "      최소: 17.1769\n",
            "      최대: 116.2071\n",
            "\n",
            "🔥 시즌×브랜치 조합별 RMSE (Ranking):\n",
            "    1. 비난방시즌_L        : RMSE= 9.5005 | 3,672개\n",
            "    2. 비난방시즌_R        : RMSE=10.6309 | 3,672개\n",
            "    3. 비난방시즌_S        : RMSE=10.8434 | 3,672개\n",
            "    4. 비난방시즌_M        : RMSE=16.1798 | 3,672개\n",
            "    5. 난방시즌_R         : RMSE=20.6498 | 5,088개\n",
            "    6. 난방시즌_S         : RMSE=21.1083 | 5,088개\n",
            "    7. 비난방시즌_Q        : RMSE=25.9683 | 3,672개\n",
            "    8. 비난방시즌_O        : RMSE=27.3052 | 3,672개\n",
            "    9. 비난방시즌_N        : RMSE=28.5891 | 3,672개\n",
            "   10. 난방시즌_A         : RMSE=29.6929 | 5,088개\n",
            "   11. 비난방시즌_A        : RMSE=33.3788 | 3,672개\n",
            "   12. 난방시즌_L         : RMSE=38.0704 | 5,088개\n",
            "   13. 비난방시즌_I        : RMSE=40.5269 | 3,672개\n",
            "   14. 난방시즌_H         : RMSE=43.1567 | 5,088개\n",
            "   15. 비난방시즌_F        : RMSE=45.2663 | 3,672개\n",
            "   16. 비난방시즌_H        : RMSE=46.5058 | 3,672개\n",
            "   17. 난방시즌_D         : RMSE=47.2322 | 5,088개\n",
            "   18. 난방시즌_G         : RMSE=49.6932 | 5,088개\n",
            "   19. 비난방시즌_K        : RMSE=50.8846 | 3,672개\n",
            "   20. 난방시즌_C         : RMSE=54.2458 | 5,088개\n",
            "   21. 난방시즌_M         : RMSE=56.8407 | 5,088개\n",
            "   22. 비난방시즌_D        : RMSE=61.9719 | 3,672개\n",
            "   23. 비난방시즌_P        : RMSE=63.7274 | 3,672개\n",
            "   24. 난방시즌_K         : RMSE=65.5340 | 5,088개\n",
            "   25. 비난방시즌_E        : RMSE=65.5797 | 3,672개\n",
            "   26. 비난방시즌_J        : RMSE=66.6835 | 3,672개\n",
            "   27. 난방시즌_B         : RMSE=67.6216 | 5,088개\n",
            "   28. 난방시즌_E         : RMSE=75.5598 | 5,088개\n",
            "   29. 비난방시즌_G        : RMSE=76.7462 | 3,672개\n",
            "   30. 비난방시즌_B        : RMSE=76.8676 | 3,672개\n",
            "   31. 난방시즌_Q         : RMSE=93.2894 | 5,088개\n",
            "   32. 난방시즌_F         : RMSE=96.5040 | 5,088개\n",
            "   33. 비난방시즌_C        : RMSE=101.2537 | 3,672개\n",
            "   34. 난방시즌_O         : RMSE=109.5633 | 5,088개\n",
            "   35. 난방시즌_I         : RMSE=115.5664 | 5,088개\n",
            "   36. 난방시즌_J         : RMSE=121.6607 | 5,088개\n",
            "   37. 난방시즌_N         : RMSE=136.0169 | 5,088개\n",
            "   38. 난방시즌_P         : RMSE=142.5448 | 5,088개\n",
            "\n",
            "🔍 모델 최적화 vs 실제 성능 비교:\n",
            "   훈련시 최적화 RMSE: 평균=33.3423, 범위=[20.9227, 46.5207]\n",
            "   실제 테스트 RMSE: 70.8864\n",
            "   성능 차이: 37.5441\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# 최종 결과를 test_df에 추가\n",
        "print(\"💾 최종 결과 저장...\")\n",
        "\n",
        "# 원본 test_df 복사\n",
        "result_df = test_df.copy()\n",
        "\n",
        "# 예측 결과 추가 (음수값 제거)\n",
        "result_df['pred_heat_demand'] = np.maximum(final_predictions, 0).round(1)\n",
        "\n",
        "# CSV 파일 저장\n",
        "output_filename = 'lightgbm_branch_season_predictions.csv'\n",
        "result_df.to_csv(output_filename, index=False)\n",
        "\n",
        "print(f\"📁 결과 파일 저장: {output_filename}\")\n",
        "\n",
        "# =============================================================================\n",
        "# RMSE 중심 성능 평가 (실제값이 있는 경우)\n",
        "# =============================================================================\n",
        "\n",
        "if 'heat_demand' in test_df.columns:\n",
        "    print(f\"\\n📊 RMSE 성능 평가\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    # 전체 RMSE\n",
        "    y_true = test_df['heat_demand'].values\n",
        "    y_pred = result_df['pred_heat_demand'].values\n",
        "    \n",
        "    # 음수나 NaN 값 제거\n",
        "    valid_mask = ~(np.isnan(y_true) | np.isnan(y_pred))\n",
        "    y_true_clean = y_true[valid_mask]\n",
        "    y_pred_clean = y_pred[valid_mask]\n",
        "    \n",
        "    overall_rmse = np.sqrt(mean_squared_error(y_true_clean, y_pred_clean))\n",
        "    overall_mae = mean_absolute_error(y_true_clean, y_pred_clean)\n",
        "    correlation = np.corrcoef(y_true_clean, y_pred_clean)[0, 1]\n",
        "    \n",
        "    print(f\"🏆 전체 성능:\")\n",
        "    print(f\"   RMSE: {overall_rmse:.4f}\")\n",
        "    print(f\"   MAE:  {overall_mae:.4f}\")\n",
        "    print(f\"   상관계수: {correlation:.4f}\")\n",
        "    print(f\"   유효 데이터: {len(y_true_clean):,}개\")\n",
        "    \n",
        "    # 시즌별 RMSE (핵심!)\n",
        "    print(f\"\\n📈 시즌별 RMSE 성능:\")\n",
        "    season_names = {0: '비난방시즌', 1: '난방시즌'}\n",
        "    season_results = {}\n",
        "    \n",
        "    for season in [0, 1]:\n",
        "        mask = (test_df['heating_season'] == season) & valid_mask\n",
        "        if np.sum(mask) > 0:\n",
        "            season_rmse = np.sqrt(mean_squared_error(y_true[mask], y_pred[mask]))\n",
        "            season_mae = mean_absolute_error(y_true[mask], y_pred[mask])\n",
        "            season_corr = np.corrcoef(y_true[mask], y_pred[mask])[0, 1] if np.sum(mask) > 1 else 0\n",
        "            season_results[season] = {\n",
        "                'rmse': season_rmse, \n",
        "                'mae': season_mae, \n",
        "                'corr': season_corr,\n",
        "                'count': np.sum(mask)\n",
        "            }\n",
        "            \n",
        "            print(f\"   {season_names[season]:8s}: RMSE={season_rmse:7.4f} | MAE={season_mae:7.4f} | 상관={season_corr:6.3f} | {np.sum(mask):,}개\")\n",
        "    \n",
        "    # 브랜치별 RMSE (상위/하위 분석)\n",
        "    print(f\"\\n📊 브랜치별 RMSE 성능:\")\n",
        "    branch_results = {}\n",
        "    \n",
        "    for branch in sorted(test_df['branch_id'].unique()):\n",
        "        mask = (test_df['branch_id'] == branch) & valid_mask\n",
        "        if np.sum(mask) > 1:  # 최소 2개 이상의 데이터가 있어야 RMSE 계산 가능\n",
        "            branch_rmse = np.sqrt(mean_squared_error(y_true[mask], y_pred[mask]))\n",
        "            branch_mae = mean_absolute_error(y_true[mask], y_pred[mask])\n",
        "            branch_results[branch] = {\n",
        "                'rmse': branch_rmse,\n",
        "                'mae': branch_mae, \n",
        "                'count': np.sum(mask)\n",
        "            }\n",
        "    \n",
        "    if branch_results:\n",
        "        # RMSE 기준 정렬\n",
        "        sorted_branches = sorted(branch_results.items(), key=lambda x: x[1]['rmse'])\n",
        "        \n",
        "        print(f\"   🥇 RMSE 우수 브랜치 (Top 5):\")\n",
        "        for i, (branch, metrics) in enumerate(sorted_branches[:5], 1):\n",
        "            print(f\"      {i}. 브랜치 {branch}: RMSE={metrics['rmse']:7.4f} | MAE={metrics['mae']:7.4f} | {metrics['count']:,}개\")\n",
        "        \n",
        "        print(f\"   🥉 RMSE 개선 필요 브랜치 (Bottom 5):\")\n",
        "        for i, (branch, metrics) in enumerate(sorted_branches[-5:], 1):\n",
        "            print(f\"      {i}. 브랜치 {branch}: RMSE={metrics['rmse']:7.4f} | MAE={metrics['mae']:7.4f} | {metrics['count']:,}개\")\n",
        "        \n",
        "        # 브랜치별 성능 통계\n",
        "        rmse_values = [v['rmse'] for v in branch_results.values()]\n",
        "        print(f\"\\n   📈 브랜치별 RMSE 통계:\")\n",
        "        print(f\"      평균: {np.mean(rmse_values):.4f}\")\n",
        "        print(f\"      표준편차: {np.std(rmse_values):.4f}\")\n",
        "        print(f\"      최소: {np.min(rmse_values):.4f}\")\n",
        "        print(f\"      최대: {np.max(rmse_values):.4f}\")\n",
        "    \n",
        "    # 시즌×브랜치 조합별 RMSE (상위 10개만)\n",
        "    print(f\"\\n🔥 시즌×브랜치 조합별 RMSE (Ranking):\")\n",
        "    combo_results = []\n",
        "    \n",
        "    for season in [0, 1]:\n",
        "        for branch in test_df['branch_id'].unique():\n",
        "            mask = (test_df['heating_season'] == season) & (test_df['branch_id'] == branch) & valid_mask\n",
        "            if np.sum(mask) > 1:\n",
        "                combo_rmse = np.sqrt(mean_squared_error(y_true[mask], y_pred[mask]))\n",
        "                combo_name = f\"{season_names[season]}_{branch}\"\n",
        "                combo_results.append((combo_name, combo_rmse, np.sum(mask)))\n",
        "    \n",
        "    # RMSE 기준 정렬하여 표시\n",
        "    combo_results.sort(key=lambda x: x[1])\n",
        "    for i, (combo_name, rmse, count) in enumerate(combo_results, 1):\n",
        "        print(f\"   {i:2d}. {combo_name:15s}: RMSE={rmse:7.4f} | {count:,}개\")\n",
        "    \n",
        "    # 훈련된 모델들의 최적화 성능과 실제 테스트 성능 비교\n",
        "    print(f\"\\n🔍 모델 최적화 vs 실제 성능 비교:\")\n",
        "    optimization_rmses = [v['best_score'] for v in training_results.values() if v.get('best_score') is not None]\n",
        "    \n",
        "    if optimization_rmses:\n",
        "        print(f\"   훈련시 최적화 RMSE: 평균={np.mean(optimization_rmses):.4f}, 범위=[{np.min(optimization_rmses):.4f}, {np.max(optimization_rmses):.4f}]\")\n",
        "        print(f\"   실제 테스트 RMSE: {overall_rmse:.4f}\")\n",
        "        print(f\"   성능 차이: {abs(overall_rmse - np.mean(optimization_rmses)):.4f}\")\n",
        "    \n",
        "else:\n",
        "    print(f\"\\n⚠️ 테스트 데이터에 heat_demand 컬럼이 없어서 RMSE 평가를 수행할 수 없습니다.\")\n",
        "    print(f\"   예측 결과만 저장되었습니다.\")\n",
        "    \n",
        "    # 예측값 기본 통계\n",
        "    print(f\"\\n📊 예측값 기본 통계:\")\n",
        "    print(f\"   개수: {len(result_df):,}개\")\n",
        "    print(f\"   평균: {result_df['pred_heat_demand'].mean():.2f}\")\n",
        "    print(f\"   중앙값: {result_df['pred_heat_demand'].median():.2f}\")\n",
        "    print(f\"   표준편차: {result_df['pred_heat_demand'].std():.2f}\")\n",
        "    print(f\"   범위: [{result_df['pred_heat_demand'].min():.2f}, {result_df['pred_heat_demand'].max():.2f}]\")\n",
        "    \n",
        "    # 시즌별 예측 통계\n",
        "    print(f\"\\n📈 시즌별 예측 통계:\")\n",
        "    for season in [0, 1]:\n",
        "        season_data = result_df[result_df['heating_season'] == season]['pred_heat_demand']\n",
        "        if len(season_data) > 0:\n",
        "            season_name = '비난방시즌' if season == 0 else '난방시즌'\n",
        "            print(f\"   {season_name}: 평균={season_data.mean():.2f}, 개수={len(season_data):,}개\")\n",
        "\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlR68tz9W1AF"
      },
      "source": [
        "## 🔟 모델 정보 저장"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "xk3Cf_3YWyKq"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "💾 모델 정보 저장...\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'json' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 25\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# JSON 파일로 저장\u001b[39;00m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mmodel_info_and_results.json\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mw\u001b[39m\u001b[33m'\u001b[39m, encoding=\u001b[33m'\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m     \u001b[43mjson\u001b[49m.dump(model_info, f, indent=\u001b[32m2\u001b[39m, ensure_ascii=\u001b[38;5;28;01mFalse\u001b[39;00m, default=\u001b[38;5;28mstr\u001b[39m)\n\u001b[32m     27\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m📁 model_info_and_results.json 저장 완료\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# 간단한 요약 출력\u001b[39;00m\n",
            "\u001b[31mNameError\u001b[39m: name 'json' is not defined"
          ]
        }
      ],
      "source": [
        "# 모델 정보 및 결과 저장\n",
        "print(\"💾 모델 정보 저장...\")\n",
        "\n",
        "# 훈련 결과 및 모델 정보를 JSON으로 저장\n",
        "model_info = {\n",
        "    'total_models': len(models),\n",
        "    'successful_models': len([k for k, v in training_results.items() if v.get('best_score') is not None]),\n",
        "    'training_results': training_results,\n",
        "    'prediction_stats': prediction_stats if 'prediction_stats' in locals() else {},\n",
        "    'feature_columns': models[list(models.keys())[0]].feature_cols if models else [],\n",
        "    'optimization_trials_per_model': n_trials_per_model,\n",
        "    'total_training_time_minutes': total_time_min if 'total_time_min' in locals() else 0\n",
        "}\n",
        "\n",
        "# RMSE 결과 추가 (있는 경우)\n",
        "if 'heat_demand' in test_df.columns:\n",
        "    model_info['evaluation_results'] = {\n",
        "        'overall_rmse': overall_rmse,\n",
        "        'overall_mae': overall_mae,\n",
        "        'correlation': correlation\n",
        "    }\n",
        "\n",
        "# JSON 파일로 저장\n",
        "with open('model_info_and_results.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(model_info, f, indent=2, ensure_ascii=False, default=str)\n",
        "\n",
        "print(\"📁 model_info_and_results.json 저장 완료\")\n",
        "\n",
        "# 간단한 요약 출력\n",
        "print(f\"\\n📋 모델 정보 요약:\")\n",
        "print(f\"   🔧 총 모델 수: {model_info['total_models']}개\")\n",
        "print(f\"   ✅ 성공한 모델: {model_info['successful_models']}개\")\n",
        "print(f\"   📊 사용 특성 수: {len(model_info['feature_columns'])}개\")\n",
        "print(f\"   🎯 모델당 최적화 시도: {model_info['optimization_trials_per_model']}회\")\n",
        "\n",
        "# Google Drive 저장 (Colab 환경)\n",
        "if IN_COLAB:\n",
        "    save_drive = input(\"\\nGoogle Drive에 결과 파일들을 저장하시겠습니까? (y/n): \").lower() == 'y'\n",
        "    if save_drive:\n",
        "        try:\n",
        "            !cp {output_filename} /content/drive/MyDrive/\n",
        "            !cp model_info_and_results.json /content/drive/MyDrive/\n",
        "            print(\"✅ Google Drive 저장 완료!\")\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Google Drive 저장 실패: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "leJLw4dVi6IW"
      },
      "source": [
        "## 🎯 최종 요약"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K8stlKlsi6IX"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"🔥 지역난방 열수요 예측: 시즌별-브랜치별 XGBoost 모델 - 최종 요약\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(f\"\\n🏗️ 모델 구성:\")\n",
        "print(f\"   📊 XGBoost 개별 모델 (시즌별 × 브랜치별)\")\n",
        "print(f\"   🎯 Optuna TPE 하이퍼파라미터 최적화\")\n",
        "print(f\"   📋 총 모델 수: {len(models)}개\")\n",
        "print(f\"   ✅ 성공적 훈련: {len([k for k, v in training_results.items() if v.get('best_score') is not None])}개\")\n",
        "\n",
        "print(f\"\\n📈 특성 엔지니어링:\")\n",
        "print(f\"   ⭐ HDD, wind_chill, 온도 제곱/세제곱\")\n",
        "print(f\"   🔄 순환형 인코딩 (시간, 월, 요일)\")\n",
        "print(f\"   📋 범주형: heating_season, 피크시간, 기온범주, 강수강도\")\n",
        "print(f\"   🧮 상호작용: 습도×기온, 월×일\")\n",
        "# print(f\"   📏 StandardScaler 정규화\")\n",
        "\n",
        "print(f\"\\n🎯 모델링 전략:\")\n",
        "print(f\"   ❄️ 난방시즌 (10,11,12,1,2,3,4월) 전용 모델\")\n",
        "print(f\"   🌞 비난방시즌 (5,6,7,8,9월) 전용 모델\")\n",
        "print(f\"   🏢 브랜치별 개별 모델 (각 지사의 특성 반영)\")\n",
        "print(f\"   ⚡ XGBoost with Early Stopping\")\n",
        "\n",
        "print(f\"\\n🔍 최적화 설정:\")\n",
        "print(f\"   📊 Optuna TPE Sampler\")\n",
        "print(f\"   🎯 모델당 {n_trials_per_model}회 시도\")\n",
        "print(f\"   📈 시계열 기반 Train/Validation 분할 (80:20)\")\n",
        "print(f\"   🎪 XGBoost Pruning Callback 사용\")\n",
        "\n",
        "if 'heat_demand' in test_df.columns:\n",
        "    print(f\"\\n🏆 최종 성능:\")\n",
        "    print(f\"   📊 전체 RMSE: {overall_rmse:.4f}\")\n",
        "    print(f\"   📏 전체 MAE: {overall_mae:.4f}\")\n",
        "    print(f\"   📈 상관계수: {correlation:.4f}\")\n",
        "\n",
        "# 최고 성능 모델 정보\n",
        "if successful_models is not None and len(successful_models) > 0:\n",
        "    best_model_name = successful_models['best_score'].idxmin()\n",
        "    best_score = successful_models.loc[best_model_name, 'best_score']\n",
        "    print(f\"\\n🥇 최고 성능 모델: {best_model_name} (RMSE: {best_score:.4f})\")\n",
        "\n",
        "print(f\"\\n📁 출력 파일:\")\n",
        "print(f\"   • {output_filename} - 예측 결과\")\n",
        "print(f\"   • model_info_and_results.json - 모델 정보 및 훈련 결과\")\n",
        "print(f\"   • 핵심 컬럼: pred_heat_demand (예측값)\")\n",
        "\n",
        "print(f\"\\n⏱️ 실행 시간:\")\n",
        "if 'total_time_min' in locals():\n",
        "    print(f\"   🚀 총 훈련 시간: {total_time_min:.1f}분\")\n",
        "    print(f\"   ⚡ 평균 모델당: {total_time_min*60/len(models):.1f}초\")\n",
        "\n",
        "print(f\"\\n🎉 지역난방 열수요 예측 완료!\")\n",
        "print(f\"🔬 혁신 포인트: 시즌×브랜치 세분화 + Optuna 자동 최적화\")\n",
        "print(f\"📊 총 {len(models)}개 모델로 정밀한 지역별-시즌별 예측 구현\")\n",
        "print(\"=\"*80)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
