{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9N8kUTzi6IA"
      },
      "source": [
        "# 🔥 지역난방 열수요 예측: 시즌별-브랜치별 XGBoost 모델\n",
        "\n",
        "## 📋 모델링 전략\n",
        "- **시즌 분할**: Heating Season vs Non-Heating Season\n",
        "- **브랜치별 개별 모델**: 각 branch_id마다 전용 모델\n",
        "- **XGBoost**: 모든 모델에 XGBoost 사용\n",
        "- **하이퍼파라미터 최적화**: Optuna TPE 사용\n",
        "- **총 모델 수**: 38개 (2시즌 × 19브랜치)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6nmbT6Edi6ID"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "💻 로컬 환경에서 실행 중...\n"
          ]
        }
      ],
      "source": [
        "# Google Colab 환경 확인 및 패키지 설치\n",
        "import sys\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "\n",
        "if IN_COLAB:\n",
        "    print(\"🔥 Google Colab 환경에서 실행 중...\")\n",
        "    !pip install xgboost optuna\n",
        "    from google.colab import files, drive\n",
        "    print(\"✅ 패키지 설치 완료!\")\n",
        "else:\n",
        "    print(\"💻 로컬 환경에서 실행 중...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "cc2w0lOti6IH"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📚 라이브러리 로드 완료!\n"
          ]
        }
      ],
      "source": [
        "# 라이브러리 import\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from tqdm.auto import tqdm\n",
        "import pickle\n",
        "import json\n",
        "\n",
        "# 머신러닝\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
        "import xgboost as xgb\n",
        "\n",
        "# Optuna\n",
        "import optuna\n",
        "from optuna.integration import XGBoostPruningCallback\n",
        "from optuna.samplers import TPESampler\n",
        "\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "print(\"📚 라이브러리 로드 완료!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # 데이터 분할: 2021-2022년 (훈련용) vs 2023년 (테스트용)\n",
        "# print(\"📊 데이터 분할 시작...\")\n",
        "\n",
        "# # train_heat.csv 파일 읽기\n",
        "# train_heat = pd.read_csv('train_heat.csv')\n",
        "# print(f\"원본 데이터 크기: {train_heat.shape}\")\n",
        "\n",
        "# # 데이터 확인\n",
        "# print(\"\\n📋 데이터 구조 확인:\")\n",
        "# print(train_heat.columns.tolist())\n",
        "# print(\"\\n첫 5행:\")\n",
        "# print(train_heat.head())\n",
        "\n",
        "# # 임시 datetime 컬럼 생성 (원본 tm 컬럼은 그대로 유지)\n",
        "# train_heat['temp_datetime'] = pd.to_datetime(train_heat['train_heat.tm'], format='%Y%m%d%H')\n",
        "\n",
        "# print(f\"\\n📅 날짜 범위: {train_heat['temp_datetime'].min()} ~ {train_heat['temp_datetime'].max()}\")\n",
        "\n",
        "# # 연도별 데이터 개수 확인\n",
        "# year_counts = train_heat['temp_datetime'].dt.year.value_counts().sort_index()\n",
        "# print(f\"\\n📊 연도별 데이터 개수:\")\n",
        "# for year, count in year_counts.items():\n",
        "#     print(f\"  {year}년: {count:,}행\")\n",
        "\n",
        "# # 연도별로 데이터 분할 (임시 datetime 컬럼 사용)\n",
        "# train_data_2122 = train_heat[train_heat['temp_datetime'].dt.year.isin([2021, 2022])].copy()\n",
        "# test_data_23 = train_heat[train_heat['temp_datetime'].dt.year == 2023].copy()\n",
        "\n",
        "# # 임시 datetime 컬럼 제거\n",
        "# train_data_2122.drop('temp_datetime', axis=1, inplace=True)\n",
        "# test_data_23.drop('temp_datetime', axis=1, inplace=True)\n",
        "\n",
        "# print(f\"\\n✂️ 분할 결과:\")\n",
        "# print(f\"2021-2022년 데이터 크기: {train_data_2122.shape}\")\n",
        "# print(f\"2023년 데이터 크기: {test_data_23.shape}\")\n",
        "\n",
        "# # 파일로 저장\n",
        "# train_data_2122.to_csv('train_data_2122.csv', index=False)\n",
        "# test_data_23.to_csv('test_data_23.csv', index=False)\n",
        "\n",
        "# print(\"\\n✅ 데이터 분할 및 저장 완료!\")\n",
        "# print(f\"- train_data_2122.csv: {train_data_2122.shape[0]:,}행\")\n",
        "# print(f\"- test_data_23.csv: {test_data_23.shape[0]:,}행\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "HsWjgGvyi6II"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ 파일 경로 설정 완료\n"
          ]
        }
      ],
      "source": [
        "# 데이터 파일 로드\n",
        "if IN_COLAB:\n",
        "    print(\"📁 파일 업로드 방법 선택:\")\n",
        "    print(\"1. 직접 업로드\")\n",
        "    print(\"2. Google Drive\")\n",
        "\n",
        "    method = input(\"선택 (1 또는 2): \")\n",
        "\n",
        "    if method == \"1\":\n",
        "        uploaded = files.upload()\n",
        "        files_list = list(uploaded.keys())\n",
        "        train_path = [f for f in files_list if 'train' in f.lower()][0]\n",
        "        test_path = [f for f in files_list if 'test' in f.lower()][0]\n",
        "    else:\n",
        "        drive.mount('/content/drive')\n",
        "        train_path = \"/content/drive/MyDrive/train_heat.csv\"\n",
        "        test_path = \"/content/drive/MyDrive/test_heat.csv\"\n",
        "else:\n",
        "    train_path = 'dataset/train_data_2122.csv'\n",
        "    test_path = 'dataset/test_data_23.csv'\n",
        "\n",
        "print(f\"✅ 파일 경로 설정 완료\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BnYi_t0i6IJ"
      },
      "source": [
        "## 1️⃣ 데이터 로드 및 전처리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "iy4VEB5gi6IK"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📊 데이터 로드 및 전처리...\n",
            "   훈련: (332861, 15), 테스트: (166440, 15)\n",
            "   기간: 2021-01-01 01:00:00 ~ 2023-12-31 23:00:00\n",
            "   브랜치: ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S']\n"
          ]
        }
      ],
      "source": [
        "def load_and_preprocess(train_path, test_path):\n",
        "    print(\"📊 데이터 로드 및 전처리...\")\n",
        "\n",
        "    # 데이터 로드\n",
        "    train_df = pd.read_csv(train_path)\n",
        "    test_df = pd.read_csv(test_path)\n",
        "\n",
        "    def process_df(df):\n",
        "        # 컬럼명 정리\n",
        "        if 'Unnamed: 0' in df.columns:\n",
        "            df = df.drop(columns=['Unnamed: 0'])\n",
        "        df.columns = [col.replace('train_heat.', '') for col in df.columns]\n",
        "\n",
        "        # 시간 변수\n",
        "        df['datetime'] = pd.to_datetime(df['tm'], format='%Y%m%d%H')\n",
        "        # df['year'] = df['datetime'].dt.year\n",
        "        df['month'] = df['datetime'].dt.month\n",
        "        # df['day'] = df['datetime'].dt.day\n",
        "        df['hour'] = df['datetime'].dt.hour\n",
        "        df['dayofweek'] = df['datetime'].dt.dayofweek\n",
        "\n",
        "        # 결측치 처리\n",
        "        missing_cols = ['ta', 'wd', 'ws', 'rn_day', 'rn_hr1', 'hm', 'si', 'ta_chi']\n",
        "        if 'heat_demand' in df.columns:\n",
        "            missing_cols.append('heat_demand')\n",
        "\n",
        "        for col in missing_cols:\n",
        "            if col in df.columns:\n",
        "                df[col] = df[col].replace(-99, np.nan)\n",
        "\n",
        "        # wd -9.9 결측치 처리\n",
        "        df.loc[df['wd'] == -9.9, 'wd'] = np.nan\n",
        "\n",
        "        # 일사량 야간 처리\n",
        "        if 'si' in df.columns:\n",
        "            night_mask = (df['hour'] < 8) | (df['hour'] > 18)\n",
        "            df.loc[night_mask & df['si'].isna(), 'si'] = 0\n",
        "\n",
        "        # 지사별 보간\n",
        "        df = df.sort_values(['branch_id', 'datetime'])\n",
        "        numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
        "\n",
        "        for branch in df['branch_id'].unique():\n",
        "            mask = df['branch_id'] == branch\n",
        "            df.loc[mask, numeric_cols] = df.loc[mask, numeric_cols].interpolate().fillna(method='ffill').fillna(method='bfill')\n",
        "\n",
        "        return df\n",
        "\n",
        "    train_df = process_df(train_df)\n",
        "    test_df = process_df(test_df)\n",
        "\n",
        "    print(f\"   훈련: {train_df.shape}, 테스트: {test_df.shape}\")\n",
        "    print(f\"   기간: {train_df['datetime'].min()} ~ {test_df['datetime'].max()}\")\n",
        "    print(f\"   브랜치: {sorted(train_df['branch_id'].unique())}\")\n",
        "\n",
        "    return train_df, test_df\n",
        "\n",
        "train_df, test_df = load_and_preprocess(train_path, test_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnbWsoYUi6IK"
      },
      "source": [
        "## 2️⃣ 파생변수 생성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "qmwGrilMi6IL"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ 파생변수 생성 완료: 37개 컬럼\n"
          ]
        }
      ],
      "source": [
        "def create_features(df):\n",
        "    \"\"\"HDD, wind_chill, 순환형 인코딩, 범주형 변수 생성\"\"\"\n",
        "    df = df.copy()\n",
        "\n",
        "    # ⭐ HDD (수치형)\n",
        "    if 'ta' in df.columns:\n",
        "        df['HDD_18'] = np.maximum(18 - df['ta'], 0)\n",
        "        df['HDD_20'] = np.maximum(20 - df['ta'], 0)\n",
        "\n",
        "    # ⭐ wind_chill (수치형)\n",
        "    if 'ta' in df.columns and 'ws' in df.columns:\n",
        "        df['wind_chill'] = np.where(\n",
        "            (df['ta'] <= 10) & (df['ws'] > 0),\n",
        "            13.12 + 0.6215 * df['ta'] - 11.37 * (df['ws'] ** 0.16) + 0.3965 * df['ta'] * (df['ws'] ** 0.16),\n",
        "            df['ta']\n",
        "        )\n",
        "\n",
        "    # ⭐ heating_season (범주형)\n",
        "    df['heating_season'] = df['month'].isin([10, 11, 12, 1, 2, 3, 4]).astype(int)\n",
        "\n",
        "    # 시간대 범주형\n",
        "    df['is_weekend'] = (df['dayofweek'] >= 5).astype(int)\n",
        "    df['is_peak_morning'] = ((df['hour'] >= 7) & (df['hour'] <= 9)).astype(int)\n",
        "    df['is_peak_evening'] = ((df['hour'] >= 18) & (df['hour'] <= 22)).astype(int)\n",
        "    df['is_night'] = ((df['hour'] >= 23) | (df['hour'] <= 5)).astype(int)\n",
        "\n",
        "    # 피크시간 통합\n",
        "    df['peak_time_category'] = 0\n",
        "    df.loc[df['is_peak_morning'] == 1, 'peak_time_category'] = 1\n",
        "    df.loc[df['is_peak_evening'] == 1, 'peak_time_category'] = 2\n",
        "    df.loc[df['is_night'] == 1, 'peak_time_category'] = 3\n",
        "\n",
        "    # ⭐ 기온 범주 (범주형)\n",
        "    if 'ta' in df.columns:\n",
        "        df['temp_category'] = pd.cut(df['ta'],\n",
        "                                   bins=[-np.inf, 0, 10, 20, 30, np.inf],\n",
        "                                   labels=[0, 1, 2, 3, 4]).astype(int)\n",
        "\n",
        "    # ⭐ 강수 강도 (범주형)\n",
        "    if 'rn_day' in df.columns:\n",
        "        df['rain_intensity'] = pd.cut(df['rn_day'],\n",
        "                                   bins=[-1, 0, 1, 5, 10, np.inf],\n",
        "                                   labels=[0, 1, 2, 3, 4]).astype(int)\n",
        "\n",
        "    # ⭐ 순환형 인코딩 (시간 cos, sin)\n",
        "    df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)\n",
        "    df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)\n",
        "    df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)\n",
        "    df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)\n",
        "    df['dayofweek_sin'] = np.sin(2 * np.pi * df['dayofweek'] / 7)\n",
        "    df['dayofweek_cos'] = np.cos(2 * np.pi * df['dayofweek'] / 7)\n",
        "\n",
        "    # 시간 기반 파생변수\n",
        "    df['hour_squared'] = df['hour'] ** 2\n",
        "    df['month_day_interaction'] = df['month'] * df['datetime'].dt.day\n",
        "    \n",
        "    # 기온 관련 파생변수\n",
        "    if 'ta' in df.columns:\n",
        "        df['ta_squared'] = df['ta'] ** 2\n",
        "        df['ta_cubed'] = df['ta'] ** 3\n",
        "    \n",
        "    # 습도와 기온 상호작용\n",
        "    if 'hm' in df.columns and 'ta' in df.columns:\n",
        "        df['hm_ta_interaction'] = df['hm'] * df['ta']\n",
        "\n",
        "    return df\n",
        "\n",
        "# 파생변수 생성\n",
        "train_df = create_features(train_df)\n",
        "test_df = create_features(test_df)\n",
        "\n",
        "print(f\"✅ 파생변수 생성 완료: {train_df.shape[1]}개 컬럼\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BnrDxhRi6IM"
      },
      "source": [
        "## 3️⃣ 시즌별-브랜치별 데이터 분할"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "jmdSkH3Ci6IN"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📊 데이터 분할 정보:\n",
            "   브랜치: 19개 - ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S']\n",
            "   시즌: 2개 - ['비난방', '난방']\n",
            "   총 조합: 38개\n",
            "   비난방_A: 7,344개 데이터\n",
            "   비난방_B: 7,344개 데이터\n",
            "   비난방_C: 7,344개 데이터\n",
            "   비난방_D: 7,344개 데이터\n",
            "   비난방_E: 7,344개 데이터\n",
            "   비난방_F: 7,344개 데이터\n",
            "   비난방_G: 7,344개 데이터\n",
            "   비난방_H: 7,344개 데이터\n",
            "   비난방_I: 7,344개 데이터\n",
            "   비난방_J: 7,344개 데이터\n",
            "   비난방_K: 7,344개 데이터\n",
            "   비난방_L: 7,344개 데이터\n",
            "   비난방_M: 7,344개 데이터\n",
            "   비난방_N: 7,344개 데이터\n",
            "   비난방_O: 7,344개 데이터\n",
            "   비난방_P: 7,344개 데이터\n",
            "   비난방_Q: 7,344개 데이터\n",
            "   비난방_R: 7,344개 데이터\n",
            "   비난방_S: 7,344개 데이터\n",
            "   난방_A: 10,175개 데이터\n",
            "   난방_B: 10,175개 데이터\n",
            "   난방_C: 10,175개 데이터\n",
            "   난방_D: 10,175개 데이터\n",
            "   난방_E: 10,175개 데이터\n",
            "   난방_F: 10,175개 데이터\n",
            "   난방_G: 10,175개 데이터\n",
            "   난방_H: 10,175개 데이터\n",
            "   난방_I: 10,175개 데이터\n",
            "   난방_J: 10,175개 데이터\n",
            "   난방_K: 10,175개 데이터\n",
            "   난방_L: 10,175개 데이터\n",
            "   난방_M: 10,175개 데이터\n",
            "   난방_N: 10,175개 데이터\n",
            "   난방_O: 10,175개 데이터\n",
            "   난방_P: 10,175개 데이터\n",
            "   난방_Q: 10,175개 데이터\n",
            "   난방_R: 10,175개 데이터\n",
            "   난방_S: 10,175개 데이터\n",
            "📊 데이터 분할 정보:\n",
            "   브랜치: 19개 - ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S']\n",
            "   시즌: 2개 - ['비난방', '난방']\n",
            "   총 조합: 38개\n",
            "   비난방_A: 3,672개 데이터\n",
            "   비난방_B: 3,672개 데이터\n",
            "   비난방_C: 3,672개 데이터\n",
            "   비난방_D: 3,672개 데이터\n",
            "   비난방_E: 3,672개 데이터\n",
            "   비난방_F: 3,672개 데이터\n",
            "   비난방_G: 3,672개 데이터\n",
            "   비난방_H: 3,672개 데이터\n",
            "   비난방_I: 3,672개 데이터\n",
            "   비난방_J: 3,672개 데이터\n",
            "   비난방_K: 3,672개 데이터\n",
            "   비난방_L: 3,672개 데이터\n",
            "   비난방_M: 3,672개 데이터\n",
            "   비난방_N: 3,672개 데이터\n",
            "   비난방_O: 3,672개 데이터\n",
            "   비난방_P: 3,672개 데이터\n",
            "   비난방_Q: 3,672개 데이터\n",
            "   비난방_R: 3,672개 데이터\n",
            "   비난방_S: 3,672개 데이터\n",
            "   난방_A: 5,088개 데이터\n",
            "   난방_B: 5,088개 데이터\n",
            "   난방_C: 5,088개 데이터\n",
            "   난방_D: 5,088개 데이터\n",
            "   난방_E: 5,088개 데이터\n",
            "   난방_F: 5,088개 데이터\n",
            "   난방_G: 5,088개 데이터\n",
            "   난방_H: 5,088개 데이터\n",
            "   난방_I: 5,088개 데이터\n",
            "   난방_J: 5,088개 데이터\n",
            "   난방_K: 5,088개 데이터\n",
            "   난방_L: 5,088개 데이터\n",
            "   난방_M: 5,088개 데이터\n",
            "   난방_N: 5,088개 데이터\n",
            "   난방_O: 5,088개 데이터\n",
            "   난방_P: 5,088개 데이터\n",
            "   난방_Q: 5,088개 데이터\n",
            "   난방_R: 5,088개 데이터\n",
            "   난방_S: 5,088개 데이터\n",
            "\n",
            "✅ 훈련 데이터: 38개 분할\n",
            "✅ 테스트 데이터: 38개 분할\n"
          ]
        }
      ],
      "source": [
        "# 시즌별-브랜치별 데이터 분할\n",
        "def split_by_season_and_branch(df):\n",
        "    data_splits = {}\n",
        "    \n",
        "    branches = sorted(df['branch_id'].unique())\n",
        "    seasons = [0, 1]  # 0: 비난방시즌, 1: 난방시즌\n",
        "    season_names = {0: '비난방', 1: '난방'}\n",
        "    \n",
        "    print(f\"📊 데이터 분할 정보:\")\n",
        "    print(f\"   브랜치: {len(branches)}개 - {branches}\")\n",
        "    print(f\"   시즌: {len(seasons)}개 - {[season_names[s] for s in seasons]}\")\n",
        "    print(f\"   총 조합: {len(branches) * len(seasons)}개\")\n",
        "    \n",
        "    for season in seasons:\n",
        "        for branch in branches:\n",
        "            key = f\"{season_names[season]}_{branch}\"\n",
        "            \n",
        "            # 시즌과 브랜치로 필터링\n",
        "            subset = df[(df['heating_season'] == season) & (df['branch_id'] == branch)].copy()\n",
        "            \n",
        "            if len(subset) > 0:\n",
        "                data_splits[key] = subset\n",
        "                print(f\"   {key}: {len(subset):,}개 데이터\")\n",
        "            else:\n",
        "                print(f\"   {key}: 데이터 없음 ⚠️\")\n",
        "    \n",
        "    return data_splits\n",
        "\n",
        "# 훈련 및 테스트 데이터 분할\n",
        "train_splits = split_by_season_and_branch(train_df)\n",
        "test_splits = split_by_season_and_branch(test_df)\n",
        "\n",
        "print(f\"\\n✅ 훈련 데이터: {len(train_splits)}개 분할\")\n",
        "print(f\"✅ 테스트 데이터: {len(test_splits)}개 분할\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 📌 Validation시 월별 추출"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_temporal_split_indices(df, test_size=0.2, min_val_samples=10):\n",
        "    \"\"\"시간 기반 분할 인덱스 반환\"\"\"\n",
        "    \n",
        "    month_counts = df['month'].value_counts()\n",
        "    valid_months = month_counts[month_counts >= min_val_samples * 2].index\n",
        "    \n",
        "    if len(valid_months) < 3:\n",
        "        # 폴백: 기존 방식\n",
        "        split_idx = int(len(df) * (1 - test_size))\n",
        "        return df.index[:split_idx], df.index[split_idx:]\n",
        "    \n",
        "    train_indices = []\n",
        "    val_indices = []\n",
        "    \n",
        "    for month in valid_months:\n",
        "        month_data = df[df['month'] == month].sort_values('datetime')\n",
        "        val_size = max(min_val_samples, int(len(month_data) * test_size))\n",
        "        \n",
        "        train_indices.extend(month_data.iloc[:-val_size].index)\n",
        "        val_indices.extend(month_data.iloc[-val_size:].index)\n",
        "    \n",
        "    print(f\"      📅 월별 분할: {len(valid_months)}개월, 검증 {len(val_indices)}개\")\n",
        "    \n",
        "    return train_indices, val_indices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmL7oLW1i6IN"
      },
      "source": [
        "## 4️⃣ XGBoost 모델 클래스 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "XGBoost 버전: 3.0.2\n",
            "✅ 버전 호환 XGBoost 모델 클래스 정의 완료\n"
          ]
        }
      ],
      "source": [
        "# XGBoost 버전 확인\n",
        "import xgboost as xgb\n",
        "print(f\"XGBoost 버전: {xgb.__version__}\")\n",
        "\n",
        "# 버전 호환 XGBoost 모델 클래스\n",
        "class OptimizedXGBoostModel:\n",
        "    def __init__(self, model_name):\n",
        "        self.model_name = model_name\n",
        "        self.model = None\n",
        "        self.best_params = None\n",
        "        self.feature_cols = None\n",
        "        self.study = None\n",
        "        self.best_score = None\n",
        "        \n",
        "        # XGBoost 버전 확인\n",
        "        self.xgb_version = xgb.__version__\n",
        "        self.use_callbacks = self._check_callbacks_support()\n",
        "        \n",
        "    def _check_callbacks_support(self):\n",
        "        \"\"\"XGBoost 버전에 따른 callbacks 지원 여부 확인\"\"\"\n",
        "        try:\n",
        "            # 버전 1.4.0 이상에서 callbacks 지원\n",
        "            version_parts = self.xgb_version.split('.')\n",
        "            major = int(version_parts[0])\n",
        "            minor = int(version_parts[1]) if len(version_parts) > 1 else 0\n",
        "            \n",
        "            if major > 1 or (major == 1 and minor >= 4):\n",
        "                return True\n",
        "            else:\n",
        "                return False\n",
        "        except:\n",
        "            return False\n",
        "        \n",
        "    def define_feature_columns(self, df):\n",
        "        \"\"\"특성 컬럼 정의\"\"\"\n",
        "        exclude_cols = [\n",
        "            'tm', 'datetime', 'year', 'heat_demand', 'branch_id'\n",
        "        ]\n",
        "        \n",
        "        self.feature_cols = [col for col in df.columns \n",
        "                           if col not in exclude_cols and df[col].dtype in ['int64', 'float64']]\n",
        "        \n",
        "        print(f\"   📋 {self.model_name}: {len(self.feature_cols)}개 특성 사용\")\n",
        "        return self.feature_cols\n",
        "    \n",
        "    def objective(self, trial, X_train, y_train, X_val, y_val):\n",
        "        \"\"\"Optuna 목적 함수\"\"\"\n",
        "        # 하이퍼파라미터 탐색 공간 정의 (early stopping 제거하고 n_estimators로 제어)\n",
        "        params = {\n",
        "            'objective': 'reg:squarederror',\n",
        "            'booster': 'gbtree',\n",
        "            'lambda': trial.suggest_float('lambda', 1e-8, 1.0, log=True),\n",
        "            'alpha': trial.suggest_float('alpha', 1e-8, 1.0, log=True),\n",
        "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.3, 1.0),\n",
        "            'subsample': trial.suggest_float('subsample', 0.4, 1.0),\n",
        "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
        "            'n_estimators': trial.suggest_int('n_estimators', 50, 500),  # 범위 축소로 안정성 확보\n",
        "            'max_depth': trial.suggest_int('max_depth', 3, 8),\n",
        "            'min_child_weight': trial.suggest_int('min_child_weight', 1, 8),\n",
        "            'random_state': 42,\n",
        "            'n_jobs': -1,\n",
        "            'verbosity': 0\n",
        "        }\n",
        "        \n",
        "        # 모델 생성 및 간단한 훈련 (early stopping 없이)\n",
        "        model = xgb.XGBRegressor(**params)\n",
        "        model.fit(X_train, y_train, verbose=False)\n",
        "        \n",
        "        # 검증 예측\n",
        "        y_pred = model.predict(X_val)\n",
        "        rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
        "        \n",
        "        return rmse\n",
        "    \n",
        "    def fit(self, df, target_col='heat_demand', n_trials=30):\n",
        "        \"\"\"모델 훈련 (Optuna 최적화 포함)\"\"\"\n",
        "        print(f\"\\n🔍 {self.model_name} 모델 훈련 시작...\")\n",
        "        print(f\"   🔧 XGBoost 버전: {self.xgb_version}, Callbacks 지원: {self.use_callbacks}\")\n",
        "        \n",
        "        if len(df) < 10:\n",
        "            print(f\"   ⚠️ 데이터 부족 ({len(df)}개) - 기본 모델 사용\")\n",
        "            self._fit_basic_model(df, target_col)\n",
        "            return\n",
        "        \n",
        "        # 🔥 1. 분할 인덱스 먼저 구하기 (datetime 있을 때)\n",
        "        train_indices, val_indices = get_temporal_split_indices(df, test_size=0.2)\n",
        "        \n",
        "        # 🔥 2. 특성 컬럼 정의 (datetime 제거)\n",
        "        self.define_feature_columns(df)\n",
        "        \n",
        "        # 🔥 3. X, y 생성 (datetime 없음)\n",
        "        X = df[self.feature_cols].copy()\n",
        "        y = df[target_col].copy()\n",
        "        \n",
        "        # 🔥 4. 인덱스로 분할\n",
        "        X_train = X.loc[train_indices]\n",
        "        y_train = y.loc[train_indices]\n",
        "        X_val = X.loc[val_indices]\n",
        "        y_val = y.loc[val_indices]\n",
        "        \n",
        "        print(f\"      📊 훈련: {len(X_train):,}개, 검증: {len(X_val):,}개\")\n",
        "        \n",
        "        if len(X_train) < 5 or len(X_val) < 2:\n",
        "            print(f\"   ⚠️ 분할 후 데이터 부족 - 기본 모델 사용\")\n",
        "            self._fit_basic_model(df, target_col)\n",
        "            return\n",
        "        \n",
        "        # Optuna 최적화\n",
        "        print(f\"   🎯 하이퍼파라미터 최적화: \", end=\"\", flush=True)\n",
        "        \n",
        "        try:\n",
        "            # 모든 로그 끄기\n",
        "            optuna.logging.set_verbosity(optuna.logging.ERROR)\n",
        "            \n",
        "            self.study = optuna.create_study(\n",
        "                direction='minimize',\n",
        "                sampler=TPESampler(seed=42),\n",
        "                study_name=f\"xgb_{self.model_name}\"\n",
        "            )\n",
        "            \n",
        "            # 진행상황 표시를 위한 콜백\n",
        "            def progress_callback(study, trial):\n",
        "                print(f\"\\r   🎯 하이퍼파라미터 최적화: {len(study.trials)}/{n_trials} (Best RMSE: {study.best_value:.4f})\", end=\"\", flush=True)\n",
        "            \n",
        "            # 최적화 실행\n",
        "            self.study.optimize(\n",
        "                lambda trial: self.objective(trial, X_train, y_train, X_val, y_val),\n",
        "                n_trials=n_trials,\n",
        "                callbacks=[progress_callback]\n",
        "            )\n",
        "            \n",
        "            print()  # 줄바꿈\n",
        "            \n",
        "            # 안전한 best_value 접근\n",
        "            if len(self.study.trials) > 0 and self.study.best_trial is not None:\n",
        "                self.best_score = self.study.best_value\n",
        "                self.best_params = self.study.best_params.copy()\n",
        "                \n",
        "                # 기본 파라미터 추가\n",
        "                self.best_params.update({\n",
        "                    'objective': 'reg:squarederror',\n",
        "                    'random_state': 42,\n",
        "                    'n_jobs': -1,\n",
        "                    'verbosity': 0\n",
        "                })\n",
        "                \n",
        "                # 전체 데이터로 최종 훈련 (early stopping 없이 간단하게)\n",
        "                self.model = xgb.XGBRegressor(**self.best_params)\n",
        "                self.model.fit(X, y, verbose=False)\n",
        "                \n",
        "                # 성능 정보\n",
        "                val_pred = self.model.predict(X_val)\n",
        "                val_rmse = np.sqrt(mean_squared_error(y_val, val_pred))\n",
        "                \n",
        "                print(f\"   📈 최적화 완료: Best RMSE = {self.best_score:.4f}\")\n",
        "                print(f\"   📊 검증 RMSE = {val_rmse:.4f}\")\n",
        "                print(f\"   🏆 최적 파라미터: lr={self.best_params.get('learning_rate', 0.1):.3f}, n_est={self.best_params.get('n_estimators', 100)}\")\n",
        "                \n",
        "            else:\n",
        "                print(f\"   ⚠️ 최적화 실패: 유효한 trial 없음 - 기본 모델 사용\")\n",
        "                self._fit_basic_model(df, target_col)\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(f\"\\n   ⚠️ 최적화 실패: {str(e)[:30]}... - 기본 모델 사용\")\n",
        "            self._fit_basic_model(df, target_col)\n",
        "    \n",
        "    def _fit_basic_model(self, df, target_col):\n",
        "        \"\"\"기본 모델 훈련 (최적화 실패 시 사용)\"\"\"\n",
        "        if not hasattr(self, 'feature_cols') or self.feature_cols is None:\n",
        "            self.define_feature_columns(df)\n",
        "        \n",
        "        X = df[self.feature_cols].copy()\n",
        "        y = df[target_col].copy()\n",
        "        \n",
        "        \n",
        "        # 기본 XGBoost 모델 (가장 안전한 파라미터)\n",
        "        self.model = xgb.XGBRegressor(\n",
        "            n_estimators=200,\n",
        "            learning_rate=0.1,\n",
        "            max_depth=6,\n",
        "            min_child_weight=1,\n",
        "            subsample=0.8,\n",
        "            colsample_bytree=0.8,\n",
        "            random_state=42,\n",
        "            n_jobs=-1,\n",
        "            verbosity=0\n",
        "        )\n",
        "        \n",
        "        # 안전한 기본 훈련 (early stopping 없이)\n",
        "        self.model.fit(X, y, verbose=False)\n",
        "        self.best_score = None\n",
        "        self.best_params = None\n",
        "        print(f\"   🔧 기본 모델 훈련 완료\")\n",
        "    \n",
        "    def predict(self, df):\n",
        "        \"\"\"예측\"\"\"\n",
        "        if self.model is None:\n",
        "            return np.full(len(df), 0)\n",
        "        \n",
        "        # 동일한 특성 컬럼 사용\n",
        "        X = df[self.feature_cols].copy()\n",
        "        # X = X.fillna(0)\n",
        "        \n",
        "        # 예측\n",
        "        predictions = self.model.predict(X)\n",
        "        \n",
        "        # 음수 값 처리\n",
        "        predictions = np.maximum(predictions, 0)\n",
        "        \n",
        "        return predictions\n",
        "\n",
        "print(\"✅ 버전 호환 XGBoost 모델 클래스 정의 완료\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SewcIVN_i6IR"
      },
      "source": [
        "## 5️⃣ 38개 모델 훈련"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🚀 38개 XGBoost 모델 훈련 시작!\n",
            "============================================================\n",
            "\n",
            "[ 1/38] 🔥 비난방_A\n",
            "         📊 데이터: 7,344개\n",
            "\n",
            "🔍 비난방_A 모델 훈련 시작...\n",
            "   🔧 XGBoost 버전: 3.0.2, Callbacks 지원: True\n",
            "      📅 월별 분할: 5개월, 검증 1467개\n",
            "   📋 비난방_A: 21개 특성 사용\n",
            "      📊 훈련: 5,877개, 검증: 1,467개\n",
            "   🎯 하이퍼파라미터 최적화: 20/20 (Best RMSE: 8.5144)\n",
            "   📈 최적화 완료: Best RMSE = 8.5144\n",
            "   📊 검증 RMSE = 7.3287\n",
            "   🏆 최적 파라미터: lr=0.073, n_est=245\n",
            "         ✅ 최적화 | RMSE: 8.514 | ⏱️ 10.8초\n",
            "\n",
            "[ 2/38] 🔥 비난방_B\n",
            "         📊 데이터: 7,344개\n",
            "\n",
            "🔍 비난방_B 모델 훈련 시작...\n",
            "   🔧 XGBoost 버전: 3.0.2, Callbacks 지원: True\n",
            "      📅 월별 분할: 5개월, 검증 1467개\n",
            "   📋 비난방_B: 21개 특성 사용\n",
            "      📊 훈련: 5,877개, 검증: 1,467개\n",
            "   🎯 하이퍼파라미터 최적화: 20/20 (Best RMSE: 14.8406)\n",
            "   📈 최적화 완료: Best RMSE = 14.8406\n",
            "   📊 검증 RMSE = 10.4886\n",
            "   🏆 최적 파라미터: lr=0.010, n_est=208\n",
            "         ✅ 최적화 | RMSE: 14.841 | ⏱️ 13.7초\n",
            "\n",
            "[ 3/38] 🔥 비난방_C\n",
            "         📊 데이터: 7,344개\n",
            "\n",
            "🔍 비난방_C 모델 훈련 시작...\n",
            "   🔧 XGBoost 버전: 3.0.2, Callbacks 지원: True\n",
            "      📅 월별 분할: 5개월, 검증 1467개\n",
            "   📋 비난방_C: 21개 특성 사용\n",
            "      📊 훈련: 5,877개, 검증: 1,467개\n",
            "   🎯 하이퍼파라미터 최적화: 20/20 (Best RMSE: 14.7540)\n",
            "   📈 최적화 완료: Best RMSE = 14.7540\n",
            "   📊 검증 RMSE = 12.2772\n",
            "   🏆 최적 파라미터: lr=0.092, n_est=51\n",
            "         ✅ 최적화 | RMSE: 14.754 | ⏱️ 9.6초\n",
            "\n",
            "[ 4/38] 🔥 비난방_D\n",
            "         📊 데이터: 7,344개\n",
            "\n",
            "🔍 비난방_D 모델 훈련 시작...\n",
            "   🔧 XGBoost 버전: 3.0.2, Callbacks 지원: True\n",
            "      📅 월별 분할: 5개월, 검증 1467개\n",
            "   📋 비난방_D: 21개 특성 사용\n",
            "      📊 훈련: 5,877개, 검증: 1,467개\n",
            "   🎯 하이퍼파라미터 최적화: 20/20 (Best RMSE: 13.8510)\n",
            "   📈 최적화 완료: Best RMSE = 13.8510\n",
            "   📊 검증 RMSE = 12.7440\n",
            "   🏆 최적 파라미터: lr=0.022, n_est=358\n",
            "         ✅ 최적화 | RMSE: 13.851 | ⏱️ 8.9초\n",
            "\n",
            "[ 5/38] 🔥 비난방_E\n",
            "         📊 데이터: 7,344개\n",
            "\n",
            "🔍 비난방_E 모델 훈련 시작...\n",
            "   🔧 XGBoost 버전: 3.0.2, Callbacks 지원: True\n",
            "      📅 월별 분할: 5개월, 검증 1467개\n",
            "   📋 비난방_E: 21개 특성 사용\n",
            "      📊 훈련: 5,877개, 검증: 1,467개\n",
            "   🎯 하이퍼파라미터 최적화: 20/20 (Best RMSE: 11.5006)\n",
            "   📈 최적화 완료: Best RMSE = 11.5006\n",
            "   📊 검증 RMSE = 8.9818\n",
            "   🏆 최적 파라미터: lr=0.036, n_est=201\n",
            "         ✅ 최적화 | RMSE: 11.501 | ⏱️ 7.6초\n",
            "\n",
            "[ 6/38] 🔥 비난방_F\n",
            "         📊 데이터: 7,344개\n",
            "\n",
            "🔍 비난방_F 모델 훈련 시작...\n",
            "   🔧 XGBoost 버전: 3.0.2, Callbacks 지원: True\n",
            "      📅 월별 분할: 5개월, 검증 1467개\n",
            "   📋 비난방_F: 21개 특성 사용\n",
            "      📊 훈련: 5,877개, 검증: 1,467개\n",
            "   🎯 하이퍼파라미터 최적화: 20/20 (Best RMSE: 6.6579)\n",
            "   📈 최적화 완료: Best RMSE = 6.6579\n",
            "   📊 검증 RMSE = 5.4606\n",
            "   🏆 최적 파라미터: lr=0.080, n_est=112\n",
            "         ✅ 최적화 | RMSE: 6.658 | ⏱️ 7.6초\n",
            "\n",
            "[ 7/38] 🔥 비난방_G\n",
            "         📊 데이터: 7,344개\n",
            "\n",
            "🔍 비난방_G 모델 훈련 시작...\n",
            "   🔧 XGBoost 버전: 3.0.2, Callbacks 지원: True\n",
            "      📅 월별 분할: 5개월, 검증 1467개\n",
            "   📋 비난방_G: 21개 특성 사용\n",
            "      📊 훈련: 5,877개, 검증: 1,467개\n",
            "   🎯 하이퍼파라미터 최적화: 20/20 (Best RMSE: 11.5953)\n",
            "   📈 최적화 완료: Best RMSE = 11.5953\n",
            "   📊 검증 RMSE = 8.9941\n",
            "   🏆 최적 파라미터: lr=0.011, n_est=208\n",
            "         ✅ 최적화 | RMSE: 11.595 | ⏱️ 12.2초\n",
            "\n",
            "[ 8/38] 🔥 비난방_H\n",
            "         📊 데이터: 7,344개\n",
            "\n",
            "🔍 비난방_H 모델 훈련 시작...\n",
            "   🔧 XGBoost 버전: 3.0.2, Callbacks 지원: True\n",
            "      📅 월별 분할: 5개월, 검증 1467개\n",
            "   📋 비난방_H: 21개 특성 사용\n",
            "      📊 훈련: 5,877개, 검증: 1,467개\n",
            "   🎯 하이퍼파라미터 최적화: 20/20 (Best RMSE: 9.2432)\n",
            "   📈 최적화 완료: Best RMSE = 9.2432\n",
            "   📊 검증 RMSE = 4.6788\n",
            "   🏆 최적 파라미터: lr=0.018, n_est=364\n",
            "         ✅ 최적화 | RMSE: 9.243 | ⏱️ 18.1초\n",
            "\n",
            "[ 9/38] 🔥 비난방_I\n",
            "         📊 데이터: 7,344개\n",
            "\n",
            "🔍 비난방_I 모델 훈련 시작...\n",
            "   🔧 XGBoost 버전: 3.0.2, Callbacks 지원: True\n",
            "      📅 월별 분할: 5개월, 검증 1467개\n",
            "   📋 비난방_I: 21개 특성 사용\n",
            "      📊 훈련: 5,877개, 검증: 1,467개\n",
            "   🎯 하이퍼파라미터 최적화: 20/20 (Best RMSE: 6.4516)\n",
            "   📈 최적화 완료: Best RMSE = 6.4516\n",
            "   📊 검증 RMSE = 5.0290\n",
            "   🏆 최적 파라미터: lr=0.052, n_est=182\n",
            "         ✅ 최적화 | RMSE: 6.452 | ⏱️ 10.8초\n",
            "\n",
            "[10/38] 🔥 비난방_J\n",
            "         📊 데이터: 7,344개\n",
            "\n",
            "🔍 비난방_J 모델 훈련 시작...\n",
            "   🔧 XGBoost 버전: 3.0.2, Callbacks 지원: True\n",
            "      📅 월별 분할: 5개월, 검증 1467개\n",
            "   📋 비난방_J: 21개 특성 사용\n",
            "      📊 훈련: 5,877개, 검증: 1,467개\n",
            "   🎯 하이퍼파라미터 최적화: 20/20 (Best RMSE: 10.3007)\n",
            "   📈 최적화 완료: Best RMSE = 10.3007\n",
            "   📊 검증 RMSE = 7.7568\n",
            "   🏆 최적 파라미터: lr=0.053, n_est=263\n",
            "         ✅ 최적화 | RMSE: 10.301 | ⏱️ 8.3초\n",
            "\n",
            "[11/38] 🔥 비난방_K\n",
            "         📊 데이터: 7,344개\n",
            "\n",
            "🔍 비난방_K 모델 훈련 시작...\n",
            "   🔧 XGBoost 버전: 3.0.2, Callbacks 지원: True\n",
            "      📅 월별 분할: 5개월, 검증 1467개\n",
            "   📋 비난방_K: 21개 특성 사용\n",
            "      📊 훈련: 5,877개, 검증: 1,467개\n",
            "   🎯 하이퍼파라미터 최적화: 20/20 (Best RMSE: 5.8629)\n",
            "   📈 최적화 완료: Best RMSE = 5.8629\n",
            "   📊 검증 RMSE = 4.9498\n",
            "   🏆 최적 파라미터: lr=0.092, n_est=51\n",
            "         ✅ 최적화 | RMSE: 5.863 | ⏱️ 7.7초\n",
            "\n",
            "[12/38] 🔥 비난방_L\n",
            "         📊 데이터: 7,344개\n",
            "\n",
            "🔍 비난방_L 모델 훈련 시작...\n",
            "   🔧 XGBoost 버전: 3.0.2, Callbacks 지원: True\n",
            "      📅 월별 분할: 5개월, 검증 1467개\n",
            "   📋 비난방_L: 21개 특성 사용\n",
            "      📊 훈련: 5,877개, 검증: 1,467개\n",
            "   🎯 하이퍼파라미터 최적화: 20/20 (Best RMSE: 1.4992)\n",
            "   📈 최적화 완료: Best RMSE = 1.4992\n",
            "   📊 검증 RMSE = 1.0645\n",
            "   🏆 최적 파라미터: lr=0.053, n_est=408\n",
            "         ✅ 최적화 | RMSE: 1.499 | ⏱️ 11.0초\n",
            "\n",
            "[13/38] 🔥 비난방_M\n",
            "         📊 데이터: 7,344개\n",
            "\n",
            "🔍 비난방_M 모델 훈련 시작...\n",
            "   🔧 XGBoost 버전: 3.0.2, Callbacks 지원: True\n",
            "      📅 월별 분할: 5개월, 검증 1467개\n",
            "   📋 비난방_M: 21개 특성 사용\n",
            "      📊 훈련: 5,877개, 검증: 1,467개\n",
            "   🎯 하이퍼파라미터 최적화: 20/20 (Best RMSE: 3.4471)\n",
            "   📈 최적화 완료: Best RMSE = 3.4471\n",
            "   📊 검증 RMSE = 2.0861\n",
            "   🏆 최적 파라미터: lr=0.023, n_est=348\n",
            "         ✅ 최적화 | RMSE: 3.447 | ⏱️ 15.2초\n",
            "\n",
            "[14/38] 🔥 비난방_N\n",
            "         📊 데이터: 7,344개\n",
            "\n",
            "🔍 비난방_N 모델 훈련 시작...\n",
            "   🔧 XGBoost 버전: 3.0.2, Callbacks 지원: True\n",
            "      📅 월별 분할: 5개월, 검증 1467개\n",
            "   📋 비난방_N: 21개 특성 사용\n",
            "      📊 훈련: 5,877개, 검증: 1,467개\n",
            "   🎯 하이퍼파라미터 최적화: 20/20 (Best RMSE: 5.5264)\n",
            "   📈 최적화 완료: Best RMSE = 5.5264\n",
            "   📊 검증 RMSE = 2.1242\n",
            "   🏆 최적 파라미터: lr=0.051, n_est=268\n",
            "         ✅ 최적화 | RMSE: 5.526 | ⏱️ 15.6초\n",
            "\n",
            "[15/38] 🔥 비난방_O\n",
            "         📊 데이터: 7,344개\n",
            "\n",
            "🔍 비난방_O 모델 훈련 시작...\n",
            "   🔧 XGBoost 버전: 3.0.2, Callbacks 지원: True\n",
            "      📅 월별 분할: 5개월, 검증 1467개\n",
            "   📋 비난방_O: 21개 특성 사용\n",
            "      📊 훈련: 5,877개, 검증: 1,467개\n",
            "   🎯 하이퍼파라미터 최적화: 20/20 (Best RMSE: 5.4867)\n",
            "   📈 최적화 완료: Best RMSE = 5.4867\n",
            "   📊 검증 RMSE = 4.4574\n",
            "   🏆 최적 파라미터: lr=0.011, n_est=328\n",
            "         ✅ 최적화 | RMSE: 5.487 | ⏱️ 13.4초\n",
            "\n",
            "[16/38] 🔥 비난방_P\n",
            "         📊 데이터: 7,344개\n",
            "\n",
            "🔍 비난방_P 모델 훈련 시작...\n",
            "   🔧 XGBoost 버전: 3.0.2, Callbacks 지원: True\n",
            "      📅 월별 분할: 5개월, 검증 1467개\n",
            "   📋 비난방_P: 21개 특성 사용\n",
            "      📊 훈련: 5,877개, 검증: 1,467개\n",
            "   🎯 하이퍼파라미터 최적화: 20/20 (Best RMSE: 7.1951)\n",
            "   📈 최적화 완료: Best RMSE = 7.1951\n",
            "   📊 검증 RMSE = 5.9272\n",
            "   🏆 최적 파라미터: lr=0.092, n_est=51\n",
            "         ✅ 최적화 | RMSE: 7.195 | ⏱️ 9.8초\n",
            "\n",
            "[17/38] 🔥 비난방_Q\n",
            "         📊 데이터: 7,344개\n",
            "\n",
            "🔍 비난방_Q 모델 훈련 시작...\n",
            "   🔧 XGBoost 버전: 3.0.2, Callbacks 지원: True\n",
            "      📅 월별 분할: 5개월, 검증 1467개\n",
            "   📋 비난방_Q: 21개 특성 사용\n",
            "      📊 훈련: 5,877개, 검증: 1,467개\n",
            "   🎯 하이퍼파라미터 최적화: 20/20 (Best RMSE: 7.4967)\n",
            "   📈 최적화 완료: Best RMSE = 7.4967\n",
            "   📊 검증 RMSE = 4.0099\n",
            "   🏆 최적 파라미터: lr=0.108, n_est=236\n",
            "         ✅ 최적화 | RMSE: 7.497 | ⏱️ 12.2초\n",
            "\n",
            "[18/38] 🔥 비난방_R\n",
            "         📊 데이터: 7,344개\n",
            "\n",
            "🔍 비난방_R 모델 훈련 시작...\n",
            "   🔧 XGBoost 버전: 3.0.2, Callbacks 지원: True\n",
            "      📅 월별 분할: 5개월, 검증 1467개\n",
            "   📋 비난방_R: 21개 특성 사용\n",
            "      📊 훈련: 5,877개, 검증: 1,467개\n",
            "   🎯 하이퍼파라미터 최적화: 20/20 (Best RMSE: 2.3685)\n",
            "   📈 최적화 완료: Best RMSE = 2.3685\n",
            "   📊 검증 RMSE = 2.0251\n",
            "   🏆 최적 파라미터: lr=0.023, n_est=207\n",
            "         ✅ 최적화 | RMSE: 2.369 | ⏱️ 11.8초\n",
            "\n",
            "[19/38] 🔥 비난방_S\n",
            "         📊 데이터: 7,344개\n",
            "\n",
            "🔍 비난방_S 모델 훈련 시작...\n",
            "   🔧 XGBoost 버전: 3.0.2, Callbacks 지원: True\n",
            "      📅 월별 분할: 5개월, 검증 1467개\n",
            "   📋 비난방_S: 21개 특성 사용\n",
            "      📊 훈련: 5,877개, 검증: 1,467개\n",
            "   🎯 하이퍼파라미터 최적화: 20/20 (Best RMSE: 3.5185)\n",
            "   📈 최적화 완료: Best RMSE = 3.5185\n",
            "   📊 검증 RMSE = 2.4323\n",
            "   🏆 최적 파라미터: lr=0.080, n_est=112\n",
            "         ✅ 최적화 | RMSE: 3.518 | ⏱️ 10.5초\n",
            "\n",
            "[20/38] 🔥 난방_A\n",
            "         📊 데이터: 10,175개\n",
            "\n",
            "🔍 난방_A 모델 훈련 시작...\n",
            "   🔧 XGBoost 버전: 3.0.2, Callbacks 지원: True\n",
            "      📅 월별 분할: 7개월, 검증 2032개\n",
            "   📋 난방_A: 21개 특성 사용\n",
            "      📊 훈련: 8,143개, 검증: 2,032개\n",
            "   🎯 하이퍼파라미터 최적화: 20/20 (Best RMSE: 20.8223)\n",
            "   📈 최적화 완료: Best RMSE = 20.8223\n",
            "   📊 검증 RMSE = 12.6903\n",
            "   🏆 최적 파라미터: lr=0.019, n_est=347\n",
            "         ✅ 최적화 | RMSE: 20.822 | ⏱️ 19.5초\n",
            "\n",
            "[21/38] 🔥 난방_B\n",
            "         📊 데이터: 10,175개\n",
            "\n",
            "🔍 난방_B 모델 훈련 시작...\n",
            "   🔧 XGBoost 버전: 3.0.2, Callbacks 지원: True\n",
            "      📅 월별 분할: 7개월, 검증 2032개\n",
            "   📋 난방_B: 21개 특성 사용\n",
            "      📊 훈련: 8,143개, 검증: 2,032개\n",
            "   🎯 하이퍼파라미터 최적화: 20/20 (Best RMSE: 46.0968)\n",
            "   📈 최적화 완료: Best RMSE = 46.0968\n",
            "   📊 검증 RMSE = 32.3021\n",
            "   🏆 최적 파라미터: lr=0.138, n_est=83\n",
            "         ✅ 최적화 | RMSE: 46.097 | ⏱️ 14.7초\n",
            "\n",
            "[22/38] 🔥 난방_C\n",
            "         📊 데이터: 10,175개\n",
            "\n",
            "🔍 난방_C 모델 훈련 시작...\n",
            "   🔧 XGBoost 버전: 3.0.2, Callbacks 지원: True\n",
            "      📅 월별 분할: 7개월, 검증 2032개\n",
            "   📋 난방_C: 21개 특성 사용\n",
            "      📊 훈련: 8,143개, 검증: 2,032개\n",
            "   🎯 하이퍼파라미터 최적화: 20/20 (Best RMSE: 34.3827)\n",
            "   📈 최적화 완료: Best RMSE = 34.3827\n",
            "   📊 검증 RMSE = 21.2564\n",
            "   🏆 최적 파라미터: lr=0.064, n_est=353\n",
            "         ✅ 최적화 | RMSE: 34.383 | ⏱️ 13.3초\n",
            "\n",
            "[23/38] 🔥 난방_D\n",
            "         📊 데이터: 10,175개\n",
            "\n",
            "🔍 난방_D 모델 훈련 시작...\n",
            "   🔧 XGBoost 버전: 3.0.2, Callbacks 지원: True\n",
            "      📅 월별 분할: 7개월, 검증 2032개\n",
            "   📋 난방_D: 21개 특성 사용\n",
            "      📊 훈련: 8,143개, 검증: 2,032개\n",
            "   🎯 하이퍼파라미터 최적화: 20/20 (Best RMSE: 30.9966)\n",
            "   📈 최적화 완료: Best RMSE = 30.9966\n",
            "   📊 검증 RMSE = 25.7059\n",
            "   🏆 최적 파라미터: lr=0.047, n_est=417\n",
            "         ✅ 최적화 | RMSE: 30.997 | ⏱️ 11.9초\n",
            "\n",
            "[24/38] 🔥 난방_E\n",
            "         📊 데이터: 10,175개\n",
            "\n",
            "🔍 난방_E 모델 훈련 시작...\n",
            "   🔧 XGBoost 버전: 3.0.2, Callbacks 지원: True\n",
            "      📅 월별 분할: 7개월, 검증 2032개\n",
            "   📋 난방_E: 21개 특성 사용\n",
            "      📊 훈련: 8,143개, 검증: 2,032개\n",
            "   🎯 하이퍼파라미터 최적화: 20/20 (Best RMSE: 10.3815)\n",
            "   📈 최적화 완료: Best RMSE = 10.3815\n",
            "   📊 검증 RMSE = 7.6477\n",
            "   🏆 최적 파라미터: lr=0.053, n_est=408\n",
            "         ✅ 최적화 | RMSE: 10.382 | ⏱️ 12.7초\n",
            "\n",
            "[25/38] 🔥 난방_F\n",
            "         📊 데이터: 10,175개\n",
            "\n",
            "🔍 난방_F 모델 훈련 시작...\n",
            "   🔧 XGBoost 버전: 3.0.2, Callbacks 지원: True\n",
            "      📅 월별 분할: 7개월, 검증 2032개\n",
            "   📋 난방_F: 21개 특성 사용\n",
            "      📊 훈련: 8,143개, 검증: 2,032개\n",
            "   🎯 하이퍼파라미터 최적화: 20/20 (Best RMSE: 11.3378)\n",
            "   📈 최적화 완료: Best RMSE = 11.3378\n",
            "   📊 검증 RMSE = 8.0668\n",
            "   🏆 최적 파라미터: lr=0.053, n_est=408\n",
            "         ✅ 최적화 | RMSE: 11.338 | ⏱️ 12.1초\n",
            "\n",
            "[26/38] 🔥 난방_G\n",
            "         📊 데이터: 10,175개\n",
            "\n",
            "🔍 난방_G 모델 훈련 시작...\n",
            "   🔧 XGBoost 버전: 3.0.2, Callbacks 지원: True\n",
            "      📅 월별 분할: 7개월, 검증 2032개\n",
            "   📋 난방_G: 21개 특성 사용\n",
            "      📊 훈련: 8,143개, 검증: 2,032개\n",
            "   🎯 하이퍼파라미터 최적화: 20/20 (Best RMSE: 32.7309)\n",
            "   📈 최적화 완료: Best RMSE = 32.7309\n",
            "   📊 검증 RMSE = 21.0335\n",
            "   🏆 최적 파라미터: lr=0.030, n_est=285\n",
            "         ✅ 최적화 | RMSE: 32.731 | ⏱️ 17.3초\n",
            "\n",
            "[27/38] 🔥 난방_H\n",
            "         📊 데이터: 10,175개\n",
            "\n",
            "🔍 난방_H 모델 훈련 시작...\n",
            "   🔧 XGBoost 버전: 3.0.2, Callbacks 지원: True\n",
            "      📅 월별 분할: 7개월, 검증 2032개\n",
            "   📋 난방_H: 21개 특성 사용\n",
            "      📊 훈련: 8,143개, 검증: 2,032개\n",
            "   🎯 하이퍼파라미터 최적화: 20/20 (Best RMSE: 28.0386)\n",
            "   📈 최적화 완료: Best RMSE = 28.0386\n",
            "   📊 검증 RMSE = 15.0225\n",
            "   🏆 최적 파라미터: lr=0.018, n_est=359\n",
            "         ✅ 최적화 | RMSE: 28.039 | ⏱️ 19.6초\n",
            "\n",
            "[28/38] 🔥 난방_I\n",
            "         📊 데이터: 10,175개\n",
            "\n",
            "🔍 난방_I 모델 훈련 시작...\n",
            "   🔧 XGBoost 버전: 3.0.2, Callbacks 지원: True\n",
            "      📅 월별 분할: 7개월, 검증 2032개\n",
            "   📋 난방_I: 21개 특성 사용\n",
            "      📊 훈련: 8,143개, 검증: 2,032개\n",
            "   🎯 하이퍼파라미터 최적화: 20/20 (Best RMSE: 11.8099)\n",
            "   📈 최적화 완료: Best RMSE = 11.8099\n",
            "   📊 검증 RMSE = 9.8451\n",
            "   🏆 최적 파라미터: lr=0.080, n_est=112\n",
            "         ✅ 최적화 | RMSE: 11.810 | ⏱️ 9.5초\n",
            "\n",
            "[29/38] 🔥 난방_J\n",
            "         📊 데이터: 10,175개\n",
            "\n",
            "🔍 난방_J 모델 훈련 시작...\n",
            "   🔧 XGBoost 버전: 3.0.2, Callbacks 지원: True\n",
            "      📅 월별 분할: 7개월, 검증 2032개\n",
            "   📋 난방_J: 21개 특성 사용\n",
            "      📊 훈련: 8,143개, 검증: 2,032개\n",
            "   🎯 하이퍼파라미터 최적화: 20/20 (Best RMSE: 14.8009)\n",
            "   📈 최적화 완료: Best RMSE = 14.8009\n",
            "   📊 검증 RMSE = 7.0812\n",
            "   🏆 최적 파라미터: lr=0.044, n_est=396\n",
            "         ✅ 최적화 | RMSE: 14.801 | ⏱️ 11.2초\n",
            "\n",
            "[30/38] 🔥 난방_K\n",
            "         📊 데이터: 10,175개\n",
            "\n",
            "🔍 난방_K 모델 훈련 시작...\n",
            "   🔧 XGBoost 버전: 3.0.2, Callbacks 지원: True\n",
            "      📅 월별 분할: 7개월, 검증 2032개\n",
            "   📋 난방_K: 21개 특성 사용\n",
            "      📊 훈련: 8,143개, 검증: 2,032개\n",
            "   🎯 하이퍼파라미터 최적화: 20/20 (Best RMSE: 10.0361)\n",
            "   📈 최적화 완료: Best RMSE = 10.0361\n",
            "   📊 검증 RMSE = 7.4359\n",
            "   🏆 최적 파라미터: lr=0.103, n_est=368\n",
            "         ✅ 최적화 | RMSE: 10.036 | ⏱️ 9.2초\n",
            "\n",
            "[31/38] 🔥 난방_L\n",
            "         📊 데이터: 10,175개\n",
            "\n",
            "🔍 난방_L 모델 훈련 시작...\n",
            "   🔧 XGBoost 버전: 3.0.2, Callbacks 지원: True\n",
            "      📅 월별 분할: 7개월, 검증 2032개\n",
            "   📋 난방_L: 21개 특성 사용\n",
            "      📊 훈련: 8,143개, 검증: 2,032개\n",
            "   🎯 하이퍼파라미터 최적화: 20/20 (Best RMSE: 4.1213)\n",
            "   📈 최적화 완료: Best RMSE = 4.1213\n",
            "   📊 검증 RMSE = 3.3025\n",
            "   🏆 최적 파라미터: lr=0.056, n_est=186\n",
            "         ✅ 최적화 | RMSE: 4.121 | ⏱️ 8.8초\n",
            "\n",
            "[32/38] 🔥 난방_M\n",
            "         📊 데이터: 10,175개\n",
            "\n",
            "🔍 난방_M 모델 훈련 시작...\n",
            "   🔧 XGBoost 버전: 3.0.2, Callbacks 지원: True\n",
            "      📅 월별 분할: 7개월, 검증 2032개\n",
            "   📋 난방_M: 21개 특성 사용\n",
            "      📊 훈련: 8,143개, 검증: 2,032개\n",
            "   🎯 하이퍼파라미터 최적화: 20/20 (Best RMSE: 8.6812)\n",
            "   📈 최적화 완료: Best RMSE = 8.6812\n",
            "   📊 검증 RMSE = 7.2128\n",
            "   🏆 최적 파라미터: lr=0.080, n_est=112\n",
            "         ✅ 최적화 | RMSE: 8.681 | ⏱️ 9.5초\n",
            "\n",
            "[33/38] 🔥 난방_N\n",
            "         📊 데이터: 10,175개\n",
            "\n",
            "🔍 난방_N 모델 훈련 시작...\n",
            "   🔧 XGBoost 버전: 3.0.2, Callbacks 지원: True\n",
            "      📅 월별 분할: 7개월, 검증 2032개\n",
            "   📋 난방_N: 21개 특성 사용\n",
            "      📊 훈련: 8,143개, 검증: 2,032개\n",
            "   🎯 하이퍼파라미터 최적화: 20/20 (Best RMSE: 16.7801)\n",
            "   📈 최적화 완료: Best RMSE = 16.7801\n",
            "   📊 검증 RMSE = 9.9963\n",
            "   🏆 최적 파라미터: lr=0.051, n_est=422\n",
            "         ✅ 최적화 | RMSE: 16.780 | ⏱️ 10.1초\n",
            "\n",
            "[34/38] 🔥 난방_O\n",
            "         📊 데이터: 10,175개\n",
            "\n",
            "🔍 난방_O 모델 훈련 시작...\n",
            "   🔧 XGBoost 버전: 3.0.2, Callbacks 지원: True\n",
            "      📅 월별 분할: 7개월, 검증 2032개\n",
            "   📋 난방_O: 21개 특성 사용\n",
            "      📊 훈련: 8,143개, 검증: 2,032개\n",
            "   🎯 하이퍼파라미터 최적화: 20/20 (Best RMSE: 12.5439)\n",
            "   📈 최적화 완료: Best RMSE = 12.5439\n",
            "   📊 검증 RMSE = 9.8797\n",
            "   🏆 최적 파라미터: lr=0.112, n_est=276\n",
            "         ✅ 최적화 | RMSE: 12.544 | ⏱️ 9.4초\n",
            "\n",
            "[35/38] 🔥 난방_P\n",
            "         📊 데이터: 10,175개\n",
            "\n",
            "🔍 난방_P 모델 훈련 시작...\n",
            "   🔧 XGBoost 버전: 3.0.2, Callbacks 지원: True\n",
            "      📅 월별 분할: 7개월, 검증 2032개\n",
            "   📋 난방_P: 21개 특성 사용\n",
            "      📊 훈련: 8,143개, 검증: 2,032개\n",
            "   🎯 하이퍼파라미터 최적화: 20/20 (Best RMSE: 16.1460)\n",
            "   📈 최적화 완료: Best RMSE = 16.1460\n",
            "   📊 검증 RMSE = 10.9115\n",
            "   🏆 최적 파라미터: lr=0.053, n_est=408\n",
            "         ✅ 최적화 | RMSE: 16.146 | ⏱️ 8.8초\n",
            "\n",
            "[36/38] 🔥 난방_Q\n",
            "         📊 데이터: 10,175개\n",
            "\n",
            "🔍 난방_Q 모델 훈련 시작...\n",
            "   🔧 XGBoost 버전: 3.0.2, Callbacks 지원: True\n",
            "      📅 월별 분할: 7개월, 검증 2032개\n",
            "   📋 난방_Q: 21개 특성 사용\n",
            "      📊 훈련: 8,143개, 검증: 2,032개\n",
            "   🎯 하이퍼파라미터 최적화: 20/20 (Best RMSE: 15.1132)\n",
            "   📈 최적화 완료: Best RMSE = 15.1132\n",
            "   📊 검증 RMSE = 7.5827\n",
            "   🏆 최적 파라미터: lr=0.085, n_est=372\n",
            "         ✅ 최적화 | RMSE: 15.113 | ⏱️ 10.5초\n",
            "\n",
            "[37/38] 🔥 난방_R\n",
            "         📊 데이터: 10,175개\n",
            "\n",
            "🔍 난방_R 모델 훈련 시작...\n",
            "   🔧 XGBoost 버전: 3.0.2, Callbacks 지원: True\n",
            "      📅 월별 분할: 7개월, 검증 2032개\n",
            "   📋 난방_R: 21개 특성 사용\n",
            "      📊 훈련: 8,143개, 검증: 2,032개\n",
            "   🎯 하이퍼파라미터 최적화: 20/20 (Best RMSE: 3.3409)\n",
            "   📈 최적화 완료: Best RMSE = 3.3409\n",
            "   📊 검증 RMSE = 2.7541\n",
            "   🏆 최적 파라미터: lr=0.103, n_est=368\n",
            "         ✅ 최적화 | RMSE: 3.341 | ⏱️ 9.7초\n",
            "\n",
            "[38/38] 🔥 난방_S\n",
            "         📊 데이터: 10,175개\n",
            "\n",
            "🔍 난방_S 모델 훈련 시작...\n",
            "   🔧 XGBoost 버전: 3.0.2, Callbacks 지원: True\n",
            "      📅 월별 분할: 7개월, 검증 2032개\n",
            "   📋 난방_S: 21개 특성 사용\n",
            "      📊 훈련: 8,143개, 검증: 2,032개\n",
            "   🎯 하이퍼파라미터 최적화: 20/20 (Best RMSE: 5.1724)\n",
            "   📈 최적화 완료: Best RMSE = 5.1724\n",
            "   📊 검증 RMSE = 3.2792\n",
            "   🏆 최적 파라미터: lr=0.066, n_est=378\n",
            "         ✅ 최적화 | RMSE: 5.172 | ⏱️ 9.6초\n",
            "\n",
            "============================================================\n",
            "🎉 모든 모델 훈련 완료!\n",
            "⏱️  총 소요 시간: 7.4분 (평균 11.6초/모델)\n",
            "📊 훈련 결과:\n",
            "   ✅ 최적화 성공: 38개\n",
            "   🔧 기본 모델: 0개\n",
            "   ❌ 완전 실패: 0개\n",
            "   📈 전체 성공률: 100.0%\n",
            "🏆 최고 성능: 비난방_L (RMSE: 1.4992)\n",
            "📈 시즌별 평균 RMSE:\n",
            "   난방시즌: 17.5438 (19개 모델)\n",
            "   비난방시즌: 7.9005 (19개 모델)\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# 38개 모델 훈련\n",
        "print(\"🚀 38개 XGBoost 모델 훈련 시작!\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "models = {}\n",
        "training_results = {}\n",
        "n_trials_per_model = 20  # 시간 단축을 위해 20으로 조정\n",
        "\n",
        "start_time = datetime.now()\n",
        "\n",
        "# 성공/실패 카운터\n",
        "success_count = 0\n",
        "basic_count = 0\n",
        "failed_count = 0\n",
        "\n",
        "# 모든 훈련 데이터 분할에 대해 모델 훈련\n",
        "for i, (model_key, train_data) in enumerate(train_splits.items(), 1):\n",
        "    print(f\"\\n[{i:2d}/{len(train_splits)}] 🔥 {model_key}\")\n",
        "    print(f\"         📊 데이터: {len(train_data):,}개\")\n",
        "    \n",
        "    # 모델 생성 및 훈련\n",
        "    model = OptimizedXGBoostModel(model_key)\n",
        "    \n",
        "    try:\n",
        "        model_start = datetime.now()\n",
        "        model.fit(train_data, n_trials=n_trials_per_model)\n",
        "        model_time = (datetime.now() - model_start).total_seconds()\n",
        "        \n",
        "        models[model_key] = model\n",
        "        \n",
        "        # 결과 분류\n",
        "        if model.best_score is not None:\n",
        "            success_count += 1\n",
        "            status = \"✅ 최적화\"\n",
        "            score_text = f\"RMSE: {model.best_score:.3f}\"\n",
        "        else:\n",
        "            basic_count += 1\n",
        "            status = \"🔧 기본모델\"\n",
        "            score_text = \"기본파라미터\"\n",
        "        \n",
        "        # 안전한 결과 저장\n",
        "        training_results[model_key] = {\n",
        "            'data_size': len(train_data),\n",
        "            'training_time': model_time,\n",
        "            'best_score': model.best_score,\n",
        "            'best_params': model.best_params,\n",
        "            'optimization_success': model.best_score is not None\n",
        "        }\n",
        "        \n",
        "        print(f\"         {status} | {score_text} | ⏱️ {model_time:.1f}초\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"         ❌ 훈련 실패: {str(e)[:30]}...\")\n",
        "        failed_count += 1\n",
        "        \n",
        "        # 완전 기본 모델로 대체\n",
        "        try:\n",
        "            basic_model = OptimizedXGBoostModel(model_key)\n",
        "            basic_model._fit_basic_model(train_data, 'heat_demand')\n",
        "            models[model_key] = basic_model\n",
        "            \n",
        "            training_results[model_key] = {\n",
        "                'data_size': len(train_data),\n",
        "                'training_time': 0,\n",
        "                'best_score': None,\n",
        "                'best_params': None,\n",
        "                'optimization_success': False,\n",
        "                'error': str(e)[:50]\n",
        "            }\n",
        "            print(f\"         🔧 기본 모델로 대체 완료\")\n",
        "            \n",
        "        except Exception as e2:\n",
        "            print(f\"         ❌ 기본 모델 생성도 실패\")\n",
        "            # 더미 모델 저장\n",
        "            dummy_model = OptimizedXGBoostModel(model_key)\n",
        "            dummy_model.model = None\n",
        "            models[model_key] = dummy_model\n",
        "            \n",
        "            training_results[model_key] = {\n",
        "                'data_size': len(train_data),\n",
        "                'training_time': 0,\n",
        "                'best_score': None,\n",
        "                'best_params': None,\n",
        "                'optimization_success': False,\n",
        "                'error': f\"Complete failure: {str(e2)[:30]}\"\n",
        "            }\n",
        "\n",
        "total_time = (datetime.now() - start_time).total_seconds()\n",
        "\n",
        "print(f\"\\n\" + \"=\" * 60)\n",
        "print(f\"🎉 모든 모델 훈련 완료!\")\n",
        "print(f\"⏱️  총 소요 시간: {total_time/60:.1f}분 (평균 {total_time/len(train_splits):.1f}초/모델)\")\n",
        "print(f\"📊 훈련 결과:\")\n",
        "print(f\"   ✅ 최적화 성공: {success_count}개\")\n",
        "print(f\"   🔧 기본 모델: {basic_count}개\") \n",
        "print(f\"   ❌ 완전 실패: {failed_count}개\")\n",
        "print(f\"   📈 전체 성공률: {(success_count + basic_count)/len(train_splits)*100:.1f}%\")\n",
        "\n",
        "# 최고 성능 모델 찾기\n",
        "successful_models = {k: v for k, v in training_results.items() \n",
        "                    if v.get('optimization_success', False)}\n",
        "\n",
        "if successful_models:\n",
        "    best_model = min(successful_models.items(), key=lambda x: x[1]['best_score'])\n",
        "    print(f\"🏆 최고 성능: {best_model[0]} (RMSE: {best_model[1]['best_score']:.4f})\")\n",
        "    \n",
        "    # 시즌별 평균 성능\n",
        "    season_scores = {'난방': [], '비난방': []}\n",
        "    for model_name, result in successful_models.items():\n",
        "        season = model_name.split('_')[0]\n",
        "        if season in season_scores:\n",
        "            season_scores[season].append(result['best_score'])\n",
        "    \n",
        "    print(f\"📈 시즌별 평균 RMSE:\")\n",
        "    for season, scores in season_scores.items():\n",
        "        if scores:\n",
        "            print(f\"   {season}시즌: {np.mean(scores):.4f} ({len(scores)}개 모델)\")\n",
        "\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xC-cKYeui6IS"
      },
      "source": [
        "## 6️⃣ 훈련 결과 분석"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Q73KBW9yi6IT"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "📊 훈련 결과 분석\n",
            "============================================================\n",
            "✅ 성공: 38개 모델\n",
            "❌ 실패: 0개 모델\n",
            "\n",
            "🏆 최적화 성능 통계:\n",
            "   평균 RMSE: 12.7222\n",
            "   최소 RMSE: 1.4992\n",
            "   최대 RMSE: 46.0968\n",
            "   표준편차: 9.9239\n",
            "\n",
            "📈 시즌별 평균 RMSE:\n",
            "   난방시즌: 17.5438 (19개 모델)\n",
            "   비난방시즌: 7.9005 (19개 모델)\n",
            "\n",
            "⏱️ 훈련 시간 통계:\n",
            "   평균 모델당: 11.6초\n",
            "   총 훈련 시간: 7.4분\n"
          ]
        }
      ],
      "source": [
        "# 훈련 결과 분석\n",
        "print(\"\\n📊 훈련 결과 분석\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# 결과 정리\n",
        "results_df = pd.DataFrame(training_results).T\n",
        "results_df['season'] = results_df.index.str.split('_').str[0]\n",
        "results_df['branch'] = results_df.index.str.split('_').str[1]\n",
        "\n",
        "# 성공/실패 통계\n",
        "successful_models = results_df[results_df['best_score'].notna()]\n",
        "failed_models = results_df[results_df['best_score'].isna()]\n",
        "\n",
        "print(f\"✅ 성공: {len(successful_models)}개 모델\")\n",
        "print(f\"❌ 실패: {len(failed_models)}개 모델\")\n",
        "\n",
        "if len(successful_models) > 0:\n",
        "    print(f\"\\n🏆 최적화 성능 통계:\")\n",
        "    print(f\"   평균 RMSE: {successful_models['best_score'].mean():.4f}\")\n",
        "    print(f\"   최소 RMSE: {successful_models['best_score'].min():.4f}\")\n",
        "    print(f\"   최대 RMSE: {successful_models['best_score'].max():.4f}\")\n",
        "    print(f\"   표준편차: {successful_models['best_score'].std():.4f}\")\n",
        "\n",
        "    # 시즌별 성능\n",
        "    print(f\"\\n📈 시즌별 평균 RMSE:\")\n",
        "    season_performance = successful_models.groupby('season')['best_score'].agg(['mean', 'count'])\n",
        "    for season, row in season_performance.iterrows():\n",
        "        print(f\"   {season}시즌: {row['mean']:.4f} ({int(row['count'])}개 모델)\")\n",
        "\n",
        "    # # 상위 5개 모델\n",
        "    # print(f\"\\n🥇 성능 상위 5개 모델:\")\n",
        "    # top_models = successful_models.nsmallest(5, 'best_score')\n",
        "    # for idx, (model_name, row) in enumerate(top_models.iterrows(), 1):\n",
        "    #     print(f\"   {idx}. {model_name}: RMSE = {row['best_score']:.4f}\")\n",
        "\n",
        "# 실패한 모델이 있으면 정보 출력\n",
        "if len(failed_models) > 0:\n",
        "    print(f\"\\n⚠️ 실패한 모델들:\")\n",
        "    for model_name, row in failed_models.iterrows():\n",
        "        error_msg = row.get('error', '알 수 없는 오류')\n",
        "        print(f\"   {model_name}: {error_msg}\")\n",
        "\n",
        "# 훈련 시간 통계\n",
        "avg_time = results_df['training_time'].mean()\n",
        "total_time_min = results_df['training_time'].sum() / 60\n",
        "print(f\"\\n⏱️ 훈련 시간 통계:\")\n",
        "print(f\"   평균 모델당: {avg_time:.1f}초\")\n",
        "print(f\"   총 훈련 시간: {total_time_min:.1f}분\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 📍 NaN 및 dtype 문제 해결 함수 별도 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ NaN 및 dtype 문제 해결 함수 준비 완료\n",
            "실행하려면: results_df, evaluation_results = run_safe_evaluation()\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# NaN 및 데이터 타입 문제 해결\n",
        "# =============================================================================\n",
        "\n",
        "# 1. RMSE 평가 시 NaN 문제 해결\n",
        "def safe_rmse_evaluation(test_df, result_df):\n",
        "    \"\"\"안전한 RMSE 평가 (NaN 처리 포함)\"\"\"\n",
        "    print(f\"\\n📊 안전한 RMSE 성능 평가\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    if 'heat_demand' not in test_df.columns:\n",
        "        print(\"⚠️ 테스트 데이터에 heat_demand 컬럼이 없습니다.\")\n",
        "        return None\n",
        "    \n",
        "    # 원본 데이터\n",
        "    y_true = test_df['heat_demand'].values\n",
        "    y_pred = result_df['pred_heat_demand'].values\n",
        "    \n",
        "    print(f\"📋 원본 데이터 상태:\")\n",
        "    print(f\"   실제값 NaN: {np.isnan(y_true).sum():,}개\")\n",
        "    print(f\"   예측값 NaN: {np.isnan(y_pred).sum():,}개\")\n",
        "    print(f\"   실제값 inf: {np.isinf(y_true).sum():,}개\")\n",
        "    print(f\"   예측값 inf: {np.isinf(y_pred).sum():,}개\")\n",
        "    \n",
        "    # 유효한 값들만 필터링\n",
        "    valid_mask = (~np.isnan(y_true)) & (~np.isnan(y_pred)) & (~np.isinf(y_true)) & (~np.isinf(y_pred))\n",
        "    \n",
        "    if np.sum(valid_mask) == 0:\n",
        "        print(\"❌ 유효한 데이터가 없습니다!\")\n",
        "        return None\n",
        "    \n",
        "    y_true_clean = y_true[valid_mask]\n",
        "    y_pred_clean = y_pred[valid_mask]\n",
        "    \n",
        "    print(f\"✅ 정리 후 유효 데이터: {len(y_true_clean):,}개 ({len(y_true_clean)/len(y_true)*100:.1f}%)\")\n",
        "    \n",
        "    # 전체 성능 계산\n",
        "    overall_rmse = np.sqrt(mean_squared_error(y_true_clean, y_pred_clean))\n",
        "    overall_mae = mean_absolute_error(y_true_clean, y_pred_clean)\n",
        "    correlation = np.corrcoef(y_true_clean, y_pred_clean)[0, 1] if len(y_true_clean) > 1 else 0\n",
        "    \n",
        "    print(f\"\\n🏆 전체 성능:\")\n",
        "    print(f\"   RMSE: {overall_rmse:.4f}\")\n",
        "    print(f\"   MAE:  {overall_mae:.4f}\")\n",
        "    print(f\"   상관계수: {correlation:.4f}\")\n",
        "    \n",
        "    # 시즌별 RMSE\n",
        "    print(f\"\\n📈 시즌별 RMSE 성능:\")\n",
        "    season_names = {0: '비난방시즌', 1: '난방시즌'}\n",
        "    season_results = {}\n",
        "    \n",
        "    for season in [0, 1]:\n",
        "        season_mask = (test_df['heating_season'] == season) & valid_mask\n",
        "        if np.sum(season_mask) > 0:\n",
        "            season_rmse = np.sqrt(mean_squared_error(y_true[season_mask], y_pred[season_mask]))\n",
        "            season_mae = mean_absolute_error(y_true[season_mask], y_pred[season_mask])\n",
        "            season_corr = np.corrcoef(y_true[season_mask], y_pred[season_mask])[0, 1] if np.sum(season_mask) > 1 else 0\n",
        "            season_results[season] = {\n",
        "                'rmse': season_rmse, \n",
        "                'mae': season_mae, \n",
        "                'corr': season_corr,\n",
        "                'count': np.sum(season_mask)\n",
        "            }\n",
        "            \n",
        "            print(f\"   {season_names[season]:8s}: RMSE={season_rmse:7.4f} | MAE={season_mae:7.4f} | 상관={season_corr:6.3f} | {np.sum(season_mask):,}개\")\n",
        "    \n",
        "    # 브랜치별 RMSE\n",
        "    print(f\"\\n📊 브랜치별 RMSE 성능 (유효 데이터만):\")\n",
        "    branch_results = {}\n",
        "    \n",
        "    for branch in sorted(test_df['branch_id'].unique()):\n",
        "        branch_mask = (test_df['branch_id'] == branch) & valid_mask\n",
        "        if np.sum(branch_mask) > 1:  # 최소 2개 이상\n",
        "            try:\n",
        "                branch_rmse = np.sqrt(mean_squared_error(y_true[branch_mask], y_pred[branch_mask]))\n",
        "                branch_mae = mean_absolute_error(y_true[branch_mask], y_pred[branch_mask])\n",
        "                branch_results[branch] = {\n",
        "                    'rmse': branch_rmse,\n",
        "                    'mae': branch_mae, \n",
        "                    'count': np.sum(branch_mask)\n",
        "                }\n",
        "            except Exception as e:\n",
        "                print(f\"   ⚠️ 브랜치 {branch} 계산 실패: {str(e)[:30]}...\")\n",
        "                continue\n",
        "    \n",
        "    if branch_results:\n",
        "        # RMSE 기준 정렬\n",
        "        sorted_branches = sorted(branch_results.items(), key=lambda x: x[1]['rmse'])\n",
        "        \n",
        "        print(f\"   🥇 RMSE 우수 브랜치 (Top 5):\")\n",
        "        for i, (branch, metrics) in enumerate(sorted_branches[:5], 1):\n",
        "            print(f\"      {i}. 브랜치 {branch}: RMSE={metrics['rmse']:7.4f} | MAE={metrics['mae']:7.4f} | {metrics['count']:,}개\")\n",
        "        \n",
        "        print(f\"   🥉 RMSE 개선 필요 브랜치 (Bottom 5):\")\n",
        "        for i, (branch, metrics) in enumerate(sorted_branches[-5:], 1):\n",
        "            print(f\"      {i}. 브랜치 {branch}: RMSE={metrics['rmse']:7.4f} | MAE={metrics['mae']:7.4f} | {metrics['count']:,}개\")\n",
        "    \n",
        "    return {\n",
        "        'overall_rmse': overall_rmse,\n",
        "        'overall_mae': overall_mae,\n",
        "        'correlation': correlation,\n",
        "        'season_results': season_results,\n",
        "        'branch_results': branch_results,\n",
        "        'valid_count': len(y_true_clean),\n",
        "        'total_count': len(y_true)\n",
        "    }\n",
        "\n",
        "# 2. 훈련 결과 분석 시 dtype 문제 해결\n",
        "def safe_training_analysis(training_results):\n",
        "    \"\"\"안전한 훈련 결과 분석 (dtype 문제 해결)\"\"\"\n",
        "    print(f\"\\n📊 훈련 결과 분석 (dtype 안전)\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    # DataFrame 생성 시 안전하게 처리\n",
        "    results_list = []\n",
        "    for model_name, result in training_results.items():\n",
        "        # best_score를 안전하게 변환\n",
        "        best_score = result.get('best_score')\n",
        "        if best_score is not None:\n",
        "            try:\n",
        "                best_score = float(best_score)\n",
        "            except (ValueError, TypeError):\n",
        "                best_score = None\n",
        "        \n",
        "        # 안전한 딕셔너리 생성\n",
        "        safe_result = {\n",
        "            'model_name': model_name,\n",
        "            'data_size': result.get('data_size', 0),\n",
        "            'training_time': result.get('training_time', 0),\n",
        "            'best_score': best_score,\n",
        "            'optimization_success': result.get('optimization_success', False),\n",
        "            'season': model_name.split('_')[0] if '_' in model_name else 'unknown',\n",
        "            'branch': model_name.split('_')[1] if '_' in model_name and len(model_name.split('_')) > 1 else 'unknown'\n",
        "        }\n",
        "        results_list.append(safe_result)\n",
        "    \n",
        "    # DataFrame 생성\n",
        "    results_df = pd.DataFrame(results_list)\n",
        "    \n",
        "    # 성공/실패 통계\n",
        "    successful_models = results_df[results_df['optimization_success'] == True]\n",
        "    failed_models = results_df[results_df['optimization_success'] == False]\n",
        "    \n",
        "    print(f\"✅ 성공: {len(successful_models)}개 모델\")\n",
        "    print(f\"❌ 실패: {len(failed_models)}개 모델\")\n",
        "    \n",
        "    # 성공한 모델들의 성능 통계\n",
        "    if len(successful_models) > 0:\n",
        "        # best_score가 유효한 것들만 필터링\n",
        "        valid_scores = successful_models[successful_models['best_score'].notna()]\n",
        "        \n",
        "        if len(valid_scores) > 0:\n",
        "            print(f\"\\n🏆 최적화 성능 통계:\")\n",
        "            print(f\"   평균 RMSE: {valid_scores['best_score'].mean():.4f}\")\n",
        "            print(f\"   최소 RMSE: {valid_scores['best_score'].min():.4f}\")\n",
        "            print(f\"   최대 RMSE: {valid_scores['best_score'].max():.4f}\")\n",
        "            print(f\"   표준편차: {valid_scores['best_score'].std():.4f}\")\n",
        "            \n",
        "            # 시즌별 성능\n",
        "            print(f\"\\n📈 시즌별 평균 RMSE:\")\n",
        "            season_performance = valid_scores.groupby('season')['best_score'].agg(['mean', 'count'])\n",
        "            for season, row in season_performance.iterrows():\n",
        "                print(f\"   {season}시즌: {row['mean']:.4f} ({int(row['count'])}개 모델)\")\n",
        "            \n",
        "            # 상위 5개 모델 (안전하게)\n",
        "            print(f\"\\n🥇 성능 상위 5개 모델:\")\n",
        "            try:\n",
        "                # best_score를 숫자형으로 확실히 변환\n",
        "                valid_scores_copy = valid_scores.copy()\n",
        "                valid_scores_copy['best_score'] = pd.to_numeric(valid_scores_copy['best_score'], errors='coerce')\n",
        "                \n",
        "                # NaN 제거 후 정렬\n",
        "                top_models = valid_scores_copy.dropna(subset=['best_score']).nsmallest(5, 'best_score')\n",
        "                \n",
        "                for idx, (_, row) in enumerate(top_models.iterrows(), 1):\n",
        "                    print(f\"   {idx}. {row['model_name']}: RMSE = {row['best_score']:.4f}\")\n",
        "                    \n",
        "            except Exception as e:\n",
        "                print(f\"   ⚠️ 상위 모델 정렬 실패: {str(e)}\")\n",
        "                # 대안: 수동 정렬\n",
        "                try:\n",
        "                    scores_list = [(name, score) for name, score in zip(valid_scores['model_name'], valid_scores['best_score']) if pd.notna(score)]\n",
        "                    scores_list.sort(key=lambda x: float(x[1]))\n",
        "                    \n",
        "                    for idx, (name, score) in enumerate(scores_list[:5], 1):\n",
        "                        print(f\"   {idx}. {name}: RMSE = {score:.4f}\")\n",
        "                except Exception as e2:\n",
        "                    print(f\"   ❌ 수동 정렬도 실패: {str(e2)}\")\n",
        "    \n",
        "    # 실패한 모델 정보\n",
        "    if len(failed_models) > 0:\n",
        "        print(f\"\\n⚠️ 실패한 모델들:\")\n",
        "        error_summary = {}\n",
        "        for _, row in failed_models.iterrows():\n",
        "            season = row['season']\n",
        "            if season not in error_summary:\n",
        "                error_summary[season] = 0\n",
        "            error_summary[season] += 1\n",
        "        \n",
        "        for season, count in error_summary.items():\n",
        "            print(f\"   {season}시즌: {count}개\")\n",
        "    \n",
        "    # 훈련 시간 통계\n",
        "    avg_time = results_df['training_time'].mean()\n",
        "    total_time_min = results_df['training_time'].sum() / 60\n",
        "    print(f\"\\n⏱️ 훈련 시간 통계:\")\n",
        "    print(f\"   평균 모델당: {avg_time:.1f}초\")\n",
        "    print(f\"   총 훈련 시간: {total_time_min:.1f}분\")\n",
        "    \n",
        "    return results_df, successful_models, failed_models\n",
        "\n",
        "# 3. 실행 함수\n",
        "def run_safe_evaluation():\n",
        "    \"\"\"안전한 평가 실행\"\"\"\n",
        "    # 훈련 결과 분석\n",
        "    results_df, successful_models, failed_models = safe_training_analysis(training_results)\n",
        "    \n",
        "    # RMSE 평가 (NaN 안전)\n",
        "    evaluation_results = safe_rmse_evaluation(test_df, result_df)\n",
        "    \n",
        "    return results_df, evaluation_results\n",
        "\n",
        "print(\"✅ NaN 및 dtype 문제 해결 함수 준비 완료\")\n",
        "print(\"실행하려면: results_df, evaluation_results = run_safe_evaluation()\")\n",
        "\n",
        "# 추가: 예측값에서 NaN 제거 함수\n",
        "def clean_predictions(predictions):\n",
        "    \"\"\"예측값 NaN 정리\"\"\"\n",
        "    # NaN을 0으로 대체 (또는 평균값)\n",
        "    cleaned = np.where(np.isnan(predictions), 0, predictions)\n",
        "    \n",
        "    # 음수값 제거\n",
        "    cleaned = np.maximum(cleaned, 0)\n",
        "    \n",
        "    # inf 값 제거\n",
        "    cleaned = np.where(np.isinf(cleaned), 0, cleaned)\n",
        "    \n",
        "    return cleaned\n",
        "\n",
        "# 기존 result_df 정리\n",
        "if 'result_df' in locals():\n",
        "    print(\"🧹 기존 예측값 정리 중...\")\n",
        "    original_nan_count = result_df['pred_heat_demand'].isna().sum()\n",
        "    \n",
        "    # 예측값 정리\n",
        "    result_df['pred_heat_demand'] = clean_predictions(result_df['pred_heat_demand'].values)\n",
        "    \n",
        "    print(f\"   정리 전 NaN: {original_nan_count}개\")\n",
        "    print(f\"   정리 후 NaN: {result_df['pred_heat_demand'].isna().sum()}개\")\n",
        "    print(f\"   정리 후 범위: [{result_df['pred_heat_demand'].min():.2f}, {result_df['pred_heat_demand'].max():.2f}]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 📍 NaN 있는 경우 아래와 같이 결과 분석"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 새로운 안전한 훈련 결과 분석 사용\n",
        "results_df, successful_models, failed_models = safe_training_analysis(training_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdr_IyHVi6IU"
      },
      "source": [
        "## 7️⃣ 테스트 예측"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "NyMyt1tLi6IU"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🎯 테스트 데이터 예측 시작...\n",
            "========================================\n",
            "📊 비난방_A: 3,672개 데이터 예측 중...\n",
            "   ✅ 완료: 평균=32.56, 범위=[15.40, 88.01]\n",
            "📊 비난방_B: 3,672개 데이터 예측 중...\n",
            "   ✅ 완료: 평균=78.18, 범위=[28.47, 220.26]\n",
            "📊 비난방_C: 3,672개 데이터 예측 중...\n",
            "   ✅ 완료: 평균=94.22, 범위=[39.65, 222.22]\n",
            "📊 비난방_D: 3,672개 데이터 예측 중...\n",
            "   ✅ 완료: 평균=56.01, 범위=[24.26, 121.57]\n",
            "📊 비난방_E: 3,672개 데이터 예측 중...\n",
            "   ✅ 완료: 평균=46.52, 범위=[3.87, 147.74]\n",
            "📊 비난방_F: 3,672개 데이터 예측 중...\n",
            "   ✅ 완료: 평균=37.73, 범위=[14.03, 64.06]\n",
            "📊 비난방_G: 3,672개 데이터 예측 중...\n",
            "   ✅ 완료: 평균=75.82, 범위=[39.08, 190.67]\n",
            "📊 비난방_H: 3,672개 데이터 예측 중...\n",
            "   ✅ 완료: 평균=41.67, 범위=[17.45, 116.63]\n",
            "📊 비난방_I: 3,672개 데이터 예측 중...\n",
            "   ✅ 완료: 평균=36.73, 범위=[14.46, 65.54]\n",
            "📊 비난방_J: 3,672개 데이터 예측 중...\n",
            "   ✅ 완료: 평균=51.58, 범위=[11.31, 115.81]\n",
            "📊 비난방_K: 3,672개 데이터 예측 중...\n",
            "   ✅ 완료: 평균=43.16, 범위=[11.62, 99.23]\n",
            "📊 비난방_L: 3,672개 데이터 예측 중...\n",
            "   ✅ 완료: 평균=9.37, 범위=[4.34, 27.61]\n",
            "📊 비난방_M: 3,672개 데이터 예측 중...\n",
            "   ✅ 완료: 평균=14.97, 범위=[5.84, 41.30]\n",
            "📊 비난방_N: 3,672개 데이터 예측 중...\n",
            "   ✅ 완료: 평균=26.64, 범위=[8.18, 92.44]\n",
            "📊 비난방_O: 3,672개 데이터 예측 중...\n",
            "   ✅ 완료: 평균=27.35, 범위=[11.05, 70.76]\n",
            "📊 비난방_P: 3,672개 데이터 예측 중...\n",
            "   ✅ 완료: 평균=53.64, 범위=[18.01, 114.16]\n",
            "📊 비난방_Q: 3,672개 데이터 예측 중...\n",
            "   ✅ 완료: 평균=20.81, 범위=[0.00, 78.72]\n",
            "📊 비난방_R: 3,672개 데이터 예측 중...\n",
            "   ✅ 완료: 평균=9.27, 범위=[3.36, 21.91]\n",
            "📊 비난방_S: 3,672개 데이터 예측 중...\n",
            "   ✅ 완료: 평균=6.11, 범위=[1.25, 15.04]\n",
            "📊 난방_A: 5,088개 데이터 예측 중...\n",
            "   ✅ 완료: 평균=161.97, 범위=[31.69, 402.42]\n",
            "📊 난방_B: 5,088개 데이터 예측 중...\n",
            "   ✅ 완료: 평균=346.91, 범위=[52.56, 953.80]\n",
            "📊 난방_C: 5,088개 데이터 예측 중...\n",
            "   ✅ 완료: 평균=358.55, 범위=[69.93, 880.29]\n",
            "📊 난방_D: 5,088개 데이터 예측 중...\n",
            "   ✅ 완료: 평균=239.75, 범위=[58.20, 561.23]\n",
            "📊 난방_E: 5,088개 데이터 예측 중...\n",
            "   ✅ 완료: 평균=68.10, 범위=[9.95, 196.96]\n",
            "📊 난방_F: 5,088개 데이터 예측 중...\n",
            "   ✅ 완료: 평균=88.45, 범위=[19.42, 218.07]\n",
            "📊 난방_G: 5,088개 데이터 예측 중...\n",
            "   ✅ 완료: 평균=299.00, 범위=[74.54, 749.82]\n",
            "📊 난방_H: 5,088개 데이터 예측 중...\n",
            "   ✅ 완료: 평균=200.82, 범위=[42.05, 505.77]\n",
            "📊 난방_I: 5,088개 데이터 예측 중...\n",
            "   ✅ 완료: 평균=100.54, 범위=[16.57, 256.51]\n",
            "📊 난방_J: 5,088개 데이터 예측 중...\n",
            "   ✅ 완료: 평균=109.03, 범위=[18.31, 278.64]\n",
            "📊 난방_K: 5,088개 데이터 예측 중...\n",
            "   ✅ 완료: 평균=61.01, 범위=[9.51, 148.39]\n",
            "📊 난방_L: 5,088개 데이터 예측 중...\n",
            "   ✅ 완료: 평균=36.65, 범위=[8.72, 101.11]\n",
            "📊 난방_M: 5,088개 데이터 예측 중...\n",
            "   ✅ 완료: 평균=51.16, 범위=[9.31, 134.27]\n",
            "📊 난방_N: 5,088개 데이터 예측 중...\n",
            "   ✅ 완료: 평균=126.49, 범위=[14.88, 334.84]\n",
            "📊 난방_O: 5,088개 데이터 예측 중...\n",
            "   ✅ 완료: 평균=105.04, 범위=[17.84, 265.32]\n",
            "📊 난방_P: 5,088개 데이터 예측 중...\n",
            "   ✅ 완료: 평균=130.25, 범위=[27.58, 303.73]\n",
            "📊 난방_Q: 5,088개 데이터 예측 중...\n",
            "   ✅ 완료: 평균=80.04, 범위=[10.19, 239.28]\n",
            "📊 난방_R: 5,088개 데이터 예측 중...\n",
            "   ✅ 완료: 평균=19.80, 범위=[3.69, 48.56]\n",
            "📊 난방_S: 5,088개 데이터 예측 중...\n",
            "   ✅ 완료: 평균=11.99, 범위=[1.17, 38.40]\n",
            "\n",
            "✅ 예측 완료: 38개 모델\n",
            "\n",
            "📈 예측값 통계 요약:\n",
            "   전체 예측 개수: 166,440.0개\n",
            "   평균 예측값 범위: [6.11, 358.55]\n",
            "   최대 예측값: 953.80\n"
          ]
        }
      ],
      "source": [
        "# 테스트 데이터 예측\n",
        "print(\"🎯 테스트 데이터 예측 시작...\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "# 예측 결과를 저장할 딕셔너리\n",
        "predictions = {}\n",
        "prediction_stats = {}\n",
        "\n",
        "# 각 모델별로 해당 테스트 데이터에 대해 예측\n",
        "for model_key, model in models.items():\n",
        "    if model_key in test_splits:\n",
        "        test_data = test_splits[model_key]\n",
        "        \n",
        "        print(f\"📊 {model_key}: {len(test_data):,}개 데이터 예측 중...\")\n",
        "        \n",
        "        try:\n",
        "            pred = model.predict(test_data)\n",
        "            predictions[model_key] = {\n",
        "                'data': test_data,\n",
        "                'predictions': pred\n",
        "            }\n",
        "            \n",
        "            # 예측 통계\n",
        "            prediction_stats[model_key] = {\n",
        "                'count': len(pred),\n",
        "                'mean': np.mean(pred),\n",
        "                'std': np.std(pred),\n",
        "                'min': np.min(pred),\n",
        "                'max': np.max(pred)\n",
        "            }\n",
        "            \n",
        "            print(f\"   ✅ 완료: 평균={np.mean(pred):.2f}, 범위=[{np.min(pred):.2f}, {np.max(pred):.2f}]\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"   ❌ 예측 실패: {str(e)}\")\n",
        "            # 기본값으로 0 할당\n",
        "            predictions[model_key] = {\n",
        "                'data': test_data,\n",
        "                'predictions': np.zeros(len(test_data))\n",
        "            }\n",
        "    else:\n",
        "        print(f\"⚠️ {model_key}: 대응하는 테스트 데이터 없음\")\n",
        "\n",
        "print(f\"\\n✅ 예측 완료: {len(predictions)}개 모델\")\n",
        "\n",
        "# 예측 통계 요약\n",
        "if prediction_stats:\n",
        "    stats_df = pd.DataFrame(prediction_stats).T\n",
        "    print(f\"\\n📈 예측값 통계 요약:\")\n",
        "    print(f\"   전체 예측 개수: {stats_df['count'].sum():,}개\")\n",
        "    print(f\"   평균 예측값 범위: [{stats_df['mean'].min():.2f}, {stats_df['mean'].max():.2f}]\")\n",
        "    print(f\"   최대 예측값: {stats_df['max'].max():.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1lscpyji6IV"
      },
      "source": [
        "## 8️⃣ 예측 결과 통합"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "MmB8fvVHi6IV"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔄 예측 결과 통합 중...\n",
            "📊 비난방_A: 3672개 인덱스에 할당\n",
            "📊 비난방_B: 3672개 인덱스에 할당\n",
            "📊 비난방_C: 3672개 인덱스에 할당\n",
            "📊 비난방_D: 3672개 인덱스에 할당\n",
            "📊 비난방_E: 3672개 인덱스에 할당\n",
            "📊 비난방_F: 3672개 인덱스에 할당\n",
            "📊 비난방_G: 3672개 인덱스에 할당\n",
            "📊 비난방_H: 3672개 인덱스에 할당\n",
            "📊 비난방_I: 3672개 인덱스에 할당\n",
            "📊 비난방_J: 3672개 인덱스에 할당\n",
            "📊 비난방_K: 3672개 인덱스에 할당\n",
            "📊 비난방_L: 3672개 인덱스에 할당\n",
            "📊 비난방_M: 3672개 인덱스에 할당\n",
            "📊 비난방_N: 3672개 인덱스에 할당\n",
            "📊 비난방_O: 3672개 인덱스에 할당\n",
            "📊 비난방_P: 3672개 인덱스에 할당\n",
            "📊 비난방_Q: 3672개 인덱스에 할당\n",
            "📊 비난방_R: 3672개 인덱스에 할당\n",
            "📊 비난방_S: 3672개 인덱스에 할당\n",
            "📊 난방_A: 5088개 인덱스에 할당\n",
            "📊 난방_B: 5088개 인덱스에 할당\n",
            "📊 난방_C: 5088개 인덱스에 할당\n",
            "📊 난방_D: 5088개 인덱스에 할당\n",
            "📊 난방_E: 5088개 인덱스에 할당\n",
            "📊 난방_F: 5088개 인덱스에 할당\n",
            "📊 난방_G: 5088개 인덱스에 할당\n",
            "📊 난방_H: 5088개 인덱스에 할당\n",
            "📊 난방_I: 5088개 인덱스에 할당\n",
            "📊 난방_J: 5088개 인덱스에 할당\n",
            "📊 난방_K: 5088개 인덱스에 할당\n",
            "📊 난방_L: 5088개 인덱스에 할당\n",
            "📊 난방_M: 5088개 인덱스에 할당\n",
            "📊 난방_N: 5088개 인덱스에 할당\n",
            "📊 난방_O: 5088개 인덱스에 할당\n",
            "📊 난방_P: 5088개 인덱스에 할당\n",
            "📊 난방_Q: 5088개 인덱스에 할당\n",
            "📊 난방_R: 5088개 인덱스에 할당\n",
            "📊 난방_S: 5088개 인덱스에 할당\n",
            "\n",
            "✅ 예측 결과 통합 완료\n",
            "   📊 총 예측 개수: 166,440개\n",
            "   📈 예측값 통계: 평균=96.16, 최대=953.80\n"
          ]
        }
      ],
      "source": [
        "# 예측 결과를 원본 test_df 순서에 맞게 통합\n",
        "print(\"🔄 예측 결과 통합 중...\")\n",
        "\n",
        "# 결과를 저장할 배열 초기화\n",
        "final_predictions = np.zeros(len(test_df))\n",
        "prediction_counts = np.zeros(len(test_df))  # 각 인덱스별 예측 횟수 추적\n",
        "\n",
        "# 각 예측 결과를 해당 인덱스에 할당\n",
        "for model_key, pred_info in predictions.items():\n",
        "    test_data = pred_info['data']\n",
        "    pred_values = pred_info['predictions']\n",
        "    \n",
        "    # 원본 test_df에서 해당 데이터의 인덱스 찾기\n",
        "    season, branch = model_key.split('_')\n",
        "    season_num = 1 if season == '난방' else 0\n",
        "    \n",
        "    # 조건에 맞는 인덱스 찾기\n",
        "    mask = (test_df['heating_season'] == season_num) & (test_df['branch_id'] == branch)\n",
        "    indices = test_df[mask].index.tolist()\n",
        "    \n",
        "    print(f\"📊 {model_key}: {len(indices)}개 인덱스에 할당\")\n",
        "    \n",
        "    # 예측값 할당 (인덱스 개수와 예측값 개수가 맞는지 확인)\n",
        "    if len(indices) == len(pred_values):\n",
        "        for i, idx in enumerate(indices):\n",
        "            final_predictions[idx] = pred_values[i]\n",
        "            prediction_counts[idx] += 1\n",
        "    else:\n",
        "        print(f\"   ⚠️ 크기 불일치: 인덱스 {len(indices)}개 vs 예측값 {len(pred_values)}개\")\n",
        "        # 크기가 다르면 최소 개수만큼만 할당\n",
        "        min_len = min(len(indices), len(pred_values))\n",
        "        for i in range(min_len):\n",
        "            final_predictions[indices[i]] = pred_values[i]\n",
        "            prediction_counts[indices[i]] += 1\n",
        "\n",
        "# 예측되지 않은 데이터 확인\n",
        "unassigned_count = np.sum(prediction_counts == 0)\n",
        "if unassigned_count > 0:\n",
        "    print(f\"⚠️ 예측되지 않은 데이터: {unassigned_count}개 (0으로 유지)\")\n",
        "\n",
        "# 중복 예측 확인\n",
        "duplicate_count = np.sum(prediction_counts > 1)\n",
        "if duplicate_count > 0:\n",
        "    print(f\"⚠️ 중복 예측된 데이터: {duplicate_count}개\")\n",
        "\n",
        "print(f\"\\n✅ 예측 결과 통합 완료\")\n",
        "print(f\"   📊 총 예측 개수: {len(final_predictions):,}개\")\n",
        "print(f\"   📈 예측값 통계: 평균={np.mean(final_predictions):.2f}, 최대={np.max(final_predictions):.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3WOSlaHi6IV"
      },
      "source": [
        "## 9️⃣ 최종 결과 저장 및 평가"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "💾 최종 결과 저장...\n",
            "📁 결과 파일 저장: xgboost_branch_season_predictions.csv\n",
            "\n",
            "📊 RMSE 성능 평가\n",
            "============================================================\n",
            "🏆 전체 성능:\n",
            "   RMSE: 21.0538\n",
            "   MAE:  12.5191\n",
            "   상관계수: 0.9834\n",
            "   유효 데이터: 166,440개\n",
            "\n",
            "📈 시즌별 RMSE 성능:\n",
            "   비난방시즌   : RMSE=10.0041 | MAE= 6.5901 | 상관= 0.950 | 69,768개\n",
            "   난방시즌    : RMSE=26.2857 | MAE=16.7981 | 상관= 0.982 | 96,672개\n",
            "\n",
            "📊 브랜치별 RMSE 성능:\n",
            "   🥇 RMSE 우수 브랜치 (Top 5):\n",
            "      1. 브랜치 R: RMSE= 2.9103 | MAE= 2.1281 | 8,760개\n",
            "      2. 브랜치 L: RMSE= 4.3791 | MAE= 3.0253 | 8,760개\n",
            "      3. 브랜치 M: RMSE= 6.8395 | MAE= 4.7554 | 8,760개\n",
            "      4. 브랜치 S: RMSE= 7.3588 | MAE= 5.8401 | 8,760개\n",
            "      5. 브랜치 K: RMSE= 9.6604 | MAE= 7.3847 | 8,760개\n",
            "   🥉 RMSE 개선 필요 브랜치 (Bottom 5):\n",
            "      1. 브랜치 H: RMSE=28.2001 | MAE=19.7508 | 8,760개\n",
            "      2. 브랜치 G: RMSE=31.4408 | MAE=22.6905 | 8,760개\n",
            "      3. 브랜치 C: RMSE=33.1009 | MAE=24.0311 | 8,760개\n",
            "      4. 브랜치 D: RMSE=35.1071 | MAE=24.7073 | 8,760개\n",
            "      5. 브랜치 B: RMSE=48.0838 | MAE=33.8632 | 8,760개\n",
            "\n",
            "   📈 브랜치별 RMSE 통계:\n",
            "      평균: 17.4319\n",
            "      표준편차: 11.8065\n",
            "      최소: 2.9103\n",
            "      최대: 48.0838\n",
            "\n",
            "🔥 시즌×브랜치 조합별 RMSE (Ranking):\n",
            "    1. 비난방시즌_L        : RMSE= 1.3702 | 3,672개\n",
            "    2. 비난방시즌_R        : RMSE= 2.1433 | 3,672개\n",
            "    3. 비난방시즌_M        : RMSE= 3.0439 | 3,672개\n",
            "    4. 난방시즌_R         : RMSE= 3.3566 | 5,088개\n",
            "    5. 비난방시즌_S        : RMSE= 4.8022 | 3,672개\n",
            "    6. 비난방시즌_N        : RMSE= 5.0054 | 3,672개\n",
            "    7. 비난방시즌_O        : RMSE= 5.1583 | 3,672개\n",
            "    8. 난방시즌_L         : RMSE= 5.6268 | 5,088개\n",
            "    9. 비난방시즌_I        : RMSE= 6.1568 | 3,672개\n",
            "   10. 비난방시즌_Q        : RMSE= 7.1685 | 3,672개\n",
            "   11. 비난방시즌_K        : RMSE= 7.3617 | 3,672개\n",
            "   12. 비난방시즌_A        : RMSE= 7.7770 | 3,672개\n",
            "   13. 난방시즌_M         : RMSE= 8.5937 | 5,088개\n",
            "   14. 난방시즌_S         : RMSE= 8.7515 | 5,088개\n",
            "   15. 비난방시즌_F        : RMSE= 9.3737 | 3,672개\n",
            "   16. 난방시즌_K         : RMSE=11.0255 | 5,088개\n",
            "   17. 비난방시즌_J        : RMSE=11.2434 | 3,672개\n",
            "   18. 비난방시즌_H        : RMSE=11.4420 | 3,672개\n",
            "   19. 난방시즌_E         : RMSE=12.2832 | 5,088개\n",
            "   20. 난방시즌_I         : RMSE=12.7520 | 5,088개\n",
            "   21. 난방시즌_F         : RMSE=13.4182 | 5,088개\n",
            "   22. 비난방시즌_G        : RMSE=13.6003 | 3,672개\n",
            "   23. 비난방시즌_P        : RMSE=13.8990 | 3,672개\n",
            "   24. 비난방시즌_E        : RMSE=14.4526 | 3,672개\n",
            "   25. 비난방시즌_D        : RMSE=14.5289 | 3,672개\n",
            "   26. 비난방시즌_C        : RMSE=14.6327 | 3,672개\n",
            "   27. 난방시즌_Q         : RMSE=14.7427 | 5,088개\n",
            "   28. 난방시즌_J         : RMSE=14.7791 | 5,088개\n",
            "   29. 난방시즌_O         : RMSE=15.4497 | 5,088개\n",
            "   30. 비난방시즌_B        : RMSE=15.8022 | 3,672개\n",
            "   31. 난방시즌_P         : RMSE=18.2266 | 5,088개\n",
            "   32. 난방시즌_N         : RMSE=18.2907 | 5,088개\n",
            "   33. 난방시즌_A         : RMSE=25.1591 | 5,088개\n",
            "   34. 난방시즌_H         : RMSE=35.7028 | 5,088개\n",
            "   35. 난방시즌_G         : RMSE=39.6036 | 5,088개\n",
            "   36. 난방시즌_C         : RMSE=41.6159 | 5,088개\n",
            "   37. 난방시즌_D         : RMSE=44.3809 | 5,088개\n",
            "   38. 난방시즌_B         : RMSE=61.6477 | 5,088개\n",
            "\n",
            "🔍 모델 최적화 vs 실제 성능 비교:\n",
            "   훈련시 최적화 RMSE: 평균=12.7222, 범위=[1.4992, 46.0968]\n",
            "   실제 테스트 RMSE: 21.0538\n",
            "   성능 차이: 8.3316\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# 최종 결과를 test_df에 추가\n",
        "print(\"💾 최종 결과 저장...\")\n",
        "\n",
        "# 원본 test_df 복사\n",
        "result_df = test_df.copy()\n",
        "\n",
        "# 예측 결과 추가 (음수값 제거)\n",
        "result_df['pred_heat_demand'] = np.maximum(final_predictions, 0).round(1)\n",
        "\n",
        "# CSV 파일 저장\n",
        "output_filename = 'xgboost_branch_season_predictions.csv'\n",
        "result_df.to_csv(output_filename, index=False)\n",
        "\n",
        "print(f\"📁 결과 파일 저장: {output_filename}\")\n",
        "\n",
        "# =============================================================================\n",
        "# RMSE 중심 성능 평가 (실제값이 있는 경우)\n",
        "# =============================================================================\n",
        "\n",
        "if 'heat_demand' in test_df.columns:\n",
        "    print(f\"\\n📊 RMSE 성능 평가\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    # 전체 RMSE\n",
        "    y_true = test_df['heat_demand'].values\n",
        "    y_pred = result_df['pred_heat_demand'].values\n",
        "    \n",
        "    # 음수나 NaN 값 제거\n",
        "    valid_mask = ~(np.isnan(y_true) | np.isnan(y_pred))\n",
        "    y_true_clean = y_true[valid_mask]\n",
        "    y_pred_clean = y_pred[valid_mask]\n",
        "    \n",
        "    overall_rmse = np.sqrt(mean_squared_error(y_true_clean, y_pred_clean))\n",
        "    overall_mae = mean_absolute_error(y_true_clean, y_pred_clean)\n",
        "    correlation = np.corrcoef(y_true_clean, y_pred_clean)[0, 1]\n",
        "    \n",
        "    print(f\"🏆 전체 성능:\")\n",
        "    print(f\"   RMSE: {overall_rmse:.4f}\")\n",
        "    print(f\"   MAE:  {overall_mae:.4f}\")\n",
        "    print(f\"   상관계수: {correlation:.4f}\")\n",
        "    print(f\"   유효 데이터: {len(y_true_clean):,}개\")\n",
        "    \n",
        "    # 시즌별 RMSE (핵심!)\n",
        "    print(f\"\\n📈 시즌별 RMSE 성능:\")\n",
        "    season_names = {0: '비난방시즌', 1: '난방시즌'}\n",
        "    season_results = {}\n",
        "    \n",
        "    for season in [0, 1]:\n",
        "        mask = (test_df['heating_season'] == season) & valid_mask\n",
        "        if np.sum(mask) > 0:\n",
        "            season_rmse = np.sqrt(mean_squared_error(y_true[mask], y_pred[mask]))\n",
        "            season_mae = mean_absolute_error(y_true[mask], y_pred[mask])\n",
        "            season_corr = np.corrcoef(y_true[mask], y_pred[mask])[0, 1] if np.sum(mask) > 1 else 0\n",
        "            season_results[season] = {\n",
        "                'rmse': season_rmse, \n",
        "                'mae': season_mae, \n",
        "                'corr': season_corr,\n",
        "                'count': np.sum(mask)\n",
        "            }\n",
        "            \n",
        "            print(f\"   {season_names[season]:8s}: RMSE={season_rmse:7.4f} | MAE={season_mae:7.4f} | 상관={season_corr:6.3f} | {np.sum(mask):,}개\")\n",
        "    \n",
        "    # 브랜치별 RMSE (상위/하위 분석)\n",
        "    print(f\"\\n📊 브랜치별 RMSE 성능:\")\n",
        "    branch_results = {}\n",
        "    \n",
        "    for branch in sorted(test_df['branch_id'].unique()):\n",
        "        mask = (test_df['branch_id'] == branch) & valid_mask\n",
        "        if np.sum(mask) > 1:  # 최소 2개 이상의 데이터가 있어야 RMSE 계산 가능\n",
        "            branch_rmse = np.sqrt(mean_squared_error(y_true[mask], y_pred[mask]))\n",
        "            branch_mae = mean_absolute_error(y_true[mask], y_pred[mask])\n",
        "            branch_results[branch] = {\n",
        "                'rmse': branch_rmse,\n",
        "                'mae': branch_mae, \n",
        "                'count': np.sum(mask)\n",
        "            }\n",
        "    \n",
        "    if branch_results:\n",
        "        # RMSE 기준 정렬\n",
        "        sorted_branches = sorted(branch_results.items(), key=lambda x: x[1]['rmse'])\n",
        "        \n",
        "        print(f\"   🥇 RMSE 우수 브랜치 (Top 5):\")\n",
        "        for i, (branch, metrics) in enumerate(sorted_branches[:5], 1):\n",
        "            print(f\"      {i}. 브랜치 {branch}: RMSE={metrics['rmse']:7.4f} | MAE={metrics['mae']:7.4f} | {metrics['count']:,}개\")\n",
        "        \n",
        "        print(f\"   🥉 RMSE 개선 필요 브랜치 (Bottom 5):\")\n",
        "        for i, (branch, metrics) in enumerate(sorted_branches[-5:], 1):\n",
        "            print(f\"      {i}. 브랜치 {branch}: RMSE={metrics['rmse']:7.4f} | MAE={metrics['mae']:7.4f} | {metrics['count']:,}개\")\n",
        "        \n",
        "        # 브랜치별 성능 통계\n",
        "        rmse_values = [v['rmse'] for v in branch_results.values()]\n",
        "        print(f\"\\n   📈 브랜치별 RMSE 통계:\")\n",
        "        print(f\"      평균: {np.mean(rmse_values):.4f}\")\n",
        "        print(f\"      표준편차: {np.std(rmse_values):.4f}\")\n",
        "        print(f\"      최소: {np.min(rmse_values):.4f}\")\n",
        "        print(f\"      최대: {np.max(rmse_values):.4f}\")\n",
        "    \n",
        "    # 시즌×브랜치 조합별 RMSE\n",
        "    print(f\"\\n🔥 시즌×브랜치 조합별 RMSE (Ranking):\")\n",
        "    combo_results = []\n",
        "    \n",
        "    for season in [0, 1]:\n",
        "        for branch in test_df['branch_id'].unique():\n",
        "            mask = (test_df['heating_season'] == season) & (test_df['branch_id'] == branch) & valid_mask\n",
        "            if np.sum(mask) > 1:\n",
        "                combo_rmse = np.sqrt(mean_squared_error(y_true[mask], y_pred[mask]))\n",
        "                combo_name = f\"{season_names[season]}_{branch}\"\n",
        "                combo_results.append((combo_name, combo_rmse, np.sum(mask)))\n",
        "    \n",
        "    # RMSE 기준 정렬하여 표시\n",
        "    combo_results.sort(key=lambda x: x[1])\n",
        "    for i, (combo_name, rmse, count) in enumerate(combo_results, 1):\n",
        "        print(f\"   {i:2d}. {combo_name:15s}: RMSE={rmse:7.4f} | {count:,}개\")\n",
        "    \n",
        "    # 훈련된 모델들의 최적화 성능과 실제 테스트 성능 비교\n",
        "    print(f\"\\n🔍 모델 최적화 vs 실제 성능 비교:\")\n",
        "    optimization_rmses = [v['best_score'] for v in training_results.values() if v.get('best_score') is not None]\n",
        "    \n",
        "    if optimization_rmses:\n",
        "        print(f\"   훈련시 최적화 RMSE: 평균={np.mean(optimization_rmses):.4f}, 범위=[{np.min(optimization_rmses):.4f}, {np.max(optimization_rmses):.4f}]\")\n",
        "        print(f\"   실제 테스트 RMSE: {overall_rmse:.4f}\")\n",
        "        print(f\"   성능 차이: {abs(overall_rmse - np.mean(optimization_rmses)):.4f}\")\n",
        "    \n",
        "else:\n",
        "    print(f\"\\n⚠️ 테스트 데이터에 heat_demand 컬럼이 없어서 RMSE 평가를 수행할 수 없습니다.\")\n",
        "    print(f\"   예측 결과만 저장되었습니다.\")\n",
        "    \n",
        "    # 예측값 기본 통계\n",
        "    print(f\"\\n📊 예측값 기본 통계:\")\n",
        "    print(f\"   개수: {len(result_df):,}개\")\n",
        "    print(f\"   평균: {result_df['pred_heat_demand'].mean():.2f}\")\n",
        "    print(f\"   중앙값: {result_df['pred_heat_demand'].median():.2f}\")\n",
        "    print(f\"   표준편차: {result_df['pred_heat_demand'].std():.2f}\")\n",
        "    print(f\"   범위: [{result_df['pred_heat_demand'].min():.2f}, {result_df['pred_heat_demand'].max():.2f}]\")\n",
        "    \n",
        "    # 시즌별 예측 통계\n",
        "    print(f\"\\n📈 시즌별 예측 통계:\")\n",
        "    for season in [0, 1]:\n",
        "        season_data = result_df[result_df['heating_season'] == season]['pred_heat_demand']\n",
        "        if len(season_data) > 0:\n",
        "            season_name = '비난방시즌' if season == 0 else '난방시즌'\n",
        "            print(f\"   {season_name}: 평균={season_data.mean():.2f}, 개수={len(season_data):,}개\")\n",
        "\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 📍 NaN 있는 경우 아래와 같이 성능평가 진행"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 새로운 안전한 RMSE 평가 사용\n",
        "evaluation_results = safe_rmse_evaluation(test_df, result_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlR68tz9W1AF"
      },
      "source": [
        "## 🔟 모델 정보 저장"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xk3Cf_3YWyKq"
      },
      "outputs": [],
      "source": [
        "# 모델 정보 및 결과 저장\n",
        "print(\"💾 모델 정보 저장...\")\n",
        "\n",
        "# 훈련 결과 및 모델 정보를 JSON으로 저장\n",
        "model_info = {\n",
        "    'total_models': len(models),\n",
        "    'successful_models': len([k for k, v in training_results.items() if v.get('best_score') is not None]),\n",
        "    'training_results': training_results,\n",
        "    'prediction_stats': prediction_stats if 'prediction_stats' in locals() else {},\n",
        "    'feature_columns': models[list(models.keys())[0]].feature_cols if models else [],\n",
        "    'optimization_trials_per_model': n_trials_per_model,\n",
        "    'total_training_time_minutes': total_time_min if 'total_time_min' in locals() else 0\n",
        "}\n",
        "\n",
        "# RMSE 결과 추가 (있는 경우)\n",
        "if 'heat_demand' in test_df.columns:\n",
        "    model_info['evaluation_results'] = {\n",
        "        'overall_rmse': overall_rmse,\n",
        "        'overall_mae': overall_mae,\n",
        "        'correlation': correlation\n",
        "    }\n",
        "\n",
        "# JSON 파일로 저장\n",
        "with open('model_info_and_results.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(model_info, f, indent=2, ensure_ascii=False, default=str)\n",
        "\n",
        "print(\"📁 model_info_and_results.json 저장 완료\")\n",
        "\n",
        "# 간단한 요약 출력\n",
        "print(f\"\\n📋 모델 정보 요약:\")\n",
        "print(f\"   🔧 총 모델 수: {model_info['total_models']}개\")\n",
        "print(f\"   ✅ 성공한 모델: {model_info['successful_models']}개\")\n",
        "print(f\"   📊 사용 특성 수: {len(model_info['feature_columns'])}개\")\n",
        "print(f\"   🎯 모델당 최적화 시도: {model_info['optimization_trials_per_model']}회\")\n",
        "\n",
        "# Google Drive 저장 (Colab 환경)\n",
        "if IN_COLAB:\n",
        "    save_drive = input(\"\\nGoogle Drive에 결과 파일들을 저장하시겠습니까? (y/n): \").lower() == 'y'\n",
        "    if save_drive:\n",
        "        try:\n",
        "            !cp {output_filename} /content/drive/MyDrive/\n",
        "            !cp model_info_and_results.json /content/drive/MyDrive/\n",
        "            print(\"✅ Google Drive 저장 완료!\")\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Google Drive 저장 실패: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "leJLw4dVi6IW"
      },
      "source": [
        "## 🎯 최종 요약"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K8stlKlsi6IX"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"🔥 지역난방 열수요 예측: 시즌별-브랜치별 XGBoost 모델 - 최종 요약\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(f\"\\n🏗️ 모델 구성:\")\n",
        "print(f\"   📊 XGBoost 개별 모델 (시즌별 × 브랜치별)\")\n",
        "print(f\"   🎯 Optuna TPE 하이퍼파라미터 최적화\")\n",
        "print(f\"   📋 총 모델 수: {len(models)}개\")\n",
        "print(f\"   ✅ 성공적 훈련: {len([k for k, v in training_results.items() if v.get('best_score') is not None])}개\")\n",
        "\n",
        "print(f\"\\n📈 특성 엔지니어링:\")\n",
        "print(f\"   ⭐ HDD, wind_chill, 온도 제곱/세제곱\")\n",
        "print(f\"   🔄 순환형 인코딩 (시간, 월, 요일)\")\n",
        "print(f\"   📋 범주형: heating_season, 피크시간, 기온범주, 강수강도\")\n",
        "print(f\"   🧮 상호작용: 습도×기온, 월×일\")\n",
        "# print(f\"   📏 StandardScaler 정규화\")\n",
        "\n",
        "print(f\"\\n🎯 모델링 전략:\")\n",
        "print(f\"   ❄️ 난방시즌 (10,11,12,1,2,3,4월) 전용 모델\")\n",
        "print(f\"   🌞 비난방시즌 (5,6,7,8,9월) 전용 모델\")\n",
        "print(f\"   🏢 브랜치별 개별 모델 (각 지사의 특성 반영)\")\n",
        "print(f\"   ⚡ XGBoost with Early Stopping\")\n",
        "\n",
        "print(f\"\\n🔍 최적화 설정:\")\n",
        "print(f\"   📊 Optuna TPE Sampler\")\n",
        "print(f\"   🎯 모델당 {n_trials_per_model}회 시도\")\n",
        "print(f\"   📈 시계열 기반 Train/Validation 분할 (80:20)\")\n",
        "print(f\"   🎪 XGBoost Pruning Callback 사용\")\n",
        "\n",
        "if 'heat_demand' in test_df.columns:\n",
        "    print(f\"\\n🏆 최종 성능:\")\n",
        "    print(f\"   📊 전체 RMSE: {overall_rmse:.4f}\")\n",
        "    print(f\"   📏 전체 MAE: {overall_mae:.4f}\")\n",
        "    print(f\"   📈 상관계수: {correlation:.4f}\")\n",
        "\n",
        "# 최고 성능 모델 정보\n",
        "if successful_models is not None and len(successful_models) > 0:\n",
        "    best_model_name = successful_models['best_score'].idxmin()\n",
        "    best_score = successful_models.loc[best_model_name, 'best_score']\n",
        "    print(f\"\\n🥇 최고 성능 모델: {best_model_name} (RMSE: {best_score:.4f})\")\n",
        "\n",
        "print(f\"\\n📁 출력 파일:\")\n",
        "print(f\"   • {output_filename} - 예측 결과\")\n",
        "print(f\"   • model_info_and_results.json - 모델 정보 및 훈련 결과\")\n",
        "print(f\"   • 핵심 컬럼: pred_heat_demand (예측값)\")\n",
        "\n",
        "print(f\"\\n⏱️ 실행 시간:\")\n",
        "if 'total_time_min' in locals():\n",
        "    print(f\"   🚀 총 훈련 시간: {total_time_min:.1f}분\")\n",
        "    print(f\"   ⚡ 평균 모델당: {total_time_min*60/len(models):.1f}초\")\n",
        "\n",
        "print(f\"\\n🎉 지역난방 열수요 예측 완료!\")\n",
        "print(f\"🔬 혁신 포인트: 시즌×브랜치 세분화 + Optuna 자동 최적화\")\n",
        "print(f\"📊 총 {len(models)}개 모델로 정밀한 지역별-시즌별 예측 구현\")\n",
        "print(\"=\"*80)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
