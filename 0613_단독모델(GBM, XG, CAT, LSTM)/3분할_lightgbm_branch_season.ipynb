{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9N8kUTzi6IA"
      },
      "source": [
        "# 🔥 지역난방 열수요 예측: 시즌별-브랜치별 LightGBM 모델\n",
        "\n",
        "## 📋 모델링 전략\n",
        "- **시즌 분할**: Heating Season vs Non-Heating Season\n",
        "- **브랜치별 개별 모델**: 각 branch_id마다 전용 모델\n",
        "- **LightGBM**: 모든 모델에 LightGBM 사용\n",
        "- **하이퍼파라미터 최적화**: Optuna TPE 사용\n",
        "- **총 모델 수**: 38개 (2시즌 × 19브랜치)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6nmbT6Edi6ID"
      },
      "outputs": [],
      "source": [
        "# Google Colab 환경 확인 및 패키지 설치\n",
        "import sys\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "\n",
        "if IN_COLAB:\n",
        "    print(\"🔥 Google Colab 환경에서 실행 중...\")\n",
        "    !pip install xgboost optuna\n",
        "    from google.colab import files, drive\n",
        "    print(\"✅ 패키지 설치 완료!\")\n",
        "else:\n",
        "    print(\"💻 로컬 환경에서 실행 중...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cc2w0lOti6IH"
      },
      "outputs": [],
      "source": [
        "# 라이브러리 import\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from tqdm.auto import tqdm\n",
        "import pickle\n",
        "import json\n",
        "\n",
        "# 머신러닝\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
        "import lightgbm as lgb\n",
        "# XGBoostPruningCallback 삭제 (LightGBM은 불필요)\n",
        "\n",
        "# Optuna\n",
        "import optuna\n",
        "from optuna.integration import XGBoostPruningCallback\n",
        "from optuna.samplers import TPESampler\n",
        "\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "print(\"📚 라이브러리 로드 완료!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HsWjgGvyi6II"
      },
      "outputs": [],
      "source": [
        "# 데이터 파일 로드\n",
        "if IN_COLAB:\n",
        "    print(\"📁 파일 업로드 방법 선택:\")\n",
        "    print(\"1. 직접 업로드\")\n",
        "    print(\"2. Google Drive\")\n",
        "\n",
        "    method = input(\"선택 (1 또는 2): \")\n",
        "\n",
        "    if method == \"1\":\n",
        "        uploaded = files.upload()\n",
        "        files_list = list(uploaded.keys())\n",
        "        train_path = [f for f in files_list if 'train' in f.lower()][0]\n",
        "        test_path = [f for f in files_list if 'test' in f.lower()][0]\n",
        "    else:\n",
        "        drive.mount('/content/drive')\n",
        "        train_path = \"/content/drive/MyDrive/train_heat.csv\"\n",
        "        test_path = \"/content/drive/MyDrive/test_heat.csv\"\n",
        "else:\n",
        "    train_path = 'dataset/train_data_2122.csv'\n",
        "    test_path = 'dataset/test_data_23.csv'\n",
        "\n",
        "print(f\"✅ 파일 경로 설정 완료\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BnYi_t0i6IJ"
      },
      "source": [
        "## 1️⃣ 데이터 로드 및 전처리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iy4VEB5gi6IK"
      },
      "outputs": [],
      "source": [
        "def load_and_preprocess(train_path, test_path):\n",
        "    print(\"📊 데이터 로드 및 전처리...\")\n",
        "\n",
        "    # 데이터 로드\n",
        "    train_df = pd.read_csv(train_path)\n",
        "    test_df = pd.read_csv(test_path)\n",
        "\n",
        "    def process_df(df):\n",
        "        # 컬럼명 정리\n",
        "        if 'Unnamed: 0' in df.columns:\n",
        "            df = df.drop(columns=['Unnamed: 0'])\n",
        "        df.columns = [col.replace('train_heat.', '') for col in df.columns]\n",
        "\n",
        "        # 시간 변수\n",
        "        df['datetime'] = pd.to_datetime(df['tm'], format='%Y%m%d%H')\n",
        "        # df['year'] = df['datetime'].dt.year\n",
        "        df['month'] = df['datetime'].dt.month\n",
        "        # df['day'] = df['datetime'].dt.day\n",
        "        df['hour'] = df['datetime'].dt.hour\n",
        "        df['dayofweek'] = df['datetime'].dt.dayofweek\n",
        "\n",
        "        # 결측치 처리\n",
        "        missing_cols = ['ta', 'wd', 'ws', 'rn_day', 'rn_hr1', 'hm', 'si', 'ta_chi']\n",
        "        if 'heat_demand' in df.columns:\n",
        "            missing_cols.append('heat_demand')\n",
        "\n",
        "        for col in missing_cols:\n",
        "            if col in df.columns:\n",
        "                df[col] = df[col].replace(-99, np.nan)\n",
        "\n",
        "        # wd -9.9 결측치 처리\n",
        "        df.loc[df['wd'] == -9.9, 'wd'] = np.nan\n",
        "\n",
        "        # 일사량 야간 처리\n",
        "        if 'si' in df.columns:\n",
        "            night_mask = (df['hour'] < 8) | (df['hour'] > 18)\n",
        "            df.loc[night_mask & df['si'].isna(), 'si'] = 0\n",
        "\n",
        "        # 지사별 보간\n",
        "        df = df.sort_values(['branch_id', 'datetime'])\n",
        "        numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
        "\n",
        "        for branch in df['branch_id'].unique():\n",
        "            mask = df['branch_id'] == branch\n",
        "            df.loc[mask, numeric_cols] = df.loc[mask, numeric_cols].interpolate().fillna(method='ffill').fillna(method='bfill')\n",
        "\n",
        "        return df\n",
        "\n",
        "    train_df = process_df(train_df)\n",
        "    test_df = process_df(test_df)\n",
        "\n",
        "    print(f\"   훈련: {train_df.shape}, 테스트: {test_df.shape}\")\n",
        "    print(f\"   기간: {train_df['datetime'].min()} ~ {test_df['datetime'].max()}\")\n",
        "    print(f\"   브랜치: {sorted(train_df['branch_id'].unique())}\")\n",
        "\n",
        "    return train_df, test_df\n",
        "\n",
        "train_df, test_df = load_and_preprocess(train_path, test_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnbWsoYUi6IK"
      },
      "source": [
        "## 2️⃣ 파생변수 생성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qmwGrilMi6IL"
      },
      "outputs": [],
      "source": [
        "def create_features(df):\n",
        "    \"\"\"HDD, wind_chill, 순환형 인코딩, 범주형 변수 생성\"\"\"\n",
        "    df = df.copy()\n",
        "\n",
        "    # ⭐ HDD (수치형)\n",
        "    if 'ta' in df.columns:\n",
        "        df['HDD_18'] = np.maximum(18 - df['ta'], 0)\n",
        "        df['HDD_20'] = np.maximum(20 - df['ta'], 0)\n",
        "\n",
        "    # ⭐ wind_chill (수치형)\n",
        "    if 'ta' in df.columns and 'ws' in df.columns:\n",
        "        df['wind_chill'] = np.where(\n",
        "            (df['ta'] <= 10) & (df['ws'] > 0),\n",
        "            13.12 + 0.6215 * df['ta'] - 11.37 * (df['ws'] ** 0.16) + 0.3965 * df['ta'] * (df['ws'] ** 0.16),\n",
        "            df['ta']\n",
        "        )\n",
        "\n",
        "    # ⭐ heating_season (범주형) - 3시즌 ######################################\n",
        "    def assign_season(month):\n",
        "        if month in [5, 6, 7, 8, 9]:  # 비난방\n",
        "            return 0\n",
        "        elif month in [10, 11, 12, 1]:  # 난방 상승\n",
        "            return 1\n",
        "        else:  # month in [2, 3, 4]  # 난방 하강\n",
        "            return 2\n",
        "\n",
        "    df['heating_season'] = df['month'].apply(assign_season)\n",
        "\n",
        "    # 시간대 범주형\n",
        "    df['is_weekend'] = (df['dayofweek'] >= 5).astype(int)\n",
        "    df['is_peak_morning'] = ((df['hour'] >= 7) & (df['hour'] <= 9)).astype(int)\n",
        "    df['is_peak_evening'] = ((df['hour'] >= 18) & (df['hour'] <= 22)).astype(int)\n",
        "    df['is_night'] = ((df['hour'] >= 23) | (df['hour'] <= 5)).astype(int)\n",
        "\n",
        "    # 피크시간 통합\n",
        "    df['peak_time_category'] = 0\n",
        "    df.loc[df['is_peak_morning'] == 1, 'peak_time_category'] = 1\n",
        "    df.loc[df['is_peak_evening'] == 1, 'peak_time_category'] = 2\n",
        "    df.loc[df['is_night'] == 1, 'peak_time_category'] = 3\n",
        "\n",
        "    # ⭐ 기온 범주 (범주형)\n",
        "    if 'ta' in df.columns:\n",
        "        df['temp_category'] = pd.cut(df['ta'],\n",
        "                                   bins=[-np.inf, 0, 10, 20, 30, np.inf],\n",
        "                                   labels=[0, 1, 2, 3, 4]).astype(int)\n",
        "\n",
        "    # ⭐ 강수 강도 (범주형)\n",
        "    if 'rn_day' in df.columns:\n",
        "        df['rain_intensity'] = pd.cut(df['rn_day'],\n",
        "                                   bins=[-1, 0, 1, 5, 10, np.inf],\n",
        "                                   labels=[0, 1, 2, 3, 4]).astype(int)\n",
        "\n",
        "    # ⭐ 순환형 인코딩 (시간 cos, sin)\n",
        "    df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)\n",
        "    df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)\n",
        "    df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)\n",
        "    df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)\n",
        "    df['dayofweek_sin'] = np.sin(2 * np.pi * df['dayofweek'] / 7)\n",
        "    df['dayofweek_cos'] = np.cos(2 * np.pi * df['dayofweek'] / 7)\n",
        "\n",
        "    # 시간 기반 파생변수\n",
        "    df['hour_squared'] = df['hour'] ** 2\n",
        "    df['month_day_interaction'] = df['month'] * df['datetime'].dt.day\n",
        "    \n",
        "    # 기온 관련 파생변수\n",
        "    if 'ta' in df.columns:\n",
        "        df['ta_squared'] = df['ta'] ** 2\n",
        "        df['ta_cubed'] = df['ta'] ** 3\n",
        "    \n",
        "    # 습도와 기온 상호작용\n",
        "    if 'hm' in df.columns and 'ta' in df.columns:\n",
        "        df['hm_ta_interaction'] = df['hm'] * df['ta']\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "# 파생변수 생성\n",
        "train_df = create_features(train_df)\n",
        "test_df = create_features(test_df)\n",
        "\n",
        "print(f\"✅ 파생변수 생성 완료: {train_df.shape[1]}개 컬럼\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BnrDxhRi6IM"
      },
      "source": [
        "## 3️⃣ 시즌별-브랜치별 데이터 분할"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jmdSkH3Ci6IN"
      },
      "outputs": [],
      "source": [
        "# 시즌별-브랜치별 데이터 분할\n",
        "def split_by_season_and_branch(df):\n",
        "    data_splits = {}\n",
        "    \n",
        "    branches = sorted(df['branch_id'].unique())\n",
        "    seasons = [0, 1, 2]  # 0: 비난방, 1: 난방상승, 2: 난방하강\n",
        "    season_names = {0: '비난방', 1: '난방상승', 2: '난방하강'} ######################################\n",
        "    \n",
        "    print(f\"📊 데이터 분할 정보:\")\n",
        "    print(f\"   브랜치: {len(branches)}개 - {branches}\")\n",
        "    print(f\"   시즌: {len(seasons)}개 - {[season_names[s] for s in seasons]}\")\n",
        "    print(f\"   총 조합: {len(branches) * len(seasons)}개\")\n",
        "    \n",
        "    for season in seasons:\n",
        "        for branch in branches:\n",
        "            key = f\"{season_names[season]}_{branch}\"\n",
        "            \n",
        "            # 시즌과 브랜치로 필터링\n",
        "            subset = df[(df['heating_season'] == season) & (df['branch_id'] == branch)].copy()\n",
        "            \n",
        "            if len(subset) > 0:\n",
        "                data_splits[key] = subset\n",
        "                print(f\"   {key}: {len(subset):,}개 데이터\")\n",
        "            else:\n",
        "                print(f\"   {key}: 데이터 없음 ⚠️\")\n",
        "    \n",
        "    return data_splits\n",
        "\n",
        "# 훈련 및 테스트 데이터 분할\n",
        "train_splits = split_by_season_and_branch(train_df)\n",
        "test_splits = split_by_season_and_branch(test_df)\n",
        "\n",
        "print(f\"\\n✅ 훈련 데이터: {len(train_splits)}개 분할\")\n",
        "print(f\"✅ 테스트 데이터: {len(test_splits)}개 분할\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 📌 Validation시 월별 추출"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_temporal_split_indices(df, test_size=0.2, min_val_samples=10):\n",
        "    \"\"\"시간 기반 분할 인덱스 반환\"\"\"\n",
        "    \n",
        "    month_counts = df['month'].value_counts()\n",
        "    valid_months = month_counts[month_counts >= min_val_samples * 2].index\n",
        "    \n",
        "    if len(valid_months) < 3:\n",
        "        # 폴백: 기존 방식\n",
        "        split_idx = int(len(df) * (1 - test_size))\n",
        "        return df.index[:split_idx], df.index[split_idx:]\n",
        "    \n",
        "    train_indices = []\n",
        "    val_indices = []\n",
        "    \n",
        "    for month in valid_months:\n",
        "        month_data = df[df['month'] == month].sort_values('datetime')\n",
        "        val_size = max(min_val_samples, int(len(month_data) * test_size))\n",
        "        \n",
        "        train_indices.extend(month_data.iloc[:-val_size].index)\n",
        "        val_indices.extend(month_data.iloc[-val_size:].index)\n",
        "    \n",
        "    print(f\"      📅 월별 분할: {len(valid_months)}개월, 검증 {len(val_indices)}개\")\n",
        "    \n",
        "    return train_indices, val_indices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmL7oLW1i6IN"
      },
      "source": [
        "## 4️⃣ LightGBM 모델 클래스 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class OptimizedLightGBMModel:\n",
        "    def __init__(self, model_name):\n",
        "        self.model_name = model_name\n",
        "        self.model = None\n",
        "        self.best_params = None\n",
        "        self.feature_cols = None\n",
        "        self.study = None\n",
        "        self.best_score = None\n",
        "        \n",
        "        # LightGBM 버전 확인\n",
        "        self.lgb_version = lgb.__version__\n",
        "        \n",
        "    def define_feature_columns(self, df):\n",
        "        \"\"\"특성 컬럼 정의\"\"\"\n",
        "        exclude_cols = [\n",
        "        'tm', 'datetime', 'year', 'heat_demand', 'branch_id', 'month'  # datetime 제외\n",
        "        ]\n",
        "        \n",
        "        self.feature_cols = [col for col in df.columns \n",
        "                           if col not in exclude_cols and df[col].dtype in ['int64', 'float64']]\n",
        "        \n",
        "        print(f\"   📋 {self.model_name}: {len(self.feature_cols)}개 특성 사용\")\n",
        "        return self.feature_cols\n",
        "    \n",
        "    def objective(self, trial, X_train, y_train, X_val, y_val):\n",
        "        \"\"\"Optuna 목적 함수 (LightGBM 파라미터)\"\"\"\n",
        "        # LightGBM 하이퍼파라미터 탐색 공간\n",
        "        params = {\n",
        "            'objective': 'regression',\n",
        "            'metric': 'rmse',\n",
        "            'boosting_type': 'gbdt',\n",
        "            'num_leaves': trial.suggest_int('num_leaves', 10, 100),\n",
        "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
        "            'feature_fraction': trial.suggest_float('feature_fraction', 0.4, 1.0),\n",
        "            'bagging_fraction': trial.suggest_float('bagging_fraction', 0.4, 1.0),\n",
        "            'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n",
        "            'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
        "            'lambda_l1': trial.suggest_float('lambda_l1', 1e-8, 10.0, log=True),\n",
        "            'lambda_l2': trial.suggest_float('lambda_l2', 1e-8, 10.0, log=True),\n",
        "            'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 5, 50),\n",
        "            'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
        "            'random_state': 42,\n",
        "            'verbosity': -1,  # 로그 출력 안함\n",
        "            'n_jobs': -1\n",
        "        }\n",
        "        \n",
        "        # 데이터셋 생성\n",
        "        train_data = lgb.Dataset(X_train, label=y_train)\n",
        "        val_data = lgb.Dataset(X_val, label=y_val, reference=train_data)\n",
        "        \n",
        "        # 모델 훈련 (early stopping 포함)\n",
        "        model = lgb.train(\n",
        "            params,\n",
        "            train_data,\n",
        "            valid_sets=[val_data],\n",
        "            num_boost_round=1000,\n",
        "            callbacks=[\n",
        "                lgb.early_stopping(50),\n",
        "                lgb.log_evaluation(0)  # 로그 출력 안함\n",
        "            ]\n",
        "        )\n",
        "        \n",
        "        # 검증 예측\n",
        "        y_pred = model.predict(X_val, num_iteration=model.best_iteration)\n",
        "        rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
        "        \n",
        "        return rmse\n",
        "    \n",
        "    def fit(self, df, target_col='heat_demand', n_trials=20):\n",
        "        \"\"\"모델 훈련 (Optuna 최적화 포함)\"\"\"\n",
        "        print(f\"\\n🔍 {self.model_name} 모델 훈련 시작...\")\n",
        "        print(f\"   🔧 LightGBM 버전: {self.lgb_version}\")\n",
        "        \n",
        "        if len(df) < 10:\n",
        "            self._fit_basic_model(df, target_col)\n",
        "            return\n",
        "    \n",
        "        # 🔥 1. 분할 인덱스 먼저 구하기 (datetime 있을 때)\n",
        "        train_indices, val_indices = get_temporal_split_indices(df, test_size=0.2)\n",
        "        \n",
        "        # 🔥 2. 특성 컬럼 정의 (datetime 제거)\n",
        "        self.define_feature_columns(df)\n",
        "        \n",
        "        # 🔥 3. X, y 생성 (datetime 없음)\n",
        "        X = df[self.feature_cols].copy()\n",
        "        y = df[target_col].copy()\n",
        "        \n",
        "        # 🔥 4. 인덱스로 분할\n",
        "        X_train = X.loc[train_indices]\n",
        "        y_train = y.loc[train_indices]\n",
        "        X_val = X.loc[val_indices]\n",
        "        y_val = y.loc[val_indices]\n",
        "        \n",
        "        print(f\"      📊 훈련: {len(X_train):,}개, 검증: {len(X_val):,}개\")\n",
        "            \n",
        "        if len(X_train) < 5 or len(X_val) < 2:\n",
        "            print(f\"   ⚠️ 분할 후 데이터 부족 - 기본 모델 사용\")\n",
        "            self._fit_basic_model(df, target_col)\n",
        "            return\n",
        "        \n",
        "        # Optuna 최적화\n",
        "        print(f\"   🎯 하이퍼파라미터 최적화: \", end=\"\", flush=True)\n",
        "        \n",
        "        try:\n",
        "            # 모든 로그 끄기\n",
        "            optuna.logging.set_verbosity(optuna.logging.ERROR)\n",
        "            \n",
        "            self.study = optuna.create_study(\n",
        "                direction='minimize',\n",
        "                sampler=TPESampler(seed=42),\n",
        "                study_name=f\"lgb_{self.model_name}\"\n",
        "            )\n",
        "            \n",
        "            # 진행상황 표시를 위한 콜백\n",
        "            def progress_callback(study, trial):\n",
        "                print(f\"\\r   🎯 하이퍼파라미터 최적화: {len(study.trials)}/{n_trials} (Best RMSE: {study.best_value:.4f})\", end=\"\", flush=True)\n",
        "            \n",
        "            # 최적화 실행\n",
        "            self.study.optimize(\n",
        "                lambda trial: self.objective(trial, X_train, y_train, X_val, y_val),\n",
        "                n_trials=n_trials,\n",
        "                callbacks=[progress_callback]\n",
        "            )\n",
        "            \n",
        "            print()  # 줄바꿈\n",
        "            \n",
        "            # 안전한 best_value 접근\n",
        "            if len(self.study.trials) > 0 and self.study.best_trial is not None:\n",
        "                self.best_score = self.study.best_value\n",
        "                self.best_params = self.study.best_params.copy()\n",
        "                \n",
        "                # 기본 파라미터 추가\n",
        "                self.best_params.update({\n",
        "                    'objective': 'regression',\n",
        "                    'metric': 'rmse',\n",
        "                    'random_state': 42,\n",
        "                    'verbosity': -1,\n",
        "                    'n_jobs': -1\n",
        "                })\n",
        "                \n",
        "                # 전체 데이터로 최종 훈련\n",
        "                train_data_full = lgb.Dataset(X, label=y)\n",
        "                val_data_full = lgb.Dataset(X_val, label=y_val, reference=train_data_full)\n",
        "                \n",
        "                self.model = lgb.train(\n",
        "                    self.best_params,\n",
        "                    train_data_full,\n",
        "                    valid_sets=[val_data_full],\n",
        "                    num_boost_round=1500,\n",
        "                    callbacks=[\n",
        "                        lgb.early_stopping(100),\n",
        "                        lgb.log_evaluation(0)\n",
        "                    ]\n",
        "                )\n",
        "                \n",
        "                # 성능 정보\n",
        "                val_pred = self.model.predict(X_val, num_iteration=self.model.best_iteration)\n",
        "                val_rmse = np.sqrt(mean_squared_error(y_val, val_pred))\n",
        "                \n",
        "                print(f\"   📈 최적화 완료: Best RMSE = {self.best_score:.4f}\")\n",
        "                print(f\"   📊 검증 RMSE = {val_rmse:.4f}\")\n",
        "                print(f\"   🏆 최적 파라미터: lr={self.best_params.get('learning_rate', 0.1):.3f}, leaves={self.best_params.get('num_leaves', 31)}\")\n",
        "                \n",
        "            else:\n",
        "                print(f\"   ⚠️ 최적화 실패: 유효한 trial 없음 - 기본 모델 사용\")\n",
        "                self._fit_basic_model(df, target_col)\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(f\"\\n   ⚠️ 최적화 실패: {str(e)[:30]}... - 기본 모델 사용\")\n",
        "            self._fit_basic_model(df, target_col)\n",
        "    \n",
        "    def _fit_basic_model(self, df, target_col):\n",
        "        \"\"\"기본 모델 훈련 (최적화 실패 시 사용)\"\"\"\n",
        "        if not hasattr(self, 'feature_cols') or self.feature_cols is None:\n",
        "            self.define_feature_columns(df)\n",
        "        \n",
        "        X = df[self.feature_cols].copy()\n",
        "        y = df[target_col].copy()\n",
        "        \n",
        "        \n",
        "        # 기본 LightGBM 파라미터\n",
        "        params = {\n",
        "            'objective': 'regression',\n",
        "            'metric': 'rmse',\n",
        "            'boosting_type': 'gbdt',\n",
        "            'num_leaves': 31,\n",
        "            'learning_rate': 0.1,\n",
        "            'feature_fraction': 0.8,\n",
        "            'bagging_fraction': 0.8,\n",
        "            'bagging_freq': 5,\n",
        "            'random_state': 42,\n",
        "            'verbosity': -1,\n",
        "            'n_jobs': -1\n",
        "        }\n",
        "        \n",
        "        # 데이터셋 생성 및 훈련\n",
        "        train_data = lgb.Dataset(X, label=y)\n",
        "        \n",
        "        self.model = lgb.train(\n",
        "            params,\n",
        "            train_data,\n",
        "            num_boost_round=500,\n",
        "            callbacks=[lgb.log_evaluation(0)]\n",
        "        )\n",
        "        \n",
        "        self.best_score = None\n",
        "        self.best_params = None\n",
        "        print(f\"   🔧 기본 모델 훈련 완료\")\n",
        "    \n",
        "    def predict(self, df):\n",
        "        \"\"\"예측\"\"\"\n",
        "        if self.model is None:\n",
        "            return np.full(len(df), 0)\n",
        "        \n",
        "        # 동일한 특성 컬럼 사용\n",
        "        X = df[self.feature_cols].copy()\n",
        "        X = X.fillna(0)\n",
        "        \n",
        "        # 예측 (best_iteration 사용)\n",
        "        if hasattr(self.model, 'best_iteration') and self.model.best_iteration > 0:\n",
        "            predictions = self.model.predict(X, num_iteration=self.model.best_iteration)\n",
        "        else:\n",
        "            predictions = self.model.predict(X)\n",
        "        \n",
        "        # 음수 값 처리\n",
        "        predictions = np.maximum(predictions, 0)\n",
        "        \n",
        "        return predictions\n",
        "\n",
        "print(\"✅ LightGBM 모델 클래스 정의 완료\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SewcIVN_i6IR"
      },
      "source": [
        "## 5️⃣ 57개 모델 훈련"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 57개 모델 훈련\n",
        "print(\"🚀 57개 LightGBM 모델 훈련 시작!\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "models = {}\n",
        "training_results = {}\n",
        "n_trials_per_model = 20  # 시간 단축을 위해 20으로 조정\n",
        "\n",
        "start_time = datetime.now()\n",
        "\n",
        "# 성공/실패 카운터\n",
        "success_count = 0\n",
        "basic_count = 0\n",
        "failed_count = 0\n",
        "\n",
        "# 모든 훈련 데이터 분할에 대해 모델 훈련\n",
        "for i, (model_key, train_data) in enumerate(train_splits.items(), 1):\n",
        "    print(f\"\\n[{i:2d}/{len(train_splits)}] 🔥 {model_key}\")\n",
        "    print(f\"         📊 데이터: {len(train_data):,}개\")\n",
        "    \n",
        "    # 모델 생성 및 훈련\n",
        "    model = OptimizedLightGBMModel(model_key)\n",
        "    \n",
        "    try:\n",
        "        model_start = datetime.now()\n",
        "        model.fit(train_data, n_trials=n_trials_per_model)\n",
        "        model_time = (datetime.now() - model_start).total_seconds()\n",
        "        \n",
        "        models[model_key] = model\n",
        "        \n",
        "        # 결과 분류\n",
        "        if model.best_score is not None:\n",
        "            success_count += 1\n",
        "            status = \"✅ 최적화\"\n",
        "            score_text = f\"RMSE: {model.best_score:.3f}\"\n",
        "        else:\n",
        "            basic_count += 1\n",
        "            status = \"🔧 기본모델\"\n",
        "            score_text = \"기본파라미터\"\n",
        "        \n",
        "        # 안전한 결과 저장\n",
        "        training_results[model_key] = {\n",
        "            'data_size': len(train_data),\n",
        "            'training_time': model_time,\n",
        "            'best_score': model.best_score,\n",
        "            'best_params': model.best_params,\n",
        "            'optimization_success': model.best_score is not None\n",
        "        }\n",
        "        \n",
        "        print(f\"         {status} | {score_text} | ⏱️ {model_time:.1f}초\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"         ❌ 훈련 실패: {str(e)[:30]}...\")\n",
        "        failed_count += 1\n",
        "        \n",
        "        # 완전 기본 모델로 대체\n",
        "        try:\n",
        "            basic_model = OptimizedLightGBMModel(model_key)\n",
        "            basic_model._fit_basic_model(train_data, 'heat_demand')\n",
        "            models[model_key] = basic_model\n",
        "            \n",
        "            training_results[model_key] = {\n",
        "                'data_size': len(train_data),\n",
        "                'training_time': 0,\n",
        "                'best_score': None,\n",
        "                'best_params': None,\n",
        "                'optimization_success': False,\n",
        "                'error': str(e)[:50]\n",
        "            }\n",
        "            print(f\"         🔧 기본 모델로 대체 완료\")\n",
        "            \n",
        "        except Exception as e2:\n",
        "            print(f\"         ❌ 기본 모델 생성도 실패\")\n",
        "            # 더미 모델 저장\n",
        "            dummy_model = OptimizedLightGBMModel(model_key)\n",
        "            dummy_model.model = None\n",
        "            models[model_key] = dummy_model\n",
        "            \n",
        "            training_results[model_key] = {\n",
        "                'data_size': len(train_data),\n",
        "                'training_time': 0,\n",
        "                'best_score': None,\n",
        "                'best_params': None,\n",
        "                'optimization_success': False,\n",
        "                'error': f\"Complete failure: {str(e2)[:30]}\"\n",
        "            }\n",
        "\n",
        "total_time = (datetime.now() - start_time).total_seconds()\n",
        "\n",
        "print(f\"\\n\" + \"=\" * 60)\n",
        "print(f\"🎉 모든 모델 훈련 완료!\")\n",
        "print(f\"⏱️  총 소요 시간: {total_time/60:.1f}분 (평균 {total_time/len(train_splits):.1f}초/모델)\")\n",
        "print(f\"📊 훈련 결과:\")\n",
        "print(f\"   ✅ 최적화 성공: {success_count}개\")\n",
        "print(f\"   🔧 기본 모델: {basic_count}개\") \n",
        "print(f\"   ❌ 완전 실패: {failed_count}개\")\n",
        "print(f\"   📈 전체 성공률: {(success_count + basic_count)/len(train_splits)*100:.1f}%\")\n",
        "\n",
        "# 최고 성능 모델 찾기\n",
        "successful_models = {k: v for k, v in training_results.items() \n",
        "                    if v.get('optimization_success', False)}\n",
        "\n",
        "if successful_models:\n",
        "    best_model = min(successful_models.items(), key=lambda x: x[1]['best_score'])\n",
        "    print(f\"🏆 최고 성능: {best_model[0]} (RMSE: {best_model[1]['best_score']:.4f})\")\n",
        "    \n",
        "    # 시즌별 평균 성능\n",
        "    season_scores = {'난방': [], '비난방': []}\n",
        "    for model_name, result in successful_models.items():\n",
        "        season = model_name.split('_')[0]\n",
        "        if season in season_scores:\n",
        "            season_scores[season].append(result['best_score'])\n",
        "    \n",
        "    print(f\"📈 시즌별 평균 RMSE:\")\n",
        "    for season, scores in season_scores.items():\n",
        "        if scores:\n",
        "            print(f\"   {season}시즌: {np.mean(scores):.4f} ({len(scores)}개 모델)\")\n",
        "\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xC-cKYeui6IS"
      },
      "source": [
        "## 6️⃣ 훈련 결과 분석"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q73KBW9yi6IT"
      },
      "outputs": [],
      "source": [
        "# 훈련 결과 분석\n",
        "print(\"\\n📊 훈련 결과 분석\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# 결과 정리\n",
        "results_df = pd.DataFrame(training_results).T\n",
        "results_df['season'] = results_df.index.str.split('_').str[0]\n",
        "results_df['branch'] = results_df.index.str.split('_').str[1]\n",
        "\n",
        "# 성공/실패 통계\n",
        "successful_models = results_df[results_df['best_score'].notna()]\n",
        "failed_models = results_df[results_df['best_score'].isna()]\n",
        "\n",
        "print(f\"✅ 성공: {len(successful_models)}개 모델\")\n",
        "print(f\"❌ 실패: {len(failed_models)}개 모델\")\n",
        "\n",
        "if len(successful_models) > 0:\n",
        "    print(f\"\\n🏆 최적화 성능 통계:\")\n",
        "    print(f\"   평균 RMSE: {successful_models['best_score'].mean():.4f}\")\n",
        "    print(f\"   최소 RMSE: {successful_models['best_score'].min():.4f}\")\n",
        "    print(f\"   최대 RMSE: {successful_models['best_score'].max():.4f}\")\n",
        "    print(f\"   표준편차: {successful_models['best_score'].std():.4f}\")\n",
        "\n",
        "    # 시즌별 성능\n",
        "    print(f\"\\n📈 시즌별 평균 RMSE:\")\n",
        "    season_performance = successful_models.groupby('season')['best_score'].agg(['mean', 'count'])\n",
        "    for season, row in season_performance.iterrows():\n",
        "        print(f\"   {season}시즌: {row['mean']:.4f} ({int(row['count'])}개 모델)\")\n",
        "\n",
        "    # # 상위 5개 모델\n",
        "    # print(f\"\\n🥇 성능 상위 5개 모델:\")\n",
        "    # top_models = successful_models.nsmallest(5, 'best_score')\n",
        "    # for idx, (model_name, row) in enumerate(top_models.iterrows(), 1):\n",
        "    #     print(f\"   {idx}. {model_name}: RMSE = {row['best_score']:.4f}\")\n",
        "\n",
        "# 실패한 모델이 있으면 정보 출력\n",
        "if len(failed_models) > 0:\n",
        "    print(f\"\\n⚠️ 실패한 모델들:\")\n",
        "    for model_name, row in failed_models.iterrows():\n",
        "        error_msg = row.get('error', '알 수 없는 오류')\n",
        "        print(f\"   {model_name}: {error_msg}\")\n",
        "\n",
        "# 훈련 시간 통계\n",
        "avg_time = results_df['training_time'].mean()\n",
        "total_time_min = results_df['training_time'].sum() / 60\n",
        "print(f\"\\n⏱️ 훈련 시간 통계:\")\n",
        "print(f\"   평균 모델당: {avg_time:.1f}초\")\n",
        "print(f\"   총 훈련 시간: {total_time_min:.1f}분\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdr_IyHVi6IU"
      },
      "source": [
        "## 7️⃣ 테스트 예측"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NyMyt1tLi6IU"
      },
      "outputs": [],
      "source": [
        "# 테스트 데이터 예측\n",
        "print(\"🎯 테스트 데이터 예측 시작...\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "# 예측 결과를 저장할 딕셔너리\n",
        "predictions = {}\n",
        "prediction_stats = {}\n",
        "\n",
        "# 각 모델별로 해당 테스트 데이터에 대해 예측\n",
        "for model_key, model in models.items():\n",
        "    if model_key in test_splits:\n",
        "        test_data = test_splits[model_key]\n",
        "        \n",
        "        print(f\"📊 {model_key}: {len(test_data):,}개 데이터 예측 중...\")\n",
        "        \n",
        "        try:\n",
        "            pred = model.predict(test_data)\n",
        "            predictions[model_key] = {\n",
        "                'data': test_data,\n",
        "                'predictions': pred\n",
        "            }\n",
        "            \n",
        "            # 예측 통계\n",
        "            prediction_stats[model_key] = {\n",
        "                'count': len(pred),\n",
        "                'mean': np.mean(pred),\n",
        "                'std': np.std(pred),\n",
        "                'min': np.min(pred),\n",
        "                'max': np.max(pred)\n",
        "            }\n",
        "            \n",
        "            print(f\"   ✅ 완료: 평균={np.mean(pred):.2f}, 범위=[{np.min(pred):.2f}, {np.max(pred):.2f}]\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"   ❌ 예측 실패: {str(e)}\")\n",
        "            # 기본값으로 0 할당\n",
        "            predictions[model_key] = {\n",
        "                'data': test_data,\n",
        "                'predictions': np.zeros(len(test_data))\n",
        "            }\n",
        "    else:\n",
        "        print(f\"⚠️ {model_key}: 대응하는 테스트 데이터 없음\")\n",
        "\n",
        "print(f\"\\n✅ 예측 완료: {len(predictions)}개 모델\")\n",
        "\n",
        "# 예측 통계 요약\n",
        "if prediction_stats:\n",
        "    stats_df = pd.DataFrame(prediction_stats).T\n",
        "    print(f\"\\n📈 예측값 통계 요약:\")\n",
        "    print(f\"   전체 예측 개수: {stats_df['count'].sum():,}개\")\n",
        "    print(f\"   평균 예측값 범위: [{stats_df['mean'].min():.2f}, {stats_df['mean'].max():.2f}]\")\n",
        "    print(f\"   최대 예측값: {stats_df['max'].max():.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1lscpyji6IV"
      },
      "source": [
        "## 8️⃣ 예측 결과 통합"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MmB8fvVHi6IV"
      },
      "outputs": [],
      "source": [
        "# 예측 결과를 원본 test_df 순서에 맞게 통합\n",
        "print(\"🔄 예측 결과 통합 중...\")\n",
        "\n",
        "# 결과를 저장할 배열 초기화\n",
        "final_predictions = np.zeros(len(test_df))\n",
        "prediction_counts = np.zeros(len(test_df))  # 각 인덱스별 예측 횟수 추적\n",
        "\n",
        "# 각 예측 결과를 해당 인덱스에 할당\n",
        "for model_key, pred_info in predictions.items():\n",
        "    test_data = pred_info['data']\n",
        "    pred_values = pred_info['predictions']\n",
        "    \n",
        "    # 원본 test_df에서 해당 데이터의 인덱스 찾기\n",
        "    season, branch = model_key.split('_')\n",
        "    season_num = 1 if season == '난방' else 0\n",
        "    \n",
        "    # 조건에 맞는 인덱스 찾기\n",
        "    mask = (test_df['heating_season'] == season_num) & (test_df['branch_id'] == branch)\n",
        "    indices = test_df[mask].index.tolist()\n",
        "    \n",
        "    print(f\"📊 {model_key}: {len(indices)}개 인덱스에 할당\")\n",
        "    \n",
        "    # 예측값 할당 (인덱스 개수와 예측값 개수가 맞는지 확인)\n",
        "    if len(indices) == len(pred_values):\n",
        "        for i, idx in enumerate(indices):\n",
        "            final_predictions[idx] = pred_values[i]\n",
        "            prediction_counts[idx] += 1\n",
        "    else:\n",
        "        print(f\"   ⚠️ 크기 불일치: 인덱스 {len(indices)}개 vs 예측값 {len(pred_values)}개\")\n",
        "        # 크기가 다르면 최소 개수만큼만 할당\n",
        "        min_len = min(len(indices), len(pred_values))\n",
        "        for i in range(min_len):\n",
        "            final_predictions[indices[i]] = pred_values[i]\n",
        "            prediction_counts[indices[i]] += 1\n",
        "\n",
        "# 예측되지 않은 데이터 확인\n",
        "unassigned_count = np.sum(prediction_counts == 0)\n",
        "if unassigned_count > 0:\n",
        "    print(f\"⚠️ 예측되지 않은 데이터: {unassigned_count}개 (0으로 유지)\")\n",
        "\n",
        "# 중복 예측 확인\n",
        "duplicate_count = np.sum(prediction_counts > 1)\n",
        "if duplicate_count > 0:\n",
        "    print(f\"⚠️ 중복 예측된 데이터: {duplicate_count}개\")\n",
        "\n",
        "print(f\"\\n✅ 예측 결과 통합 완료\")\n",
        "print(f\"   📊 총 예측 개수: {len(final_predictions):,}개\")\n",
        "print(f\"   📈 예측값 통계: 평균={np.mean(final_predictions):.2f}, 최대={np.max(final_predictions):.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3WOSlaHi6IV"
      },
      "source": [
        "## 9️⃣ 최종 결과 저장 및 평가"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 최종 결과를 test_df에 추가\n",
        "print(\"💾 최종 결과 저장...\")\n",
        "\n",
        "# 원본 test_df 복사\n",
        "result_df = test_df.copy()\n",
        "\n",
        "# 예측 결과 추가 (음수값 제거)\n",
        "result_df['pred_heat_demand'] = np.maximum(final_predictions, 0).round(1)\n",
        "\n",
        "# CSV 파일 저장\n",
        "output_filename = 'lightgbm_branch_season_predictions.csv'\n",
        "result_df.to_csv(output_filename, index=False)\n",
        "\n",
        "print(f\"📁 결과 파일 저장: {output_filename}\")\n",
        "\n",
        "# =============================================================================\n",
        "# RMSE 중심 성능 평가 (실제값이 있는 경우)\n",
        "# =============================================================================\n",
        "\n",
        "if 'heat_demand' in test_df.columns:\n",
        "    print(f\"\\n📊 RMSE 성능 평가\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    # 전체 RMSE\n",
        "    y_true = test_df['heat_demand'].values\n",
        "    y_pred = result_df['pred_heat_demand'].values\n",
        "    \n",
        "    # 음수나 NaN 값 제거\n",
        "    valid_mask = ~(np.isnan(y_true) | np.isnan(y_pred))\n",
        "    y_true_clean = y_true[valid_mask]\n",
        "    y_pred_clean = y_pred[valid_mask]\n",
        "    \n",
        "    overall_rmse = np.sqrt(mean_squared_error(y_true_clean, y_pred_clean))\n",
        "    overall_mae = mean_absolute_error(y_true_clean, y_pred_clean)\n",
        "    correlation = np.corrcoef(y_true_clean, y_pred_clean)[0, 1]\n",
        "    \n",
        "    print(f\"🏆 전체 성능:\")\n",
        "    print(f\"   RMSE: {overall_rmse:.4f}\")\n",
        "    print(f\"   MAE:  {overall_mae:.4f}\")\n",
        "    print(f\"   상관계수: {correlation:.4f}\")\n",
        "    print(f\"   유효 데이터: {len(y_true_clean):,}개\")\n",
        "    \n",
        "    # 시즌별 RMSE (핵심!)\n",
        "    print(f\"\\n📈 시즌별 RMSE 성능:\")\n",
        "    season_names = {0: '비난방시즌', 1: '난방상승시즌', 2: '난방하강시즌'}\n",
        "    season_results = {}\n",
        "\n",
        "    for season in [0, 1, 2]:\n",
        "        mask = (test_df['heating_season'] == season) & valid_mask\n",
        "        if np.sum(mask) > 0:\n",
        "            season_rmse = np.sqrt(mean_squared_error(y_true[mask], y_pred[mask]))\n",
        "            season_mae = mean_absolute_error(y_true[mask], y_pred[mask])\n",
        "            season_corr = np.corrcoef(y_true[mask], y_pred[mask])[0, 1] if np.sum(mask) > 1 else 0\n",
        "            season_results[season] = {\n",
        "                'rmse': season_rmse, \n",
        "                'mae': season_mae, \n",
        "                'corr': season_corr,\n",
        "                'count': np.sum(mask)\n",
        "            }\n",
        "            \n",
        "            print(f\"   {season_names[season]:12s}: RMSE={season_rmse:7.4f} | MAE={season_mae:7.4f} | 상관={season_corr:6.3f} | {np.sum(mask):,}개\")\n",
        "    \n",
        "    # 브랜치별 RMSE (상위/하위 분석)\n",
        "    print(f\"\\n📊 브랜치별 RMSE 성능:\")\n",
        "    branch_results = {}\n",
        "    \n",
        "    for branch in sorted(test_df['branch_id'].unique()):\n",
        "        mask = (test_df['branch_id'] == branch) & valid_mask\n",
        "        if np.sum(mask) > 1:  # 최소 2개 이상의 데이터가 있어야 RMSE 계산 가능\n",
        "            branch_rmse = np.sqrt(mean_squared_error(y_true[mask], y_pred[mask]))\n",
        "            branch_mae = mean_absolute_error(y_true[mask], y_pred[mask])\n",
        "            branch_results[branch] = {\n",
        "                'rmse': branch_rmse,\n",
        "                'mae': branch_mae, \n",
        "                'count': np.sum(mask)\n",
        "            }\n",
        "    \n",
        "    if branch_results:\n",
        "        # RMSE 기준 정렬\n",
        "        sorted_branches = sorted(branch_results.items(), key=lambda x: x[1]['rmse'])\n",
        "        \n",
        "        print(f\"   🥇 RMSE 우수 브랜치 (Top 5):\")\n",
        "        for i, (branch, metrics) in enumerate(sorted_branches[:5], 1):\n",
        "            print(f\"      {i}. 브랜치 {branch}: RMSE={metrics['rmse']:7.4f} | MAE={metrics['mae']:7.4f} | {metrics['count']:,}개\")\n",
        "        \n",
        "        print(f\"   🥉 RMSE 개선 필요 브랜치 (Bottom 5):\")\n",
        "        for i, (branch, metrics) in enumerate(sorted_branches[-5:], 1):\n",
        "            print(f\"      {i}. 브랜치 {branch}: RMSE={metrics['rmse']:7.4f} | MAE={metrics['mae']:7.4f} | {metrics['count']:,}개\")\n",
        "        \n",
        "        # 브랜치별 성능 통계\n",
        "        rmse_values = [v['rmse'] for v in branch_results.values()]\n",
        "        print(f\"\\n   📈 브랜치별 RMSE 통계:\")\n",
        "        print(f\"      평균: {np.mean(rmse_values):.4f}\")\n",
        "        print(f\"      표준편차: {np.std(rmse_values):.4f}\")\n",
        "        print(f\"      최소: {np.min(rmse_values):.4f}\")\n",
        "        print(f\"      최대: {np.max(rmse_values):.4f}\")\n",
        "    \n",
        "    # 시즌×브랜치 조합별 RMSE (상위 10개만)\n",
        "    print(f\"\\n🔥 시즌×브랜치 조합별 RMSE (Ranking):\")\n",
        "    combo_results = []\n",
        "    \n",
        "    for season in [0, 1]:\n",
        "        for branch in test_df['branch_id'].unique():\n",
        "            mask = (test_df['heating_season'] == season) & (test_df['branch_id'] == branch) & valid_mask\n",
        "            if np.sum(mask) > 1:\n",
        "                combo_rmse = np.sqrt(mean_squared_error(y_true[mask], y_pred[mask]))\n",
        "                combo_name = f\"{season_names[season]}_{branch}\"\n",
        "                combo_results.append((combo_name, combo_rmse, np.sum(mask)))\n",
        "    \n",
        "    # RMSE 기준 정렬하여 표시\n",
        "    combo_results.sort(key=lambda x: x[1])\n",
        "    for i, (combo_name, rmse, count) in enumerate(combo_results, 1):\n",
        "        print(f\"   {i:2d}. {combo_name:15s}: RMSE={rmse:7.4f} | {count:,}개\")\n",
        "    \n",
        "    # 훈련된 모델들의 최적화 성능과 실제 테스트 성능 비교\n",
        "    print(f\"\\n🔍 모델 최적화 vs 실제 성능 비교:\")\n",
        "    optimization_rmses = [v['best_score'] for v in training_results.values() if v.get('best_score') is not None]\n",
        "    \n",
        "    if optimization_rmses:\n",
        "        print(f\"   훈련시 최적화 RMSE: 평균={np.mean(optimization_rmses):.4f}, 범위=[{np.min(optimization_rmses):.4f}, {np.max(optimization_rmses):.4f}]\")\n",
        "        print(f\"   실제 테스트 RMSE: {overall_rmse:.4f}\")\n",
        "        print(f\"   성능 차이: {abs(overall_rmse - np.mean(optimization_rmses)):.4f}\")\n",
        "    \n",
        "else:\n",
        "    print(f\"\\n⚠️ 테스트 데이터에 heat_demand 컬럼이 없어서 RMSE 평가를 수행할 수 없습니다.\")\n",
        "    print(f\"   예측 결과만 저장되었습니다.\")\n",
        "    \n",
        "    # 예측값 기본 통계\n",
        "    print(f\"\\n📊 예측값 기본 통계:\")\n",
        "    print(f\"   개수: {len(result_df):,}개\")\n",
        "    print(f\"   평균: {result_df['pred_heat_demand'].mean():.2f}\")\n",
        "    print(f\"   중앙값: {result_df['pred_heat_demand'].median():.2f}\")\n",
        "    print(f\"   표준편차: {result_df['pred_heat_demand'].std():.2f}\")\n",
        "    print(f\"   범위: [{result_df['pred_heat_demand'].min():.2f}, {result_df['pred_heat_demand'].max():.2f}]\")\n",
        "    \n",
        "    # 시즌별 예측 통계\n",
        "    print(f\"\\n📈 시즌별 예측 통계:\")\n",
        "    season_names = {0: '비난방시즌', 1: '난방상승시즌', 2: '난방하강시즌'}\n",
        "    for season in [0, 1, 2]:\n",
        "        season_data = result_df[result_df['heating_season'] == season]['pred_heat_demand']\n",
        "        if len(season_data) > 0:\n",
        "            season_name = season_names[season]\n",
        "            print(f\"   {season_name}: 평균={season_data.mean():.2f}, 개수={len(season_data):,}개\")\n",
        "\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlR68tz9W1AF"
      },
      "source": [
        "## 🔟 모델 정보 저장"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xk3Cf_3YWyKq"
      },
      "outputs": [],
      "source": [
        "# 모델 정보 및 결과 저장\n",
        "print(\"💾 모델 정보 저장...\")\n",
        "\n",
        "# 훈련 결과 및 모델 정보를 JSON으로 저장\n",
        "model_info = {\n",
        "    'total_models': len(models),\n",
        "    'successful_models': len([k for k, v in training_results.items() if v.get('best_score') is not None]),\n",
        "    'training_results': training_results,\n",
        "    'prediction_stats': prediction_stats if 'prediction_stats' in locals() else {},\n",
        "    'feature_columns': models[list(models.keys())[0]].feature_cols if models else [],\n",
        "    'optimization_trials_per_model': n_trials_per_model,\n",
        "    'total_training_time_minutes': total_time_min if 'total_time_min' in locals() else 0\n",
        "}\n",
        "\n",
        "# RMSE 결과 추가 (있는 경우)\n",
        "if 'heat_demand' in test_df.columns:\n",
        "    model_info['evaluation_results'] = {\n",
        "        'overall_rmse': overall_rmse,\n",
        "        'overall_mae': overall_mae,\n",
        "        'correlation': correlation\n",
        "    }\n",
        "\n",
        "# JSON 파일로 저장\n",
        "with open('model_info_and_results.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(model_info, f, indent=2, ensure_ascii=False, default=str)\n",
        "\n",
        "print(\"📁 model_info_and_results.json 저장 완료\")\n",
        "\n",
        "# 간단한 요약 출력\n",
        "print(f\"\\n📋 모델 정보 요약:\")\n",
        "print(f\"   🔧 총 모델 수: {model_info['total_models']}개\")\n",
        "print(f\"   ✅ 성공한 모델: {model_info['successful_models']}개\")\n",
        "print(f\"   📊 사용 특성 수: {len(model_info['feature_columns'])}개\")\n",
        "print(f\"   🎯 모델당 최적화 시도: {model_info['optimization_trials_per_model']}회\")\n",
        "\n",
        "# Google Drive 저장 (Colab 환경)\n",
        "if IN_COLAB:\n",
        "    save_drive = input(\"\\nGoogle Drive에 결과 파일들을 저장하시겠습니까? (y/n): \").lower() == 'y'\n",
        "    if save_drive:\n",
        "        try:\n",
        "            !cp {output_filename} /content/drive/MyDrive/\n",
        "            !cp model_info_and_results.json /content/drive/MyDrive/\n",
        "            print(\"✅ Google Drive 저장 완료!\")\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Google Drive 저장 실패: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "leJLw4dVi6IW"
      },
      "source": [
        "## 🎯 최종 요약"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K8stlKlsi6IX"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"🔥 지역난방 열수요 예측: 시즌별-브랜치별 XGBoost 모델 - 최종 요약\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(f\"\\n🏗️ 모델 구성:\")\n",
        "print(f\"   📊 XGBoost 개별 모델 (시즌별 × 브랜치별)\")\n",
        "print(f\"   🎯 Optuna TPE 하이퍼파라미터 최적화\")\n",
        "print(f\"   📋 총 모델 수: {len(models)}개\")\n",
        "print(f\"   ✅ 성공적 훈련: {len([k for k, v in training_results.items() if v.get('best_score') is not None])}개\")\n",
        "\n",
        "print(f\"\\n📈 특성 엔지니어링:\")\n",
        "print(f\"   ⭐ HDD, wind_chill, 온도 제곱/세제곱\")\n",
        "print(f\"   🔄 순환형 인코딩 (시간, 월, 요일)\")\n",
        "print(f\"   📋 범주형: heating_season, 피크시간, 기온범주, 강수강도\")\n",
        "print(f\"   🧮 상호작용: 습도×기온, 월×일\")\n",
        "# print(f\"   📏 StandardScaler 정규화\")\n",
        "\n",
        "print(f\"\\n🎯 모델링 전략:\")\n",
        "print(f\"   ❄️ 난방시즌 (10,11,12,1,2,3,4월) 전용 모델\")\n",
        "print(f\"   🌞 비난방시즌 (5,6,7,8,9월) 전용 모델\")\n",
        "print(f\"   🏢 브랜치별 개별 모델 (각 지사의 특성 반영)\")\n",
        "print(f\"   ⚡ XGBoost with Early Stopping\")\n",
        "\n",
        "print(f\"\\n🔍 최적화 설정:\")\n",
        "print(f\"   📊 Optuna TPE Sampler\")\n",
        "print(f\"   🎯 모델당 {n_trials_per_model}회 시도\")\n",
        "print(f\"   📈 시계열 기반 Train/Validation 분할 (80:20)\")\n",
        "print(f\"   🎪 XGBoost Pruning Callback 사용\")\n",
        "\n",
        "if 'heat_demand' in test_df.columns:\n",
        "    print(f\"\\n🏆 최종 성능:\")\n",
        "    print(f\"   📊 전체 RMSE: {overall_rmse:.4f}\")\n",
        "    print(f\"   📏 전체 MAE: {overall_mae:.4f}\")\n",
        "    print(f\"   📈 상관계수: {correlation:.4f}\")\n",
        "\n",
        "# 최고 성능 모델 정보\n",
        "if successful_models is not None and len(successful_models) > 0:\n",
        "    best_model_name = successful_models['best_score'].idxmin()\n",
        "    best_score = successful_models.loc[best_model_name, 'best_score']\n",
        "    print(f\"\\n🥇 최고 성능 모델: {best_model_name} (RMSE: {best_score:.4f})\")\n",
        "\n",
        "print(f\"\\n📁 출력 파일:\")\n",
        "print(f\"   • {output_filename} - 예측 결과\")\n",
        "print(f\"   • model_info_and_results.json - 모델 정보 및 훈련 결과\")\n",
        "print(f\"   • 핵심 컬럼: pred_heat_demand (예측값)\")\n",
        "\n",
        "print(f\"\\n⏱️ 실행 시간:\")\n",
        "if 'total_time_min' in locals():\n",
        "    print(f\"   🚀 총 훈련 시간: {total_time_min:.1f}분\")\n",
        "    print(f\"   ⚡ 평균 모델당: {total_time_min*60/len(models):.1f}초\")\n",
        "\n",
        "print(f\"\\n🎉 지역난방 열수요 예측 완료!\")\n",
        "print(f\"🔬 혁신 포인트: 시즌×브랜치 세분화 + Optuna 자동 최적화\")\n",
        "print(f\"📊 총 {len(models)}개 모델로 정밀한 지역별-시즌별 예측 구현\")\n",
        "print(\"=\"*80)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
